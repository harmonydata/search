1:"$Sreact.fragment"
2:I[82104,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
3:I[10683,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"AuthProvider"]
4:I[63612,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"SearchProvider"]
5:I[68998,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
6:I[98904,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/2c4d913f25bfc6bf.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"s_DTI9faTgGaCM3x3n4Zl","p":"/search","c":["","items","5070958a6d89906de65f3860444e973d"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","5070958a6d89906de65f3860444e973d","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/2c4d913f25bfc6bf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_62a302","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","5070958a6d89906de65f3860444e973d","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","kt-W6yfS23IVyDrWEtX3x",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
a:["$","div",null,{"children":[["$","script",null,{"dangerouslySetInnerHTML":{"__html":"window.location.replace('/items/watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan');"}}],["$","p",null,{"children":["Redirecting to"," ",["$","a",null,{"href":"/items/watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan","children":["/items/","watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan"]}],"..."]}]]}]
12:T1ff0,We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson & Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response. Finally, six additional video stimuli (that were not part of the full set of 64 videos from the training conditions) were included for attentional control questions. After each one of these six test trials, participants were asked a question that required a yes (button 1) or no (button 4) response (reverse order counterbalanced between participants). This question was, ‘Did the dancer place at least one arm above their head?’, and was designed to ensure the participants paid full attention to the dancer’s movement in each stimulus. Participants were trained outside of the scanner prior to the pre-training scan to become familiar with the all features of the experiment and what they would be asked to do whilst in the scanner.
Stimuli presentation and response recording was done with a Mac desktop computer running MATLAB R2010a (Mathworks, Natick, MA) and Psychophysics Toolbox 3 (Brainard, 1997; Pelli, 1997, Kleiner et al. 2007). Stimuli were retroprojected onto a translucent screen viewed via a mirror mounted on the head coil. The experiment was carried out in a 3-T Philips MRI scanner using a SENSE phased-array head coil. For functional imaging, a single-shot echo planar imaging sequence was used (T2*-weighted, gradient echo sequence; echo time TE=30 ms; flip angle, 90̊). The scanning parameters were as follows: repetition time TR=2000 ms; 30 axial slices; voxel dimensions, 3 x 3 mm with voxel slice thickness=4 mm; slice gap=0.8 mm; field of view (FOV), 230 x 230 x 143 mm; matrix size, 128 x 128 mm2; anterior-posterior phase-encoding. Parameters for T1-weighted anatomical scans were: 240 x 240 mm2 matrix; voxel dimensions, 2 x 2 x 2 mm; TR = 12 ms; TE = 3.5 ms; flip angle = 8̊. Due to an error in the scanning protocol, for the first 14 scan sessions, brain slices were acquired in an interleaved manner whilst the last 26 scan sessions were collected in an ascending order. Any discrepancies between the two orders of acquisition were corrected during preprocessing with appropriate slice time correction procedures. For each run of each scanning session, the first two brain volumes were discarded to reduce saturation effects. Depending on the participants’ response time to each question and the pseudorandom duration of the fixation cross prior to each trial, the total number of functional scans collected for each participant ranged between 369 and 480 volumes (mean = 395) per functional run.
As humans, our ability to survive within a social world is facilitated by learning through observing others. As such, when learning tasks as simple as tying one's shoes or as complex as performing heart surgery, we learn by watching from childhood through to old age. Many researchers from the behavioural and brain sciences suggest that observational and physical learning share common features. What remains unknown is how our brains and behaviour change when learning by observation across the lifespan, as well as how age impacts the efficacy of observational learning. To address these questions, I measure the impact of observational learning on behaviour and brain activity among children, young adults, and older adults. The ultimate aim is to develop a means of identifying factors associated with observational learning success, which in turn will inform observation-based interventions used in education and therapeutic contexts.13:T1ff0,We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson & Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response. Finally, six additional video stimuli (that were not part of the full set of 64 videos from the training conditions) were included for attentional control questions. After each one of these six test trials, participants were asked a question that required a yes (button 1) or no (button 4) response (reverse order counterbalanced between participants). This question was, ‘Did the dancer place at least one arm above their head?’, and was designed to ensure the participants paid full attention to the dancer’s movement in each stimulus. Participants were trained outside of the scanner prior to the pre-training scan to become familiar with the all features of the experiment and what they would be asked to do whilst in the scanner.
Stimuli presentation and response recording was done with a Mac desktop computer running MATLAB R2010a (Mathworks, Natick, MA) and Psychophysics Toolbox 3 (Brainard, 1997; Pelli, 1997, Kleiner et al. 2007). Stimuli were retroprojected onto a translucent screen viewed via a mirror mounted on the head coil. The experiment was carried out in a 3-T Philips MRI scanner using a SENSE phased-array head coil. For functional imaging, a single-shot echo planar imaging sequence was used (T2*-weighted, gradient echo sequence; echo time TE=30 ms; flip angle, 90̊). The scanning parameters were as follows: repetition time TR=2000 ms; 30 axial slices; voxel dimensions, 3 x 3 mm with voxel slice thickness=4 mm; slice gap=0.8 mm; field of view (FOV), 230 x 230 x 143 mm; matrix size, 128 x 128 mm2; anterior-posterior phase-encoding. Parameters for T1-weighted anatomical scans were: 240 x 240 mm2 matrix; voxel dimensions, 2 x 2 x 2 mm; TR = 12 ms; TE = 3.5 ms; flip angle = 8̊. Due to an error in the scanning protocol, for the first 14 scan sessions, brain slices were acquired in an interleaved manner whilst the last 26 scan sessions were collected in an ascending order. Any discrepancies between the two orders of acquisition were corrected during preprocessing with appropriate slice time correction procedures. For each run of each scanning session, the first two brain volumes were discarded to reduce saturation effects. Depending on the participants’ response time to each question and the pseudorandom duration of the fixation cross prior to each trial, the total number of functional scans collected for each participant ranged between 369 and 480 volumes (mean = 395) per functional run.
As humans, our ability to survive within a social world is facilitated by learning through observing others. As such, when learning tasks as simple as tying one's shoes or as complex as performing heart surgery, we learn by watching from childhood through to old age. Many researchers from the behavioural and brain sciences suggest that observational and physical learning share common features. What remains unknown is how our brains and behaviour change when learning by observation across the lifespan, as well as how age impacts the efficacy of observational learning. To address these questions, I measure the impact of observational learning on behaviour and brain activity among children, young adults, and older adults. The ultimate aim is to develop a means of identifying factors associated with observational learning success, which in turn will inform observation-based interventions used in education and therapeutic contexts.14:T1ff0,We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson & Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response. Finally, six additional video stimuli (that were not part of the full set of 64 videos from the training conditions) were included for attentional control questions. After each one of these six test trials, participants were asked a question that required a yes (button 1) or no (button 4) response (reverse order counterbalanced between participants). This question was, ‘Did the dancer place at least one arm above their head?’, and was designed to ensure the participants paid full attention to the dancer’s movement in each stimulus. Participants were trained outside of the scanner prior to the pre-training scan to become familiar with the all features of the experiment and what they would be asked to do whilst in the scanner.
Stimuli presentation and response recording was done with a Mac desktop computer running MATLAB R2010a (Mathworks, Natick, MA) and Psychophysics Toolbox 3 (Brainard, 1997; Pelli, 1997, Kleiner et al. 2007). Stimuli were retroprojected onto a translucent screen viewed via a mirror mounted on the head coil. The experiment was carried out in a 3-T Philips MRI scanner using a SENSE phased-array head coil. For functional imaging, a single-shot echo planar imaging sequence was used (T2*-weighted, gradient echo sequence; echo time TE=30 ms; flip angle, 90̊). The scanning parameters were as follows: repetition time TR=2000 ms; 30 axial slices; voxel dimensions, 3 x 3 mm with voxel slice thickness=4 mm; slice gap=0.8 mm; field of view (FOV), 230 x 230 x 143 mm; matrix size, 128 x 128 mm2; anterior-posterior phase-encoding. Parameters for T1-weighted anatomical scans were: 240 x 240 mm2 matrix; voxel dimensions, 2 x 2 x 2 mm; TR = 12 ms; TE = 3.5 ms; flip angle = 8̊. Due to an error in the scanning protocol, for the first 14 scan sessions, brain slices were acquired in an interleaved manner whilst the last 26 scan sessions were collected in an ascending order. Any discrepancies between the two orders of acquisition were corrected during preprocessing with appropriate slice time correction procedures. For each run of each scanning session, the first two brain volumes were discarded to reduce saturation effects. Depending on the participants’ response time to each question and the pseudorandom duration of the fixation cross prior to each trial, the total number of functional scans collected for each participant ranged between 369 and 480 volumes (mean = 395) per functional run.
As humans, our ability to survive within a social world is facilitated by learning through observing others. As such, when learning tasks as simple as tying one's shoes or as complex as performing heart surgery, we learn by watching from childhood through to old age. Many researchers from the behavioural and brain sciences suggest that observational and physical learning share common features. What remains unknown is how our brains and behaviour change when learning by observation across the lifespan, as well as how age impacts the efficacy of observational learning. To address these questions, I measure the impact of observational learning on behaviour and brain activity among children, young adults, and older adults. The ultimate aim is to develop a means of identifying factors associated with observational learning success, which in turn will inform observation-based interventions used in education and therapeutic contexts.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"}],["$","meta","2",{"name":"description","content":"$12"}],["$","meta","3",{"property":"og:title","content":"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"}],["$","meta","4",{"property":"og:description","content":"$13"}],["$","meta","5",{"property":"og:url","content":"https://discoverynext.vercel.app/items/5070958a6d89906de65f3860444e973d"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"}],["$","meta","15",{"name":"twitter:description","content":"$14"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
