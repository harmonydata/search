1:"$Sreact.fragment"
2:I[82104,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
3:I[10683,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"AuthProvider"]
4:I[63612,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"SearchProvider"]
5:I[68998,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
6:I[98904,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/2c4d913f25bfc6bf.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"s_DTI9faTgGaCM3x3n4Zl","p":"/search","c":["","items","682c725fd680a6eb7a33371e0c1baacb"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","682c725fd680a6eb7a33371e0c1baacb","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/2c4d913f25bfc6bf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_62a302","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","682c725fd680a6eb7a33371e0c1baacb","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","UdncJsHuSjw-YsCjaEZgO",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
a:["$","div",null,{"children":[["$","script",null,{"dangerouslySetInnerHTML":{"__html":"window.location.replace('/items/protechthem-relevant-self-regulation-data-social-media-platforms-2021-2022');"}}],["$","p",null,{"children":["Redirecting to"," ",["$","a",null,{"href":"/items/protechthem-relevant-self-regulation-data-social-media-platforms-2021-2022","children":["/items/","protechthem-relevant-self-regulation-data-social-media-platforms-2021-2022"]}],"..."]}]]}]
12:T1224,To identify vulnerabilities in self-regulatory practices, we focused on what we expected to be five social media platforms with a major role in sharenting practices, which were selected considering their demographic distribution among the population, and following a discussion with our non-academic project partners: Facebook; TikTok; Instagram; You Tube; Twitter. Textual data was retrieved from each of these platforms’ relevant self-regulatory documents (mostly terms and conditions, and community standards, even if some additional documents targeting, for instance, specifically parents were identified and considered for the analysis). This data is publicly available online and, after an initial screening, all sections of the documents that could (broadly) be relevant to sharenting, digital harms and crimes, moderation practices, minors and their parents/guardians were selected for the analysis and collated in the file here avilable.Especially over the past 15 years, the creation of new "online identities" (the social identity that we acquire in cyberspace) and the expansion of the usability of our "digital identity" (the digital storage of our attributed, biographical or even biological identities) have entailed, alongside many advantages, also new and emerging risks and crime vulnerabilities, as identity information can be misused in many ways and create severe harms. Existing research in this context has so far focused on the illegal access to personal information (e.g. through hacking or social engineering techniques) but has overlooked the risky behaviours of individuals willingly sharing identifying (and potentially sensitive) information online. In this context, an area of particular interest that has been particularly overlooked is the one connected to the sharing of identifying and sensitive information of minors, who are often overexposed online in good-faith by parents and guardians in so called "sharenting" practices. Beyond risks due to negative psychological repercussions in ignoring children's desire to having (or not) an online identity, there are concerns regarding the potential for grooming and child abuse, and the potential for identity crimes (such as identity fraud and identity theft), especially keeping in mind that today's children, in a few years, will be those employing digital identities in many aspects of their lives, and will need a clean and curated digital identity to be fully part of many aspects of our society.

The proposed project combines traditional and innovative cross-disciplinary approaches to further this emerging line of inquiry. The project does so by offering a better understanding of sharenting practices, their motivations, and the risks associated with them. It provides a better understanding of the existing technical and regulatory loopholes and gaps enabling potentially harmful sharenting practices. It also develops a better understanding of the perception of the problem by parents and guardians (our "target population"). The project can therefore enable better targeted awareness-raising activities; an improvement of the tools we currently have to study, prevent and mitigate the negative impacts of sharenting practices.

The result of this research will be of significant importance for social media users (and specifically for those in our target population) by raising awareness and promoting sustained behavioural change to minimise cyber risks. The results will also be of relevance for the work of law enforcement in better addressing crimes potentially facilitated by certain sharenting practices such as grooming and identity crimes.

More in general, the proposed approach will improve our understanding of criminogenic opportunities available in social media, supporting new avenues of investigation. By integrating insights and expertise from criminology and computer sciences, the proposed project also has important implications for demonstrating interdisciplinary methodological developments and promoting best practice for ethical online research.

The research project is structured around seven cumulative work-packages to allow the research team to build a solid body of original data (currently not available to researchers) but also to promote engagement and effective communication with a non-academic audience (primarily, law enforcement, and parents and guardians). Throughout the project, we will be supported by our Project Partners (UK Safer Internet Centre; Kidscape; Arma dei Carabinieri); together with Dame Prof. Wendy Hall and other stakeholders, the Project Partners will be also part of our Advisory Board.13:T1224,To identify vulnerabilities in self-regulatory practices, we focused on what we expected to be five social media platforms with a major role in sharenting practices, which were selected considering their demographic distribution among the population, and following a discussion with our non-academic project partners: Facebook; TikTok; Instagram; You Tube; Twitter. Textual data was retrieved from each of these platforms’ relevant self-regulatory documents (mostly terms and conditions, and community standards, even if some additional documents targeting, for instance, specifically parents were identified and considered for the analysis). This data is publicly available online and, after an initial screening, all sections of the documents that could (broadly) be relevant to sharenting, digital harms and crimes, moderation practices, minors and their parents/guardians were selected for the analysis and collated in the file here avilable.Especially over the past 15 years, the creation of new "online identities" (the social identity that we acquire in cyberspace) and the expansion of the usability of our "digital identity" (the digital storage of our attributed, biographical or even biological identities) have entailed, alongside many advantages, also new and emerging risks and crime vulnerabilities, as identity information can be misused in many ways and create severe harms. Existing research in this context has so far focused on the illegal access to personal information (e.g. through hacking or social engineering techniques) but has overlooked the risky behaviours of individuals willingly sharing identifying (and potentially sensitive) information online. In this context, an area of particular interest that has been particularly overlooked is the one connected to the sharing of identifying and sensitive information of minors, who are often overexposed online in good-faith by parents and guardians in so called "sharenting" practices. Beyond risks due to negative psychological repercussions in ignoring children's desire to having (or not) an online identity, there are concerns regarding the potential for grooming and child abuse, and the potential for identity crimes (such as identity fraud and identity theft), especially keeping in mind that today's children, in a few years, will be those employing digital identities in many aspects of their lives, and will need a clean and curated digital identity to be fully part of many aspects of our society.

The proposed project combines traditional and innovative cross-disciplinary approaches to further this emerging line of inquiry. The project does so by offering a better understanding of sharenting practices, their motivations, and the risks associated with them. It provides a better understanding of the existing technical and regulatory loopholes and gaps enabling potentially harmful sharenting practices. It also develops a better understanding of the perception of the problem by parents and guardians (our "target population"). The project can therefore enable better targeted awareness-raising activities; an improvement of the tools we currently have to study, prevent and mitigate the negative impacts of sharenting practices.

The result of this research will be of significant importance for social media users (and specifically for those in our target population) by raising awareness and promoting sustained behavioural change to minimise cyber risks. The results will also be of relevance for the work of law enforcement in better addressing crimes potentially facilitated by certain sharenting practices such as grooming and identity crimes.

More in general, the proposed approach will improve our understanding of criminogenic opportunities available in social media, supporting new avenues of investigation. By integrating insights and expertise from criminology and computer sciences, the proposed project also has important implications for demonstrating interdisciplinary methodological developments and promoting best practice for ethical online research.

The research project is structured around seven cumulative work-packages to allow the research team to build a solid body of original data (currently not available to researchers) but also to promote engagement and effective communication with a non-academic audience (primarily, law enforcement, and parents and guardians). Throughout the project, we will be supported by our Project Partners (UK Safer Internet Centre; Kidscape; Arma dei Carabinieri); together with Dame Prof. Wendy Hall and other stakeholders, the Project Partners will be also part of our Advisory Board.14:T1224,To identify vulnerabilities in self-regulatory practices, we focused on what we expected to be five social media platforms with a major role in sharenting practices, which were selected considering their demographic distribution among the population, and following a discussion with our non-academic project partners: Facebook; TikTok; Instagram; You Tube; Twitter. Textual data was retrieved from each of these platforms’ relevant self-regulatory documents (mostly terms and conditions, and community standards, even if some additional documents targeting, for instance, specifically parents were identified and considered for the analysis). This data is publicly available online and, after an initial screening, all sections of the documents that could (broadly) be relevant to sharenting, digital harms and crimes, moderation practices, minors and their parents/guardians were selected for the analysis and collated in the file here avilable.Especially over the past 15 years, the creation of new "online identities" (the social identity that we acquire in cyberspace) and the expansion of the usability of our "digital identity" (the digital storage of our attributed, biographical or even biological identities) have entailed, alongside many advantages, also new and emerging risks and crime vulnerabilities, as identity information can be misused in many ways and create severe harms. Existing research in this context has so far focused on the illegal access to personal information (e.g. through hacking or social engineering techniques) but has overlooked the risky behaviours of individuals willingly sharing identifying (and potentially sensitive) information online. In this context, an area of particular interest that has been particularly overlooked is the one connected to the sharing of identifying and sensitive information of minors, who are often overexposed online in good-faith by parents and guardians in so called "sharenting" practices. Beyond risks due to negative psychological repercussions in ignoring children's desire to having (or not) an online identity, there are concerns regarding the potential for grooming and child abuse, and the potential for identity crimes (such as identity fraud and identity theft), especially keeping in mind that today's children, in a few years, will be those employing digital identities in many aspects of their lives, and will need a clean and curated digital identity to be fully part of many aspects of our society.

The proposed project combines traditional and innovative cross-disciplinary approaches to further this emerging line of inquiry. The project does so by offering a better understanding of sharenting practices, their motivations, and the risks associated with them. It provides a better understanding of the existing technical and regulatory loopholes and gaps enabling potentially harmful sharenting practices. It also develops a better understanding of the perception of the problem by parents and guardians (our "target population"). The project can therefore enable better targeted awareness-raising activities; an improvement of the tools we currently have to study, prevent and mitigate the negative impacts of sharenting practices.

The result of this research will be of significant importance for social media users (and specifically for those in our target population) by raising awareness and promoting sustained behavioural change to minimise cyber risks. The results will also be of relevance for the work of law enforcement in better addressing crimes potentially facilitated by certain sharenting practices such as grooming and identity crimes.

More in general, the proposed approach will improve our understanding of criminogenic opportunities available in social media, supporting new avenues of investigation. By integrating insights and expertise from criminology and computer sciences, the proposed project also has important implications for demonstrating interdisciplinary methodological developments and promoting best practice for ethical online research.

The research project is structured around seven cumulative work-packages to allow the research team to build a solid body of original data (currently not available to researchers) but also to promote engagement and effective communication with a non-academic audience (primarily, law enforcement, and parents and guardians). Throughout the project, we will be supported by our Project Partners (UK Safer Internet Centre; Kidscape; Arma dei Carabinieri); together with Dame Prof. Wendy Hall and other stakeholders, the Project Partners will be also part of our Advisory Board.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"ProTechThem: Relevant Self-Regulation Data, Social Media Platforms, 2021-2022"}],["$","meta","2",{"name":"description","content":"$12"}],["$","meta","3",{"property":"og:title","content":"ProTechThem: Relevant Self-Regulation Data, Social Media Platforms, 2021-2022"}],["$","meta","4",{"property":"og:description","content":"$13"}],["$","meta","5",{"property":"og:url","content":"https://discoverynext.vercel.app/items/682c725fd680a6eb7a33371e0c1baacb"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"ProTechThem: Relevant Self-Regulation Data, Social Media Platforms, 2021-2022"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"ProTechThem: Relevant Self-Regulation Data, Social Media Platforms, 2021-2022"}],["$","meta","15",{"name":"twitter:description","content":"$14"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
