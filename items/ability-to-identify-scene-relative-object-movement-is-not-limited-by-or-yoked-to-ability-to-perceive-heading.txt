1:"$Sreact.fragment"
2:I[52332,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"default"]
3:I[65380,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"AuthProvider"]
4:I[41627,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"FirebaseProvider"]
5:"$Sreact.suspense"
6:I[92114,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"SearchProvider"]
7:I[94049,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"default"]
8:I[20190,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"default"]
9:I[9766,[],""]
a:I[98924,[],""]
b:I[74744,["9692","static/js/9692.83f9877c.js","421","static/js/421.98ca62d9.js","1759","static/js/1759.b13f3ee1.js","3535","static/js/3535.878ceef2.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","574","static/js/574.fd20103e.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.7ef30b9e.js"],"ToastContainer"]
d:I[24431,[],"OutletBoundary"]
f:I[15278,[],"AsyncMetadataOutlet"]
11:I[24431,[],"ViewportBoundary"]
14:I[57150,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/e446a64f2ff89daf.css","style"]
0:{"P":null,"b":"WLCgvrrdknkKZDhW-WCbK","p":"/search","c":["","items","ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/e446a64f2ff89daf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":["$","$L6",null,{"children":[["$","$L7",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L8",null,{}],["$","$L7",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$Lb",null,{"position":"bottom-right"}]]}]}]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading","d"],["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":["$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],"$L13"]}],false]],"m":"$undefined","G":["$14",[]],"s":false,"S":true}
15:I[24431,[],"MetadataBoundary"]
13:["$","$L15",null,{"children":["$","div",null,{"hidden":true,"children":["$","$5",null,{"fallback":null,"children":"$L16"}]}]}]
17:I[41402,["9692","static/js/9692.83f9877c.js","1759","static/js/1759.b13f3ee1.js","690","static/js/690.e023e61b.js","3535","static/js/3535.878ceef2.js","5332","static/js/5332.4ca3e6c6.js","2410","static/js/2410.ec36c5aa.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.8a1757af.js","8977","static/js/8977.d520dad7.js","6387","static/js/app/items/%5Bslug%5D/page.0819d17d.js"],""]
18:T1136,{"@context":"https://schema.org/","@type":"Dataset","name":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading","description":"During locomotion humans can judge where they are heading relative to the scene and the movement of objects within the scene.  Both judgements rely on identifying global components of optic flow.  What is the relationship between the perception of heading, and the identification of object movement during self-movement?  Do they rely on a shared mechanism?  One way to address these questions is to compare performance on the two tasks.  We designed stimuli that allowed direct comparison of the precision of heading and object movement judgements.  Across a series of experiments, we found the precision was typically higher when judging scene-relative object movement than when judging heading.  We also found that manipulations of the content of the visual scene can change the relative precision of the two judgements.  These results demonstrate that the ability to judge scene-relative object movement during self-movement is not limited by, or yoked to, the ability to judge the direction of self-movement.\nThe archived data is described in Simon K. Rushton, Rongrong Chen & Li Li (2018). Ability to identify scene-relative object movement is not limited by, or yoked to, ability to perceive heading Journal of Vision, volume 18, issue 6 (see Related Resources).\nA long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain \"compensates\" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing\nThe project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.","url":"https://harmonydata.ac.uk/search/items/ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading","identifier":["http://dx.doi.org/10.5255/UKDA-SN-853037"],"keywords":["OPTIC FLOW","HEADING","FLOW PARSING","HUMAN","PSYCHOPHYSICS","MOTION PERCEPTION"],"temporalCoverage":"2014-08-01/2017-10-31"}c:["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":[["$","$L17",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$18"}}],"$L19"]}]
1a:I[78977,["9692","static/js/9692.83f9877c.js","1759","static/js/1759.b13f3ee1.js","690","static/js/690.e023e61b.js","3535","static/js/3535.878ceef2.js","5332","static/js/5332.4ca3e6c6.js","2410","static/js/2410.ec36c5aa.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.8a1757af.js","8977","static/js/8977.d520dad7.js","6387","static/js/app/items/%5Bslug%5D/page.0819d17d.js"],"default"]
1b:Tf13,During locomotion humans can judge where they are heading relative to the scene and the movement of objects within the scene.  Both judgements rely on identifying global components of optic flow.  What is the relationship between the perception of heading, and the identification of object movement during self-movement?  Do they rely on a shared mechanism?  One way to address these questions is to compare performance on the two tasks.  We designed stimuli that allowed direct comparison of the precision of heading and object movement judgements.  Across a series of experiments, we found the precision was typically higher when judging scene-relative object movement than when judging heading.  We also found that manipulations of the content of the visual scene can change the relative precision of the two judgements.  These results demonstrate that the ability to judge scene-relative object movement during self-movement is not limited by, or yoked to, the ability to judge the direction of self-movement.
The archived data is described in Simon K. Rushton, Rongrong Chen & Li Li (2018). Ability to identify scene-relative object movement is not limited by, or yoked to, ability to perceive heading Journal of Vision, volume 18, issue 6 (see Related Resources).
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.19:["$","$L1a",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading","description":"$1b","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853037","https://reshare.ukdataservice.ac.uk/853037"],"keywords":["OPTIC FLOW","HEADING","FLOW PARSING","HUMAN","PSYCHOPHYSICS","MOTION PERCEPTION"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-853037"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853037"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"},{"@type":"Organization","name":"Serena Yang travel grant from the Psychology Department at The University of Hong Kong"},{"@type":"Organization","name":"Research Grants Council of Hong Kong (HKU 746013H)"},{"@type":"Organization","name":"Shanghai Science and Technology Committee (17ZR1420100)"},{"@type":"Organization","name":"NYU-ECNU Joint Research Institute"}],"temporalCoverage":"2014-08-01/2017-10-31"},"extra_data":{"language_codes":["en"],"harmony_id":"ukds/853037","start_year":2014,"end_year":2017,"data_access":"The Data Collection is available to any user without the requirement for registration for download/access.","urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853037","https://reshare.ukdataservice.ac.uk/853037"],"geographic_coverage":"University of Hong Kong","source":["ukds"],"num_variables":null,"genetic_data_collected":false,"dois":["http://dx.doi.org/10.5255/UKDA-SN-853037"],"sex":"all","study_design":[],"instruments":[],"ai_summary":null,"country_codes":["HK"],"resource_type":"dataset","duration_years":3,"slug":"ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading","name":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading","uuid":"1f05db7a08dc4b3eba8dc98bcf1dbc92"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
1c:Tf13,During locomotion humans can judge where they are heading relative to the scene and the movement of objects within the scene.  Both judgements rely on identifying global components of optic flow.  What is the relationship between the perception of heading, and the identification of object movement during self-movement?  Do they rely on a shared mechanism?  One way to address these questions is to compare performance on the two tasks.  We designed stimuli that allowed direct comparison of the precision of heading and object movement judgements.  Across a series of experiments, we found the precision was typically higher when judging scene-relative object movement than when judging heading.  We also found that manipulations of the content of the visual scene can change the relative precision of the two judgements.  These results demonstrate that the ability to judge scene-relative object movement during self-movement is not limited by, or yoked to, the ability to judge the direction of self-movement.
The archived data is described in Simon K. Rushton, Rongrong Chen & Li Li (2018). Ability to identify scene-relative object movement is not limited by, or yoked to, ability to perceive heading Journal of Vision, volume 18, issue 6 (see Related Resources).
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.10:{"metadata":[["$","title","0",{"children":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading"}],["$","meta","1",{"name":"description","content":"$1c"}],"$L1d","$L1e","$L1f","$L20","$L21","$L22","$L23","$L24","$L25","$L26","$L27","$L28","$L29","$L2a","$L2b","$L2c"],"error":null,"digest":"$undefined"}
2f:I[80622,[],"IconMark"]
1d:["$","meta","2",{"property":"og:title","content":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading"}]
2d:Tf13,During locomotion humans can judge where they are heading relative to the scene and the movement of objects within the scene.  Both judgements rely on identifying global components of optic flow.  What is the relationship between the perception of heading, and the identification of object movement during self-movement?  Do they rely on a shared mechanism?  One way to address these questions is to compare performance on the two tasks.  We designed stimuli that allowed direct comparison of the precision of heading and object movement judgements.  Across a series of experiments, we found the precision was typically higher when judging scene-relative object movement than when judging heading.  We also found that manipulations of the content of the visual scene can change the relative precision of the two judgements.  These results demonstrate that the ability to judge scene-relative object movement during self-movement is not limited by, or yoked to, the ability to judge the direction of self-movement.
The archived data is described in Simon K. Rushton, Rongrong Chen & Li Li (2018). Ability to identify scene-relative object movement is not limited by, or yoked to, ability to perceive heading Journal of Vision, volume 18, issue 6 (see Related Resources).
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.1e:["$","meta","3",{"property":"og:description","content":"$2d"}]
1f:["$","meta","4",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/ability-to-identify-scene-relative-object-movement-is-not-limited-by-or-yoked-to-ability-to-perceive-heading"}]
20:["$","meta","5",{"property":"og:site_name","content":"Academic Resource Discovery"}]
21:["$","meta","6",{"property":"og:locale","content":"en_US"}]
22:["$","meta","7",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}]
23:["$","meta","8",{"property":"og:image:width","content":"1200"}]
24:["$","meta","9",{"property":"og:image:height","content":"630"}]
25:["$","meta","10",{"property":"og:image:alt","content":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading"}]
26:["$","meta","11",{"property":"og:type","content":"website"}]
27:["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}]
28:["$","meta","13",{"name":"twitter:title","content":"Ability to identify scene-relative object movement is not limited\nby, or yoked to, ability to perceive heading"}]
2e:Tf13,During locomotion humans can judge where they are heading relative to the scene and the movement of objects within the scene.  Both judgements rely on identifying global components of optic flow.  What is the relationship between the perception of heading, and the identification of object movement during self-movement?  Do they rely on a shared mechanism?  One way to address these questions is to compare performance on the two tasks.  We designed stimuli that allowed direct comparison of the precision of heading and object movement judgements.  Across a series of experiments, we found the precision was typically higher when judging scene-relative object movement than when judging heading.  We also found that manipulations of the content of the visual scene can change the relative precision of the two judgements.  These results demonstrate that the ability to judge scene-relative object movement during self-movement is not limited by, or yoked to, the ability to judge the direction of self-movement.
The archived data is described in Simon K. Rushton, Rongrong Chen & Li Li (2018). Ability to identify scene-relative object movement is not limited by, or yoked to, ability to perceive heading Journal of Vision, volume 18, issue 6 (see Related Resources).
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.29:["$","meta","14",{"name":"twitter:description","content":"$2e"}]
2a:["$","meta","15",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}]
2b:["$","link","16",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]
2c:["$","$L2f","17",{}]
16:"$10:metadata"
