1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/a38392bd344718e4.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"0Pw2B2A-ctu_hDkpgRDyX","p":"/search","c":["","items","attitudes-towards-emotional-artificial-intelligence-use-transcripts-of-citizen-workshops-collected-using-an-innovative-narrative-approach-2021"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","attitudes-towards-emotional-artificial-intelligence-use-transcripts-of-citizen-workshops-collected-using-an-innovative-narrative-approach-2021","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/a38392bd344718e4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_55b4bf","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","attitudes-towards-emotional-artificial-intelligence-use-transcripts-of-citizen-workshops-collected-using-an-innovative-narrative-approach-2021","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","Lk9RR46mGc_unW4h86TZT",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["3524","static/js/2170a4aa.3678665e.js","6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","1057","static/js/1057.fef3cc4c.js","2282","static/js/2282.e20001b9.js","9234","static/js/9234.7cf96505.js","2926","static/js/2926.76e4f620.js","7511","static/js/7511.a52b23cb.js","8173","static/js/8173.582c8c90.js","613","static/js/613.da2777c4.js","9756","static/js/9756.65c7d9ea.js","97","static/js/97.c5459b6e.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.07f8eb1b.js","9123","static/js/9123.0b9c8079.js","6387","static/js/app/items/%5Bslug%5D/page.e8e51342.js"],""]
14:I[5749,["3524","static/js/2170a4aa.3678665e.js","6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","1057","static/js/1057.fef3cc4c.js","2282","static/js/2282.e20001b9.js","9234","static/js/9234.7cf96505.js","2926","static/js/2926.76e4f620.js","7511","static/js/7511.a52b23cb.js","8173","static/js/8173.582c8c90.js","613","static/js/613.da2777c4.js","9756","static/js/9756.65c7d9ea.js","97","static/js/97.c5459b6e.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.07f8eb1b.js","9123","static/js/9123.0b9c8079.js","6387","static/js/app/items/%5Bslug%5D/page.e8e51342.js"],"default"]
13:T14ff,{"@context":"https://schema.org/","@type":"Dataset","name":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021","description":"The data were collected during citizen workshops, conducted online via Zoom, exploring attitudes towards emotional artificial intelligence use (EAI). EAI is the use of affective computing and AI techniques to try to sense and interact with human emotional life, ranging from monitoring emotions through biometric data to more active interventions. \n10 sets of participants (n=46) were recruited for the following groups:\n\n3 older (65+) groups: n=13\n3 younger (18-34) groups: n=12\n2 groups, people self-identifying as disabled: n=10\n2 groups, members of UK ethnic minorities: n=11\n\nThere was an attempt to balance other demographic categories where possible. \n\nParticipants were grouped in relation to age as this has been shown to be the biggest indicator of differences in attitude towards emotional AI (Bakir & McStay, 2020; McStay, 2020). It was also considered important to include the views of those who have traditionally been ignored in the development of technology or suffered further discrimination through its use, and so the opinions and perspectives of minority groups and disabled people were sought. \n \nParticipants were recruited through a research panel for the workshops, which took place in August 2021. A novel narrative approach was used, with participants taken through a piece of interactive fiction (developed using Twine, viewable here: https://eaitwine.neocities.org/), a day-in-the life story of a protagonist encountering seven mundane use-cases of emotional AI, each structured as a) a neutral introduction to the technology; b) a binary choice involving the use of the technology; c) a ContraVision component demonstrating positive and negative events/outcomes. \nThe use cases were: \n•\tHome-hub smart assistant \n•\tBus station surveillance sensor \n•\tSocial Media Fake news/Disinformation and profiling.  \n•\tSpotify music recommendations (using voice and ambient data). \n•\tSales call evaluation and prompt tool\n•\tEmotoy that collects and responds to children's emotional data. \n•\tHire car in-cabin customisation and driving support. \n\nEach workshop lasted 2 hours. Audio files were transcribed using a transcription service before being corrected and formatted by a project researcher.\n\nReferences:\n\nBakir, V., & McStay, A. (2020). Profiling & Targeting Emotions in Digital Political Campaigns. Briefing Paper for All Party Parliamentary Group on Electoral Campaigning Transparency.\n\nMcStay, A. (2020). Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy. Big Data & Society, 7(1), 1–12. https://doi.org/10.1177/2053951720904386CONTEXT\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs).\n\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\n\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\n\nAIMS/OBJECTIVES\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\n3.","url":"https://harmonydata.ac.uk/search/items/attitudes-towards-emotional-artificial-intelligence-use-transcripts-of-citizen-workshops-collected-using-an-innovative-narrative-approach-2021","identifier":["http://dx.doi.org/10.5255/UKDA-SN-855688"],"keywords":["ATTITUDES","INFORMATION AND COMMUNICATIONS TECHNOLOGY","INTELLIGENCE","EMOTIONAL STATES","AGE"],"temporalCoverage":"2021-08-04/2021-08-13"}15:T1263,The data were collected during citizen workshops, conducted online via Zoom, exploring attitudes towards emotional artificial intelligence use (EAI). EAI is the use of affective computing and AI techniques to try to sense and interact with human emotional life, ranging from monitoring emotions through biometric data to more active interventions. 
10 sets of participants (n=46) were recruited for the following groups:

3 older (65+) groups: n=13
3 younger (18-34) groups: n=12
2 groups, people self-identifying as disabled: n=10
2 groups, members of UK ethnic minorities: n=11

There was an attempt to balance other demographic categories where possible. 

Participants were grouped in relation to age as this has been shown to be the biggest indicator of differences in attitude towards emotional AI (Bakir & McStay, 2020; McStay, 2020). It was also considered important to include the views of those who have traditionally been ignored in the development of technology or suffered further discrimination through its use, and so the opinions and perspectives of minority groups and disabled people were sought. 
 
Participants were recruited through a research panel for the workshops, which took place in August 2021. A novel narrative approach was used, with participants taken through a piece of interactive fiction (developed using Twine, viewable here: https://eaitwine.neocities.org/), a day-in-the life story of a protagonist encountering seven mundane use-cases of emotional AI, each structured as a) a neutral introduction to the technology; b) a binary choice involving the use of the technology; c) a ContraVision component demonstrating positive and negative events/outcomes. 
The use cases were: 
•	Home-hub smart assistant 
•	Bus station surveillance sensor 
•	Social Media Fake news/Disinformation and profiling.  
•	Spotify music recommendations (using voice and ambient data). 
•	Sales call evaluation and prompt tool
•	Emotoy that collects and responds to children's emotional data. 
•	Hire car in-cabin customisation and driving support. 

Each workshop lasted 2 hours. Audio files were transcribed using a transcription service before being corrected and formatted by a project researcher.

References:

Bakir, V., & McStay, A. (2020). Profiling & Targeting Emotions in Digital Political Campaigns. Briefing Paper for All Party Parliamentary Group on Electoral Campaigning Transparency.

McStay, A. (2020). Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy. Big Data & Society, 7(1), 1–12. https://doi.org/10.1177/2053951720904386CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs).

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"dataset":{"title":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021","description":"$15","image":"$undefined","publisher":"$undefined","funders":"$undefined","geographicCoverage":"GB","temporalCoverage":"2021-08-04/2021-08-13","ageCoverage":"$undefined","studyDesign":[],"resourceType":"dataset","topics":["ATTITUDES","INFORMATION AND COMMUNICATIONS TECHNOLOGY","INTELLIGENCE","EMOTIONAL STATES","AGE"],"instruments":[],"dataCatalogs":[{"name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855688","logo":"$undefined"}],"matchedVariables":[],"allVariables":[],"additionalLinks":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855688","https://reshare.ukdataservice.ac.uk/855688","http://dx.doi.org/10.5255/UKDA-SN-855688","http://dx.doi.org/10.5255/UKDA-SN-855688"],"child_datasets":[],"aiSummary":null}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T1263,The data were collected during citizen workshops, conducted online via Zoom, exploring attitudes towards emotional artificial intelligence use (EAI). EAI is the use of affective computing and AI techniques to try to sense and interact with human emotional life, ranging from monitoring emotions through biometric data to more active interventions. 
10 sets of participants (n=46) were recruited for the following groups:

3 older (65+) groups: n=13
3 younger (18-34) groups: n=12
2 groups, people self-identifying as disabled: n=10
2 groups, members of UK ethnic minorities: n=11

There was an attempt to balance other demographic categories where possible. 

Participants were grouped in relation to age as this has been shown to be the biggest indicator of differences in attitude towards emotional AI (Bakir & McStay, 2020; McStay, 2020). It was also considered important to include the views of those who have traditionally been ignored in the development of technology or suffered further discrimination through its use, and so the opinions and perspectives of minority groups and disabled people were sought. 
 
Participants were recruited through a research panel for the workshops, which took place in August 2021. A novel narrative approach was used, with participants taken through a piece of interactive fiction (developed using Twine, viewable here: https://eaitwine.neocities.org/), a day-in-the life story of a protagonist encountering seven mundane use-cases of emotional AI, each structured as a) a neutral introduction to the technology; b) a binary choice involving the use of the technology; c) a ContraVision component demonstrating positive and negative events/outcomes. 
The use cases were: 
•	Home-hub smart assistant 
•	Bus station surveillance sensor 
•	Social Media Fake news/Disinformation and profiling.  
•	Spotify music recommendations (using voice and ambient data). 
•	Sales call evaluation and prompt tool
•	Emotoy that collects and responds to children's emotional data. 
•	Hire car in-cabin customisation and driving support. 

Each workshop lasted 2 hours. Audio files were transcribed using a transcription service before being corrected and formatted by a project researcher.

References:

Bakir, V., & McStay, A. (2020). Profiling & Targeting Emotions in Digital Political Campaigns. Briefing Paper for All Party Parliamentary Group on Electoral Campaigning Transparency.

McStay, A. (2020). Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy. Big Data & Society, 7(1), 1–12. https://doi.org/10.1177/2053951720904386CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs).

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3.17:T1263,The data were collected during citizen workshops, conducted online via Zoom, exploring attitudes towards emotional artificial intelligence use (EAI). EAI is the use of affective computing and AI techniques to try to sense and interact with human emotional life, ranging from monitoring emotions through biometric data to more active interventions. 
10 sets of participants (n=46) were recruited for the following groups:

3 older (65+) groups: n=13
3 younger (18-34) groups: n=12
2 groups, people self-identifying as disabled: n=10
2 groups, members of UK ethnic minorities: n=11

There was an attempt to balance other demographic categories where possible. 

Participants were grouped in relation to age as this has been shown to be the biggest indicator of differences in attitude towards emotional AI (Bakir & McStay, 2020; McStay, 2020). It was also considered important to include the views of those who have traditionally been ignored in the development of technology or suffered further discrimination through its use, and so the opinions and perspectives of minority groups and disabled people were sought. 
 
Participants were recruited through a research panel for the workshops, which took place in August 2021. A novel narrative approach was used, with participants taken through a piece of interactive fiction (developed using Twine, viewable here: https://eaitwine.neocities.org/), a day-in-the life story of a protagonist encountering seven mundane use-cases of emotional AI, each structured as a) a neutral introduction to the technology; b) a binary choice involving the use of the technology; c) a ContraVision component demonstrating positive and negative events/outcomes. 
The use cases were: 
•	Home-hub smart assistant 
•	Bus station surveillance sensor 
•	Social Media Fake news/Disinformation and profiling.  
•	Spotify music recommendations (using voice and ambient data). 
•	Sales call evaluation and prompt tool
•	Emotoy that collects and responds to children's emotional data. 
•	Hire car in-cabin customisation and driving support. 

Each workshop lasted 2 hours. Audio files were transcribed using a transcription service before being corrected and formatted by a project researcher.

References:

Bakir, V., & McStay, A. (2020). Profiling & Targeting Emotions in Digital Political Campaigns. Briefing Paper for All Party Parliamentary Group on Electoral Campaigning Transparency.

McStay, A. (2020). Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy. Big Data & Society, 7(1), 1–12. https://doi.org/10.1177/2053951720904386CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs).

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3.18:T1263,The data were collected during citizen workshops, conducted online via Zoom, exploring attitudes towards emotional artificial intelligence use (EAI). EAI is the use of affective computing and AI techniques to try to sense and interact with human emotional life, ranging from monitoring emotions through biometric data to more active interventions. 
10 sets of participants (n=46) were recruited for the following groups:

3 older (65+) groups: n=13
3 younger (18-34) groups: n=12
2 groups, people self-identifying as disabled: n=10
2 groups, members of UK ethnic minorities: n=11

There was an attempt to balance other demographic categories where possible. 

Participants were grouped in relation to age as this has been shown to be the biggest indicator of differences in attitude towards emotional AI (Bakir & McStay, 2020; McStay, 2020). It was also considered important to include the views of those who have traditionally been ignored in the development of technology or suffered further discrimination through its use, and so the opinions and perspectives of minority groups and disabled people were sought. 
 
Participants were recruited through a research panel for the workshops, which took place in August 2021. A novel narrative approach was used, with participants taken through a piece of interactive fiction (developed using Twine, viewable here: https://eaitwine.neocities.org/), a day-in-the life story of a protagonist encountering seven mundane use-cases of emotional AI, each structured as a) a neutral introduction to the technology; b) a binary choice involving the use of the technology; c) a ContraVision component demonstrating positive and negative events/outcomes. 
The use cases were: 
•	Home-hub smart assistant 
•	Bus station surveillance sensor 
•	Social Media Fake news/Disinformation and profiling.  
•	Spotify music recommendations (using voice and ambient data). 
•	Sales call evaluation and prompt tool
•	Emotoy that collects and responds to children's emotional data. 
•	Hire car in-cabin customisation and driving support. 

Each workshop lasted 2 hours. Audio files were transcribed using a transcription service before being corrected and formatted by a project researcher.

References:

Bakir, V., & McStay, A. (2020). Profiling & Targeting Emotions in Digital Political Campaigns. Briefing Paper for All Party Parliamentary Group on Electoral Campaigning Transparency.

McStay, A. (2020). Emotional AI, soft biometrics and the surveillance of emotional life: An unusual consensus on privacy. Big Data & Society, 7(1), 1–12. https://doi.org/10.1177/2053951720904386CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs).

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/attitudes-towards-emotional-artificial-intelligence-use-transcripts-of-citizen-workshops-collected-using-an-innovative-narrative-approach-2021"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Attitudes Towards Emotional Artificial Intelligence Use: Transcripts of Citizen Workshops Collected Using an Innovative Narrative Approach, 2021"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
