1:"$Sreact.fragment"
2:I[52332,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
3:I[65380,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"AuthProvider"]
4:I[41627,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"FirebaseProvider"]
5:"$Sreact.suspense"
6:I[92114,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"SearchProvider"]
7:I[94049,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
8:I[20190,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
9:I[9766,[],""]
a:I[98924,[],""]
b:I[74744,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"ToastContainer"]
d:I[24431,[],"OutletBoundary"]
f:I[15278,[],"AsyncMetadataOutlet"]
11:I[24431,[],"ViewportBoundary"]
13:I[24431,[],"MetadataBoundary"]
15:I[57150,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/e446a64f2ff89daf.css","style"]
0:{"P":null,"b":"669YHYfowfluJ5cB834U0","p":"/search","c":["","items","connecting-content-and-logical-words-2016-2019"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","connecting-content-and-logical-words-2016-2019","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/e446a64f2ff89daf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":["$","$L6",null,{"children":[["$","$L7",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L8",null,{}],["$","$L7",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$Lb",null,{"position":"bottom-right"}]]}]}]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","connecting-content-and-logical-words-2016-2019","d"],["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":["$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$L13",null,{"children":["$","div",null,{"hidden":true,"children":["$","$5",null,{"fallback":null,"children":"$L14"}]}]}]]}],false]],"m":"$undefined","G":["$15",[]],"s":false,"S":true}
16:I[41402,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","867","static/js/867.7f6bef5e.js","2939","static/js/2939.aa50df5c.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.87b66c06.js","8977","static/js/8977.89625695.js","6387","static/js/app/items/%5Bslug%5D/page.cedc9485.js"],""]
17:T1045,{"@context":"https://schema.org/","@type":"Dataset","name":"Connecting Content and Logical Words, 2016-2019","description":"Content words (e.g. nouns and adjectives) are generally connected: there are no gaps in their denotations; no noun means ‘table or shoe’ or ‘animal or house’. We explore a formulation of connectedness which is applicable to content and logical words alike, and which compares well with the classic notion of monotonicity for quantifiers. On a first inspection, logical words satisfy this generalized version of the connectedness property at least as well as content words do — that is, both in terms of what may be observed in the lexicons of natural languages (although our investigations remain modest in that respect) and in terms of acquisition biases (with an artificial rule learning experiment). This reduces the putative differences between content and logical words, as well as the associated challenges that these differences would pose, e.g., for learners.As anyone who has learnt a foreign language or travelled abroad will have noticed, languages differ in the sounds they employ, the names they give to things, and the rules of grammar. However, linguists have long observed that, beneath this surface diversity, all human languages share a number of fundamental structural similarities. Most obviously, all languages use sounds, all languages have words, and all languages have a grammar. More subtly and more surprisingly, similarities can also be observed in more fine-grained linguistic features: for instance, George Zipf famously observed that, across multiple languages, short words tend also to be more frequent, and in my own recent work I have shown that languages prefer to use words that sound alike (e.g., cat, mat, rat, bat, fat, ...). Why do all languages exhibit these shared features? \nThis project aims to tackle exactly this key question by studying how languages are shaped by the human mind. In particular, I will explore how the way we learn language and use it to communicate drives the emergence of important features of lexicons, the set of all words in a language. To simulate the process of language change and evolution in the lab, I will use an experimental paradigm where an artificial language is passed between learners (language learning), and used by individuals to communicate with each other (language use). This paradigm has been successfully applied in previous research showing that key structural features of language can be explained as a consequence of repeated learning and use; my contribution will be to apply the same methods to study the evolution of the lexicon. I will then use two complementary techniques to evaluate the ecological validity of these results. First, do the artificial lexicons obtained after repeated learning and communication match the structure of lexicons found in real human languages? We will assess this by analyzing real natural language corpora using computational methods. Second, are these lexicons easily learnable by young children, the primary conduit of natural language transmission in the wild? This will be assessed using methods from developmental psychology to study word learning in toddlers.\nThe present project requires an unprecedented integration of techniques and concepts from language evolution, computational linguistics and developmental psychology, three fields that have so far worked independently to understand the structure of language. The outcomes of the project will be of vital interest for all these communities, and will provide insights into the foundational properties found in all human languages, as well as the nature of the constraints underlying language processing and language acquisition. This project will provide a springboard for my future work at the intersection of computational and experimental approaches to language and cognitive development.","url":"https://harmonydata.ac.uk/search/items/connecting-content-and-logical-words-2016-2019","identifier":["http://dx.doi.org/10.5255/UKDA-SN-855112"],"keywords":["LANGUAGE","LEARNING","LINGUISTICS"],"temporalCoverage":"2016-11-01/2019-11-27"}c:["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":[["$","$L16",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$17"}}],"$L18"]}]
19:I[78977,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","867","static/js/867.7f6bef5e.js","2939","static/js/2939.aa50df5c.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.87b66c06.js","8977","static/js/8977.89625695.js","6387","static/js/app/items/%5Bslug%5D/page.cedc9485.js"],"default"]
1a:Ted1,Content words (e.g. nouns and adjectives) are generally connected: there are no gaps in their denotations; no noun means ‘table or shoe’ or ‘animal or house’. We explore a formulation of connectedness which is applicable to content and logical words alike, and which compares well with the classic notion of monotonicity for quantifiers. On a first inspection, logical words satisfy this generalized version of the connectedness property at least as well as content words do — that is, both in terms of what may be observed in the lexicons of natural languages (although our investigations remain modest in that respect) and in terms of acquisition biases (with an artificial rule learning experiment). This reduces the putative differences between content and logical words, as well as the associated challenges that these differences would pose, e.g., for learners.As anyone who has learnt a foreign language or travelled abroad will have noticed, languages differ in the sounds they employ, the names they give to things, and the rules of grammar. However, linguists have long observed that, beneath this surface diversity, all human languages share a number of fundamental structural similarities. Most obviously, all languages use sounds, all languages have words, and all languages have a grammar. More subtly and more surprisingly, similarities can also be observed in more fine-grained linguistic features: for instance, George Zipf famously observed that, across multiple languages, short words tend also to be more frequent, and in my own recent work I have shown that languages prefer to use words that sound alike (e.g., cat, mat, rat, bat, fat, ...). Why do all languages exhibit these shared features? 
This project aims to tackle exactly this key question by studying how languages are shaped by the human mind. In particular, I will explore how the way we learn language and use it to communicate drives the emergence of important features of lexicons, the set of all words in a language. To simulate the process of language change and evolution in the lab, I will use an experimental paradigm where an artificial language is passed between learners (language learning), and used by individuals to communicate with each other (language use). This paradigm has been successfully applied in previous research showing that key structural features of language can be explained as a consequence of repeated learning and use; my contribution will be to apply the same methods to study the evolution of the lexicon. I will then use two complementary techniques to evaluate the ecological validity of these results. First, do the artificial lexicons obtained after repeated learning and communication match the structure of lexicons found in real human languages? We will assess this by analyzing real natural language corpora using computational methods. Second, are these lexicons easily learnable by young children, the primary conduit of natural language transmission in the wild? This will be assessed using methods from developmental psychology to study word learning in toddlers.
The present project requires an unprecedented integration of techniques and concepts from language evolution, computational linguistics and developmental psychology, three fields that have so far worked independently to understand the structure of language. The outcomes of the project will be of vital interest for all these communities, and will provide insights into the foundational properties found in all human languages, as well as the nature of the constraints underlying language processing and language acquisition. This project will provide a springboard for my future work at the intersection of computational and experimental approaches to language and cognitive development.18:["$","$L19",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Connecting Content and Logical Words, 2016-2019","description":"$1a","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855112","https://reshare.ukdataservice.ac.uk/855112"],"keywords":["LANGUAGE","LEARNING","LINGUISTICS"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-855112"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855112"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"}],"temporalCoverage":"2016-11-01/2019-11-27"},"extra_data":{"language_codes":["en"],"harmony_id":"ukds/855112","start_year":2016,"end_year":2019,"data_access":"The Data Collection is available to any user without the requirement for registration for download/access.","urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855112","https://reshare.ukdataservice.ac.uk/855112"],"geographic_coverage":"","source":["ukds"],"slug":"connecting-content-and-logical-words-2016-2019","genetic_data_collected":false,"dois":["http://dx.doi.org/10.5255/UKDA-SN-855112"],"sex":"all","study_design":[],"instruments":[],"ai_summary":null,"resource_type":"dataset","duration_years":3,"country_codes":["GB"],"num_variables":null,"name":"Connecting Content and Logical Words, 2016-2019","uuid":"4c300aff041c6864492edbb25bb36488"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
1b:Ted1,Content words (e.g. nouns and adjectives) are generally connected: there are no gaps in their denotations; no noun means ‘table or shoe’ or ‘animal or house’. We explore a formulation of connectedness which is applicable to content and logical words alike, and which compares well with the classic notion of monotonicity for quantifiers. On a first inspection, logical words satisfy this generalized version of the connectedness property at least as well as content words do — that is, both in terms of what may be observed in the lexicons of natural languages (although our investigations remain modest in that respect) and in terms of acquisition biases (with an artificial rule learning experiment). This reduces the putative differences between content and logical words, as well as the associated challenges that these differences would pose, e.g., for learners.As anyone who has learnt a foreign language or travelled abroad will have noticed, languages differ in the sounds they employ, the names they give to things, and the rules of grammar. However, linguists have long observed that, beneath this surface diversity, all human languages share a number of fundamental structural similarities. Most obviously, all languages use sounds, all languages have words, and all languages have a grammar. More subtly and more surprisingly, similarities can also be observed in more fine-grained linguistic features: for instance, George Zipf famously observed that, across multiple languages, short words tend also to be more frequent, and in my own recent work I have shown that languages prefer to use words that sound alike (e.g., cat, mat, rat, bat, fat, ...). Why do all languages exhibit these shared features? 
This project aims to tackle exactly this key question by studying how languages are shaped by the human mind. In particular, I will explore how the way we learn language and use it to communicate drives the emergence of important features of lexicons, the set of all words in a language. To simulate the process of language change and evolution in the lab, I will use an experimental paradigm where an artificial language is passed between learners (language learning), and used by individuals to communicate with each other (language use). This paradigm has been successfully applied in previous research showing that key structural features of language can be explained as a consequence of repeated learning and use; my contribution will be to apply the same methods to study the evolution of the lexicon. I will then use two complementary techniques to evaluate the ecological validity of these results. First, do the artificial lexicons obtained after repeated learning and communication match the structure of lexicons found in real human languages? We will assess this by analyzing real natural language corpora using computational methods. Second, are these lexicons easily learnable by young children, the primary conduit of natural language transmission in the wild? This will be assessed using methods from developmental psychology to study word learning in toddlers.
The present project requires an unprecedented integration of techniques and concepts from language evolution, computational linguistics and developmental psychology, three fields that have so far worked independently to understand the structure of language. The outcomes of the project will be of vital interest for all these communities, and will provide insights into the foundational properties found in all human languages, as well as the nature of the constraints underlying language processing and language acquisition. This project will provide a springboard for my future work at the intersection of computational and experimental approaches to language and cognitive development.10:{"metadata":[["$","title","0",{"children":"Connecting Content and Logical Words, 2016-2019"}],["$","meta","1",{"name":"description","content":"$1b"}],"$L1c","$L1d","$L1e","$L1f","$L20","$L21","$L22","$L23","$L24","$L25","$L26","$L27","$L28","$L29","$L2a","$L2b"],"error":null,"digest":"$undefined"}
2e:I[80622,[],"IconMark"]
1c:["$","meta","2",{"property":"og:title","content":"Connecting Content and Logical Words, 2016-2019"}]
2c:Ted1,Content words (e.g. nouns and adjectives) are generally connected: there are no gaps in their denotations; no noun means ‘table or shoe’ or ‘animal or house’. We explore a formulation of connectedness which is applicable to content and logical words alike, and which compares well with the classic notion of monotonicity for quantifiers. On a first inspection, logical words satisfy this generalized version of the connectedness property at least as well as content words do — that is, both in terms of what may be observed in the lexicons of natural languages (although our investigations remain modest in that respect) and in terms of acquisition biases (with an artificial rule learning experiment). This reduces the putative differences between content and logical words, as well as the associated challenges that these differences would pose, e.g., for learners.As anyone who has learnt a foreign language or travelled abroad will have noticed, languages differ in the sounds they employ, the names they give to things, and the rules of grammar. However, linguists have long observed that, beneath this surface diversity, all human languages share a number of fundamental structural similarities. Most obviously, all languages use sounds, all languages have words, and all languages have a grammar. More subtly and more surprisingly, similarities can also be observed in more fine-grained linguistic features: for instance, George Zipf famously observed that, across multiple languages, short words tend also to be more frequent, and in my own recent work I have shown that languages prefer to use words that sound alike (e.g., cat, mat, rat, bat, fat, ...). Why do all languages exhibit these shared features? 
This project aims to tackle exactly this key question by studying how languages are shaped by the human mind. In particular, I will explore how the way we learn language and use it to communicate drives the emergence of important features of lexicons, the set of all words in a language. To simulate the process of language change and evolution in the lab, I will use an experimental paradigm where an artificial language is passed between learners (language learning), and used by individuals to communicate with each other (language use). This paradigm has been successfully applied in previous research showing that key structural features of language can be explained as a consequence of repeated learning and use; my contribution will be to apply the same methods to study the evolution of the lexicon. I will then use two complementary techniques to evaluate the ecological validity of these results. First, do the artificial lexicons obtained after repeated learning and communication match the structure of lexicons found in real human languages? We will assess this by analyzing real natural language corpora using computational methods. Second, are these lexicons easily learnable by young children, the primary conduit of natural language transmission in the wild? This will be assessed using methods from developmental psychology to study word learning in toddlers.
The present project requires an unprecedented integration of techniques and concepts from language evolution, computational linguistics and developmental psychology, three fields that have so far worked independently to understand the structure of language. The outcomes of the project will be of vital interest for all these communities, and will provide insights into the foundational properties found in all human languages, as well as the nature of the constraints underlying language processing and language acquisition. This project will provide a springboard for my future work at the intersection of computational and experimental approaches to language and cognitive development.1d:["$","meta","3",{"property":"og:description","content":"$2c"}]
1e:["$","meta","4",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/connecting-content-and-logical-words-2016-2019"}]
1f:["$","meta","5",{"property":"og:site_name","content":"Academic Resource Discovery"}]
20:["$","meta","6",{"property":"og:locale","content":"en_US"}]
21:["$","meta","7",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}]
22:["$","meta","8",{"property":"og:image:width","content":"1200"}]
23:["$","meta","9",{"property":"og:image:height","content":"630"}]
24:["$","meta","10",{"property":"og:image:alt","content":"Connecting Content and Logical Words, 2016-2019"}]
25:["$","meta","11",{"property":"og:type","content":"website"}]
26:["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}]
27:["$","meta","13",{"name":"twitter:title","content":"Connecting Content and Logical Words, 2016-2019"}]
2d:Ted1,Content words (e.g. nouns and adjectives) are generally connected: there are no gaps in their denotations; no noun means ‘table or shoe’ or ‘animal or house’. We explore a formulation of connectedness which is applicable to content and logical words alike, and which compares well with the classic notion of monotonicity for quantifiers. On a first inspection, logical words satisfy this generalized version of the connectedness property at least as well as content words do — that is, both in terms of what may be observed in the lexicons of natural languages (although our investigations remain modest in that respect) and in terms of acquisition biases (with an artificial rule learning experiment). This reduces the putative differences between content and logical words, as well as the associated challenges that these differences would pose, e.g., for learners.As anyone who has learnt a foreign language or travelled abroad will have noticed, languages differ in the sounds they employ, the names they give to things, and the rules of grammar. However, linguists have long observed that, beneath this surface diversity, all human languages share a number of fundamental structural similarities. Most obviously, all languages use sounds, all languages have words, and all languages have a grammar. More subtly and more surprisingly, similarities can also be observed in more fine-grained linguistic features: for instance, George Zipf famously observed that, across multiple languages, short words tend also to be more frequent, and in my own recent work I have shown that languages prefer to use words that sound alike (e.g., cat, mat, rat, bat, fat, ...). Why do all languages exhibit these shared features? 
This project aims to tackle exactly this key question by studying how languages are shaped by the human mind. In particular, I will explore how the way we learn language and use it to communicate drives the emergence of important features of lexicons, the set of all words in a language. To simulate the process of language change and evolution in the lab, I will use an experimental paradigm where an artificial language is passed between learners (language learning), and used by individuals to communicate with each other (language use). This paradigm has been successfully applied in previous research showing that key structural features of language can be explained as a consequence of repeated learning and use; my contribution will be to apply the same methods to study the evolution of the lexicon. I will then use two complementary techniques to evaluate the ecological validity of these results. First, do the artificial lexicons obtained after repeated learning and communication match the structure of lexicons found in real human languages? We will assess this by analyzing real natural language corpora using computational methods. Second, are these lexicons easily learnable by young children, the primary conduit of natural language transmission in the wild? This will be assessed using methods from developmental psychology to study word learning in toddlers.
The present project requires an unprecedented integration of techniques and concepts from language evolution, computational linguistics and developmental psychology, three fields that have so far worked independently to understand the structure of language. The outcomes of the project will be of vital interest for all these communities, and will provide insights into the foundational properties found in all human languages, as well as the nature of the constraints underlying language processing and language acquisition. This project will provide a springboard for my future work at the intersection of computational and experimental approaches to language and cognitive development.28:["$","meta","14",{"name":"twitter:description","content":"$2d"}]
29:["$","meta","15",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}]
2a:["$","link","16",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]
2b:["$","$L2e","17",{}]
14:"$10:metadata"
