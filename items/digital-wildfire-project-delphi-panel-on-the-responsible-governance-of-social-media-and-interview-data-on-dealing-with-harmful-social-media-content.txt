1:"$Sreact.fragment"
2:I[82104,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
3:I[10683,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"AuthProvider"]
4:I[63612,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"SearchProvider"]
5:I[68998,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
6:I[98904,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/138a3164b4c9e92c.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"j27aFvxleOaSSzL4BSwDK","p":"/search","c":["","items","digital-wildfire-project-delphi-panel-on-the-responsible-governance-of-social-media-and-interview-data-on-dealing-with-harmful-social-media-content"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","digital-wildfire-project-delphi-panel-on-the-responsible-governance-of-social-media-and-interview-data-on-dealing-with-harmful-social-media-content","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/138a3164b4c9e92c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_62a302","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","digital-wildfire-project-delphi-panel-on-the-responsible-governance-of-social-media-and-interview-data-on-dealing-with-harmful-social-media-content","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","451bhyacOpq1J_uv4Apao",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","2154","static/chunks/834cb1aa-fe75579b2a50baac.js","3524","static/chunks/2170a4aa-66be1631595ccab0.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","1057","static/chunks/1057-d97430463abd6821.js","2282","static/chunks/2282-26bc5318a4471ee9.js","9234","static/chunks/9234-fce85e807baa599f.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","5733","static/chunks/5733-d0ad15157d7394e5.js","8173","static/chunks/8173-30737ce2fc776efb.js","613","static/chunks/613-3467f3d6fe7e6e6a.js","9756","static/chunks/9756-90c6220c809c4148.js","8738","static/chunks/8738-58586275b0d791e8.js","2649","static/chunks/2649-8ae63f8e6332939b.js","511","static/chunks/511-036317be30af8955.js","1857","static/chunks/1857-99747bd4076c313b.js","2288","static/chunks/2288-c4f1c38c0cd98db5.js","6387","static/chunks/app/items/%5Bslug%5D/page-50b1faaba0d4435c.js"],""]
14:I[5749,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","2154","static/chunks/834cb1aa-fe75579b2a50baac.js","3524","static/chunks/2170a4aa-66be1631595ccab0.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","1057","static/chunks/1057-d97430463abd6821.js","2282","static/chunks/2282-26bc5318a4471ee9.js","9234","static/chunks/9234-fce85e807baa599f.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","5733","static/chunks/5733-d0ad15157d7394e5.js","8173","static/chunks/8173-30737ce2fc776efb.js","613","static/chunks/613-3467f3d6fe7e6e6a.js","9756","static/chunks/9756-90c6220c809c4148.js","8738","static/chunks/8738-58586275b0d791e8.js","2649","static/chunks/2649-8ae63f8e6332939b.js","511","static/chunks/511-036317be30af8955.js","1857","static/chunks/1857-99747bd4076c313b.js","2288","static/chunks/2288-c4f1c38c0cd98db5.js","6387","static/chunks/app/items/%5Bslug%5D/page-50b1faaba0d4435c.js"],"default"]
13:T151c,{"@context":"https://schema.org/","@type":"Dataset","name":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content","description":"Transcripts of fieldwork interviews with professionals involved in the governance of social media communications. These interviews involve professionals revealing how the organisations they work for deal with various forms of harmful content on social media (rumour, hate speech etc.). \nData from an online Delphi panel have also been deposited into the Oxford ORA archive. This Delphi panel sought the opinion of informed experts on the appropriate governance of social media. These data are under embargo until February 2018 and will become available under the T&Cs of the Oxford ORA archive (see Related Resources). \n\nThe project investigated the spread of harmful content on social media and identified opportunities for the responsible governance of digital social spaces. As a collaborative team of computer scientists, social scientists and ethicists, we investigate the impacts that content such as rumour, hate speech and malicious campaigns can have on individuals, groups and communities and examine social media data to identify forms of ‘self-governance’ through which social media users can manage their own and others’ online behaviours. We also draw on the perspectives other key players such as social media companies, legislators, the police, civil liberties groups and educators to explore ways in which the spread of harmful social media content might be prevented, limited or managed. The project will produce a number of practical outputs including an online social media safety resource and a set of teaching and learning materials for schools and young people. This includes our video animation #TakeCareOfYourDigitalSelf. \nProject data have been archived barring exclusions. We have not archived social media posts data collected via the Twitter API. This is because the Twitter T&C, and our own project best practice guidelines, restrict archiving to Tweet IDs (rather than the content of tweets) and these were not gathered in our data collection.  The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called \"digital wildfires\". A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting \"fire!\" in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.\n \nThis project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.\n \nDrawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media.","url":"https://harmonydata.ac.uk/search/items/digital-wildfire-project-delphi-panel-on-the-responsible-governance-of-social-media-and-interview-data-on-dealing-with-harmful-social-media-content","identifier":["http://dx.doi.org/10.5255/UKDA-SN-852794"],"keywords":["SOCIAL MEDIA","DELPHI PANEL QUESTIONNAIRE","INTERNET GOVERNANCE","QUALITATIVE INTERVIEWS"],"temporalCoverage":"2015-01-01/2016-03-01"}15:T129d,Transcripts of fieldwork interviews with professionals involved in the governance of social media communications. These interviews involve professionals revealing how the organisations they work for deal with various forms of harmful content on social media (rumour, hate speech etc.). 
Data from an online Delphi panel have also been deposited into the Oxford ORA archive. This Delphi panel sought the opinion of informed experts on the appropriate governance of social media. These data are under embargo until February 2018 and will become available under the T&Cs of the Oxford ORA archive (see Related Resources). 

The project investigated the spread of harmful content on social media and identified opportunities for the responsible governance of digital social spaces. As a collaborative team of computer scientists, social scientists and ethicists, we investigate the impacts that content such as rumour, hate speech and malicious campaigns can have on individuals, groups and communities and examine social media data to identify forms of ‘self-governance’ through which social media users can manage their own and others’ online behaviours. We also draw on the perspectives other key players such as social media companies, legislators, the police, civil liberties groups and educators to explore ways in which the spread of harmful social media content might be prevented, limited or managed. The project will produce a number of practical outputs including an online social media safety resource and a set of teaching and learning materials for schools and young people. This includes our video animation #TakeCareOfYourDigitalSelf. 
Project data have been archived barring exclusions. We have not archived social media posts data collected via the Twitter API. This is because the Twitter T&C, and our own project best practice guidelines, restrict archiving to Tweet IDs (rather than the content of tweets) and these were not gathered in our data collection.  The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called "digital wildfires". A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting "fire!" in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.
 
This project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.
 
Drawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"dataset":{"title":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content","description":"$15","image":"$undefined","publisher":"$undefined","funders":"$undefined","geographicCoverage":"GB","temporalCoverage":"2015-01-01/2016-03-01","ageCoverage":"$undefined","studyDesign":[],"resourceType":"dataset","topics":["SOCIAL MEDIA","DELPHI PANEL QUESTIONNAIRE","INTERNET GOVERNANCE","QUALITATIVE INTERVIEWS"],"instruments":[],"dataCatalogs":[{"name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852794","logo":"$undefined"}],"matchedVariables":[],"allVariables":[],"additionalLinks":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852794","https://reshare.ukdataservice.ac.uk/852794","http://dx.doi.org/10.5255/UKDA-SN-852794","http://dx.doi.org/10.5255/UKDA-SN-852794"],"child_datasets":[],"aiSummary":null}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T129d,Transcripts of fieldwork interviews with professionals involved in the governance of social media communications. These interviews involve professionals revealing how the organisations they work for deal with various forms of harmful content on social media (rumour, hate speech etc.). 
Data from an online Delphi panel have also been deposited into the Oxford ORA archive. This Delphi panel sought the opinion of informed experts on the appropriate governance of social media. These data are under embargo until February 2018 and will become available under the T&Cs of the Oxford ORA archive (see Related Resources). 

The project investigated the spread of harmful content on social media and identified opportunities for the responsible governance of digital social spaces. As a collaborative team of computer scientists, social scientists and ethicists, we investigate the impacts that content such as rumour, hate speech and malicious campaigns can have on individuals, groups and communities and examine social media data to identify forms of ‘self-governance’ through which social media users can manage their own and others’ online behaviours. We also draw on the perspectives other key players such as social media companies, legislators, the police, civil liberties groups and educators to explore ways in which the spread of harmful social media content might be prevented, limited or managed. The project will produce a number of practical outputs including an online social media safety resource and a set of teaching and learning materials for schools and young people. This includes our video animation #TakeCareOfYourDigitalSelf. 
Project data have been archived barring exclusions. We have not archived social media posts data collected via the Twitter API. This is because the Twitter T&C, and our own project best practice guidelines, restrict archiving to Tweet IDs (rather than the content of tweets) and these were not gathered in our data collection.  The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called "digital wildfires". A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting "fire!" in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.
 
This project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.
 
Drawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media.17:T129d,Transcripts of fieldwork interviews with professionals involved in the governance of social media communications. These interviews involve professionals revealing how the organisations they work for deal with various forms of harmful content on social media (rumour, hate speech etc.). 
Data from an online Delphi panel have also been deposited into the Oxford ORA archive. This Delphi panel sought the opinion of informed experts on the appropriate governance of social media. These data are under embargo until February 2018 and will become available under the T&Cs of the Oxford ORA archive (see Related Resources). 

The project investigated the spread of harmful content on social media and identified opportunities for the responsible governance of digital social spaces. As a collaborative team of computer scientists, social scientists and ethicists, we investigate the impacts that content such as rumour, hate speech and malicious campaigns can have on individuals, groups and communities and examine social media data to identify forms of ‘self-governance’ through which social media users can manage their own and others’ online behaviours. We also draw on the perspectives other key players such as social media companies, legislators, the police, civil liberties groups and educators to explore ways in which the spread of harmful social media content might be prevented, limited or managed. The project will produce a number of practical outputs including an online social media safety resource and a set of teaching and learning materials for schools and young people. This includes our video animation #TakeCareOfYourDigitalSelf. 
Project data have been archived barring exclusions. We have not archived social media posts data collected via the Twitter API. This is because the Twitter T&C, and our own project best practice guidelines, restrict archiving to Tweet IDs (rather than the content of tweets) and these were not gathered in our data collection.  The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called "digital wildfires". A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting "fire!" in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.
 
This project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.
 
Drawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media.18:T129d,Transcripts of fieldwork interviews with professionals involved in the governance of social media communications. These interviews involve professionals revealing how the organisations they work for deal with various forms of harmful content on social media (rumour, hate speech etc.). 
Data from an online Delphi panel have also been deposited into the Oxford ORA archive. This Delphi panel sought the opinion of informed experts on the appropriate governance of social media. These data are under embargo until February 2018 and will become available under the T&Cs of the Oxford ORA archive (see Related Resources). 

The project investigated the spread of harmful content on social media and identified opportunities for the responsible governance of digital social spaces. As a collaborative team of computer scientists, social scientists and ethicists, we investigate the impacts that content such as rumour, hate speech and malicious campaigns can have on individuals, groups and communities and examine social media data to identify forms of ‘self-governance’ through which social media users can manage their own and others’ online behaviours. We also draw on the perspectives other key players such as social media companies, legislators, the police, civil liberties groups and educators to explore ways in which the spread of harmful social media content might be prevented, limited or managed. The project will produce a number of practical outputs including an online social media safety resource and a set of teaching and learning materials for schools and young people. This includes our video animation #TakeCareOfYourDigitalSelf. 
Project data have been archived barring exclusions. We have not archived social media posts data collected via the Twitter API. This is because the Twitter T&C, and our own project best practice guidelines, restrict archiving to Tweet IDs (rather than the content of tweets) and these were not gathered in our data collection.  The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called "digital wildfires". A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting "fire!" in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.
 
This project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.
 
Drawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/digital-wildfire-project-delphi-panel-on-the-responsible-governance-of-social-media-and-interview-data-on-dealing-with-harmful-social-media-content"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Digital Wildfire project: Delphi panel on the responsible governance of social media and interview data on dealing with harmful social media content"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
