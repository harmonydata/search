1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"NBnKkaoo4RAq1PW5uP7se","p":"/search","c":["","items","discourse-processing-in-poor-comprehenders-an-eye-movement-study"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","discourse-processing-in-poor-comprehenders-an-eye-movement-study","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","discourse-processing-in-poor-comprehenders-an-eye-movement-study","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",null,["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","LoZ-3yf-QKgNGaiPgc63j",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],""]
14:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],"default"]
13:T856,{"@context":"https://schema.org/","@type":"Dataset","name":"Discourse processing in poor comprehenders: An eye movement study","description":"These data are from an eye movement experiment examining the effect of semantic typicality and distance on online anaphor resolution during reading in children, and the extent to which individual differences in reading comprehension and working memory influence the pattern of effects observed in the eye movement data. \n\nThe .csv data file contains all eye movement measures for each region of text (Regions 1-7 for each eye movement measure; columns in the data file are labelled accordingly), plus measures of decoding efficiency (TOWRE in the data file), reading comprehension (YARC5 in the data file) and working memory (AWMA in the data file) for each participant. Reading is a crucial skill for success in today’s society, the ultimate goal of which is to extract meaning from written text. However, approximately 10 per cent of 7-11 year olds in mainstream schools have specific difficulties with reading comprehension, despite age-appropriate levels of reading accuracy, fluency, and phonological skills, placing them at increased risk of poor educational attainment.\nAlthough we know that poor comprehenders’ difficulties lie with sentence and discourse-level processing (rather than word-level processing), critically, we do not know why discourse comprehension fails. Identifying the reason for comprehension failure is essential if the specificity of text comprehension training with this population is to be improved.\nThe proposed research will monitor poor comprehenders’ eye movements as they read discourse in order to assess their moment-to-moment understanding of written language in real time, thus elucidating exactly when and why comprehension fails and pointing the way to appropriate intervention.","url":"https://harmonydata.ac.uk/search/items/discourse-processing-in-poor-comprehenders-an-eye-movement-study","identifier":["http://dx.doi.org/10.5255/UKDA-SN-851030"],"keywords":["READING COMPREHENSION","MEMORY"],"temporalCoverage":"2011-09-01/2013-05-30"}15:T6bf,These data are from an eye movement experiment examining the effect of semantic typicality and distance on online anaphor resolution during reading in children, and the extent to which individual differences in reading comprehension and working memory influence the pattern of effects observed in the eye movement data. 

The .csv data file contains all eye movement measures for each region of text (Regions 1-7 for each eye movement measure; columns in the data file are labelled accordingly), plus measures of decoding efficiency (TOWRE in the data file), reading comprehension (YARC5 in the data file) and working memory (AWMA in the data file) for each participant. Reading is a crucial skill for success in today’s society, the ultimate goal of which is to extract meaning from written text. However, approximately 10 per cent of 7-11 year olds in mainstream schools have specific difficulties with reading comprehension, despite age-appropriate levels of reading accuracy, fluency, and phonological skills, placing them at increased risk of poor educational attainment.
Although we know that poor comprehenders’ difficulties lie with sentence and discourse-level processing (rather than word-level processing), critically, we do not know why discourse comprehension fails. Identifying the reason for comprehension failure is essential if the specificity of text comprehension training with this population is to be improved.
The proposed research will monitor poor comprehenders’ eye movements as they read discourse in order to assess their moment-to-moment understanding of written language in real time, thus elucidating exactly when and why comprehension fails and pointing the way to appropriate intervention.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Discourse processing in poor comprehenders: An eye movement study","description":"$15","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851030","https://reshare.ukdataservice.ac.uk/851030"],"keywords":["READING COMPREHENSION","MEMORY"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-851030"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851030"}],"sponsor":[{"@type":"Organization","name":"ESRC"}],"temporalCoverage":"2011-09-01/2013-05-30"},"extra_data":{"study_design":[],"urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851030","https://reshare.ukdataservice.ac.uk/851030"],"dois":["http://dx.doi.org/10.5255/UKDA-SN-851030"],"ai_summary":null,"duration_years":2,"name":"Discourse processing in poor comprehenders: An eye movement study","num_variables":null,"country_codes":["GB"],"sex":"male","genetic_data_collected":false,"geographic_coverage":"","resource_type":"dataset","source":["ukds"],"start_year":2011,"language_codes":["en"],"instruments":[],"slug":"discourse-processing-in-poor-comprehenders-an-eye-movement-study","harmony_id":"ukds/851030","data_access":"The Data Collection is available for download to users registered with the UK Data Service.","end_year":2013,"uuid":"8e2d6217e8e9b9ce36cb00dfc9ce0951"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T6bf,These data are from an eye movement experiment examining the effect of semantic typicality and distance on online anaphor resolution during reading in children, and the extent to which individual differences in reading comprehension and working memory influence the pattern of effects observed in the eye movement data. 

The .csv data file contains all eye movement measures for each region of text (Regions 1-7 for each eye movement measure; columns in the data file are labelled accordingly), plus measures of decoding efficiency (TOWRE in the data file), reading comprehension (YARC5 in the data file) and working memory (AWMA in the data file) for each participant. Reading is a crucial skill for success in today’s society, the ultimate goal of which is to extract meaning from written text. However, approximately 10 per cent of 7-11 year olds in mainstream schools have specific difficulties with reading comprehension, despite age-appropriate levels of reading accuracy, fluency, and phonological skills, placing them at increased risk of poor educational attainment.
Although we know that poor comprehenders’ difficulties lie with sentence and discourse-level processing (rather than word-level processing), critically, we do not know why discourse comprehension fails. Identifying the reason for comprehension failure is essential if the specificity of text comprehension training with this population is to be improved.
The proposed research will monitor poor comprehenders’ eye movements as they read discourse in order to assess their moment-to-moment understanding of written language in real time, thus elucidating exactly when and why comprehension fails and pointing the way to appropriate intervention.17:T6bf,These data are from an eye movement experiment examining the effect of semantic typicality and distance on online anaphor resolution during reading in children, and the extent to which individual differences in reading comprehension and working memory influence the pattern of effects observed in the eye movement data. 

The .csv data file contains all eye movement measures for each region of text (Regions 1-7 for each eye movement measure; columns in the data file are labelled accordingly), plus measures of decoding efficiency (TOWRE in the data file), reading comprehension (YARC5 in the data file) and working memory (AWMA in the data file) for each participant. Reading is a crucial skill for success in today’s society, the ultimate goal of which is to extract meaning from written text. However, approximately 10 per cent of 7-11 year olds in mainstream schools have specific difficulties with reading comprehension, despite age-appropriate levels of reading accuracy, fluency, and phonological skills, placing them at increased risk of poor educational attainment.
Although we know that poor comprehenders’ difficulties lie with sentence and discourse-level processing (rather than word-level processing), critically, we do not know why discourse comprehension fails. Identifying the reason for comprehension failure is essential if the specificity of text comprehension training with this population is to be improved.
The proposed research will monitor poor comprehenders’ eye movements as they read discourse in order to assess their moment-to-moment understanding of written language in real time, thus elucidating exactly when and why comprehension fails and pointing the way to appropriate intervention.18:T6bf,These data are from an eye movement experiment examining the effect of semantic typicality and distance on online anaphor resolution during reading in children, and the extent to which individual differences in reading comprehension and working memory influence the pattern of effects observed in the eye movement data. 

The .csv data file contains all eye movement measures for each region of text (Regions 1-7 for each eye movement measure; columns in the data file are labelled accordingly), plus measures of decoding efficiency (TOWRE in the data file), reading comprehension (YARC5 in the data file) and working memory (AWMA in the data file) for each participant. Reading is a crucial skill for success in today’s society, the ultimate goal of which is to extract meaning from written text. However, approximately 10 per cent of 7-11 year olds in mainstream schools have specific difficulties with reading comprehension, despite age-appropriate levels of reading accuracy, fluency, and phonological skills, placing them at increased risk of poor educational attainment.
Although we know that poor comprehenders’ difficulties lie with sentence and discourse-level processing (rather than word-level processing), critically, we do not know why discourse comprehension fails. Identifying the reason for comprehension failure is essential if the specificity of text comprehension training with this population is to be improved.
The proposed research will monitor poor comprehenders’ eye movements as they read discourse in order to assess their moment-to-moment understanding of written language in real time, thus elucidating exactly when and why comprehension fails and pointing the way to appropriate intervention.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Discourse processing in poor comprehenders: An eye movement study"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Discourse processing in poor comprehenders: An eye movement study"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/discourse-processing-in-poor-comprehenders-an-eye-movement-study"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Discourse processing in poor comprehenders: An eye movement study"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Discourse processing in poor comprehenders: An eye movement study"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
