<!DOCTYPE html><!--669YHYfowfluJ5cB834U0--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/e446a64f2ff89daf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.1a25c7f6.js"/><script src="/search/_next/static/js/4bd1b696.100b9d70.js" async=""></script><script src="/search/_next/static/js/1255.90e9842b.js" async=""></script><script src="/search/_next/static/js/main-app.0e7376d5.js" async=""></script><script src="/search/_next/static/js/9692.83f9877c.js" async=""></script><script src="/search/_next/static/js/1828.31087444.js" async=""></script><script src="/search/_next/static/js/7213.f8248d79.js" async=""></script><script src="/search/_next/static/js/690.e023e61b.js" async=""></script><script src="/search/_next/static/js/7133.521b2ecd.js" async=""></script><script src="/search/_next/static/js/9829.124a89b0.js" async=""></script><script src="/search/_next/static/js/2619.b8db57ac.js" async=""></script><script src="/search/_next/static/js/3820.af314958.js" async=""></script><script src="/search/_next/static/js/5906.206ff298.js" async=""></script><script src="/search/_next/static/js/5738.d28a9943.js" async=""></script><script src="/search/_next/static/js/app/layout.079f6f03.js" async=""></script><script src="/search/_next/static/js/867.7f6bef5e.js" async=""></script><script src="/search/_next/static/js/2939.aa50df5c.js" async=""></script><script src="/search/_next/static/js/5183.9f1a7545.js" async=""></script><script src="/search/_next/static/js/3055.87b66c06.js" async=""></script><script src="/search/_next/static/js/8977.89625695.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.cedc9485.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021</title><meta name="description" content="This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d&#x27; index from Signal Detection Theory. 
Below is a summary of the study and its rationale:
Dual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot&#x27;s ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.
The first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.
The second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. 
The third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."/><meta property="og:title" content="Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021"/><meta property="og:description" content="This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d&#x27; index from Signal Detection Theory. 
Below is a summary of the study and its rationale:
Dual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot&#x27;s ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.
The first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.
The second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. 
The third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021"/><meta name="twitter:description" content="This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d&#x27; index from Signal Detection Theory. 
Below is a summary of the study and its rationale:
Dual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot&#x27;s ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.
The first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.
The second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. 
The third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><div hidden=""><!--$--><!--/$--></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.1a25c7f6.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[52332,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n3:I[65380,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"AuthProvider\"]\n4:I[41627,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[92114,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"SearchProvider\"]\n7:I[94049,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958."])</script><script>self.__next_f.push([1,"js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n8:I[20190,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n9:I[9766,[],\"\"]\na:I[98924,[],\"\"]\nb:I[74744,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"ToastContainer\"]\nd:I[24431,[],\"OutletBoundary\"]\nf:I[15278,[],\"AsyncMetadataOutlet\"]\n11:I[24431,[],\"ViewportBoundary\"]\n14:I[57150,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/e446a64f2ff89daf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"669YHYfowfluJ5cB834U0\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/e446a64f2ff89daf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",[\"$\",\"$Lf\",null,{\"promise\":\"$@10\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],\"$L13\"]}],false]],\"m\":\"$undefined\",\"G\":[\"$14\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"15:I[24431,[],\"MetadataBoundary\"]\n13:[\"$\",\"$L15\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$5\",null,{\"fallback\":null,\"children\":\"$L16\"}]}]}]\n"])</script><script>self.__next_f.push([1,"17:I[41402,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"\"]\n18:T14b5,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\",\"description\":\"This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d' index from Signal Detection Theory. \\nBelow is a summary of the study and its rationale:\\nDual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot's ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.\\nThe first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.\\nThe second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. \\nThe third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance.\",\"url\":\"https://harmonydata.ac.uk/search/items/discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-854727\"],\"keywords\":[\"SPEECH\",\"PERCEPTUAL PROCESSES\",\"COGNITIVE PROCESSES\"],\"temporalCoverage\":\"2018-06-01/2021-01-31\"}"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L17\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$18\"}}],\"$L19\"]}]\n"])</script><script>self.__next_f.push([1,"1a:I[78977,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"default\"]\n1b:T12ac,"])</script><script>self.__next_f.push([1,"This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d' index from Signal Detection Theory. \nBelow is a summary of the study and its rationale:\nDual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot's ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.\nThe first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.\nThe second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. \nThe third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."])</script><script>self.__next_f.push([1,"19:[\"$\",\"$L1a\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\",\"description\":\"$1b\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854727\",\"https://reshare.ukdataservice.ac.uk/854727\"],\"keywords\":[\"SPEECH\",\"PERCEPTUAL PROCESSES\",\"COGNITIVE PROCESSES\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-854727\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854727\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"Economic and Social Research Council\"}],\"temporalCoverage\":\"2018-06-01/2021-01-31\"},\"extra_data\":{\"language_codes\":[\"en\"],\"harmony_id\":\"ukds/854727\",\"start_year\":2018,\"end_year\":2021,\"data_access\":\"The Data Collection is available to any user without the requirement for registration for download/access.\",\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854727\",\"https://reshare.ukdataservice.ac.uk/854727\"],\"source\":[\"ukds\"],\"geographic_coverage\":\"\",\"genetic_data_collected\":false,\"num_variables\":null,\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-854727\"],\"sex\":\"all\",\"instruments\":[],\"slug\":\"discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\",\"ai_summary\":null,\"country_codes\":[\"GB\"],\"resource_type\":\"dataset\",\"study_design\":[],\"duration_years\":3,\"name\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\",\"uuid\":\"c4ac6d2b352883ac4fb0d6dcdb4314eb\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"1c:T12ac,"])</script><script>self.__next_f.push([1,"This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d' index from Signal Detection Theory. \nBelow is a summary of the study and its rationale:\nDual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot's ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.\nThe first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.\nThe second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. \nThe third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."])</script><script>self.__next_f.push([1,"10:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$1c\"}],\"$L1d\",\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\"],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"2f:I[80622,[],\"IconMark\"]\n1d:[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\"}]\n2d:T12ac,"])</script><script>self.__next_f.push([1,"This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d' index from Signal Detection Theory. \nBelow is a summary of the study and its rationale:\nDual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot's ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.\nThe first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.\nThe second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. \nThe third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."])</script><script>self.__next_f.push([1,"1e:[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"$2d\"}]\n1f:[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/discrimination-thresholds-of-duration-intensity-and-f0-for-a-synthesized-vowel-under-cognitive-load-2018-2021\"}]\n20:[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}]\n21:[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}]\n22:[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n23:[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}]\n24:[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}]\n25:[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\"}]\n26:[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}]\n27:[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}]\n28:[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Discrimination Thresholds of Duration, Intensity, and F0 for a Synthesized Vowel under Cognitive Load, 2018-2021\"}]\n2e:T12ac,"])</script><script>self.__next_f.push([1,"This dataset contains measures of just-noticeable differences, or JND, of duration (ms), intensity (dB), and pitch or F0 (Hz) for a synthetic vowel. JNDs were measured under 4 acoustic conditions: (1) Audio-only, i.e., with no secondary task, (2) Perceptual load, i.e., with concurrent visual stimuli but no requirement to pay attention to them, (3) Low cognitive load in the form of a 1-back task on visual stimuli, and (4) High cognitive load in the form of a 2-back task on visual stimuli. In addition, the 1-back and 2-back tasks involved either meaningless images or pronounceable nonwords. Performance on the 1-back and 2-back tasks, labelled CL accuracy, was also measured using the d' index from Signal Detection Theory. \nBelow is a summary of the study and its rationale:\nDual-tasking negatively impacts on speech perception by raising cognitive load (CL). Previous research has shown that CL increases reliance on lexical knowledge and decreases reliance on phonetic detail. Less is known about the effect of CL on the perception of acoustic dimensions below the phonetic level. This study tested the effect of CL on the ability to discriminate differences in duration, intensity, and fundamental frequency of a synthesized vowel. A psychophysical adaptive procedure was used to obtain just noticeable differences (JNDs) on each dimension under load and no load. Load was imposed by N-back tasks at two levels of difficulty (one-back, two-back) and under two types of load (images, nonwords). Compared to a control condition with no CL, all N-back conditions increased JNDs across the three dimensions. JNDs were also higher under two-back than one-back load. Nonword load was marginally more detrimental than image load for intensity and fundamental frequency discrimination. Overall, the decreased auditory acuity demonstrates that the effect of CL on the listening experience can be traced to distortions in the perception of core auditory dimensions.Most theories of human speech perception are derived from tasks performed in a quiet environment and under conditions of undivided attention. However, in the past few years, there has been a surge of interest in modelling speech recognition in more realistic conditions (e.g., noisy background, accented speech). However, among these realistic conditions, those resulting from a cognitive load have received little attention. Here, we define cognitive load (CL) as any listening challenges arising not from a distortion of the speech signal but from the recruitment of processing resources due to concurrent attentional or mnemonic demands. For example, what are the consequences of monitoring cockpit instruments on a pilot's ability to follow spoken instructions from ground control? The disruptive effect of CL on speech perception is noticed as early as in the initial stages of acoustic encoding. Under some circumstances, CL can even lead to a form of transient hearing impairment called inattentional deafness. Despite the obvious implications that these results have for theory and clinical practice, little is known about the low-level mechanisms by which CL interferes with speech perception. The aim of this proposal is to address this issue in three interconnected research streams drawing upon psychometric and identification paradigms.\nThe first stream asks whether CL affects all acoustic dimensions of speech equally. This question is important because not all acoustic dimensions are equally crucial for communication. For example, successful word recognition is more resilient to pitch distortions than duration distortions. The idea that CL affects some dimensions more than others is motivated by the claim that CL (e.g., a concurrent visual task) causes listeners to rapidly shift attention back and forth between the speech signal and the CL task, leading to an underestimation of the duration of the speech signal. If this hypothesis is correct, CL should lead primarily to a distortion of auditory temporal judgements and leave other core dimensions (loudness, pitch, and spectral structure) unaffected. This will be contrasted with the claim that CL leads to a general reduction in auditory precision across all acoustic dimensions.\nThe second stream investigates whether the format of the CL stimuli affects the severity of the CL interference. For example, is speech perception more affected by a concurrent task that requires rehearsing words silently (phonological format) or by a task that requires processing visual stimuli (visual format)? These experiments will address the debate between modal and amodal views of the processing resources used during speech perception. \nThe third stream aims to distinguish two potential mechanisms behind CL interference: Encoding and maintenance."])</script><script>self.__next_f.push([1,"29:[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"$2e\"}]\n2a:[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n2b:[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]\n2c:[\"$\",\"$L2f\",\"17\",{}]\n16:\"$10:metadata\"\n"])</script></body></html>