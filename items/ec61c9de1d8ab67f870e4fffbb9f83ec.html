<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/search/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/2c4d913f25bfc6bf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/chunks/webpack-904c4041abd776f2.js"/><script src="/search/_next/static/chunks/4bd1b696-220750848fc52813.js" async=""></script><script src="/search/_next/static/chunks/1517-45045142ab33e6f1.js" async=""></script><script src="/search/_next/static/chunks/main-app-c0fb4dfbd302de72.js" async=""></script><script src="/search/_next/static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js" async=""></script><script src="/search/_next/static/chunks/f71d1b72-799ff7a6833dc50c.js" async=""></script><script src="/search/_next/static/chunks/6586-1013c110456598c2.js" async=""></script><script src="/search/_next/static/chunks/4889-f0599128dd4090a0.js" async=""></script><script src="/search/_next/static/chunks/9141-d17bf49085d8e296.js" async=""></script><script src="/search/_next/static/chunks/2926-f97573e569b0b5d8.js" async=""></script><script src="/search/_next/static/chunks/8173-30737ce2fc776efb.js" async=""></script><script src="/search/_next/static/chunks/9756-90c6220c809c4148.js" async=""></script><script src="/search/_next/static/chunks/3163-d1a03f172499fcd8.js" async=""></script><script src="/search/_next/static/chunks/app/layout-802ca43371b3eb9d.js" async=""></script><link rel="preload" href="/search/_next/static/css/4921cfd18b262f8c.css" as="style"/><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><title>Visuomotor states of an observer influence person perception: the critical role of emotion</title><meta name="description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta property="og:title" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta property="og:description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta property="og:url" content="https://discoverynext.vercel.app/items/ec61c9de1d8ab67f870e4fffbb9f83ec"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta name="twitter:description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global o39zl1">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback';font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body class="__className_62a302"><script src="/search/_next/static/chunks/webpack-904c4041abd776f2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n3:I[10683,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"AuthProvider\"]\n4:I[63612,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"SearchProvider\"]\n5:I[68998,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"stati"])</script><script>self.__next_f.push([1,"c/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n6:I[98904,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n7:I[15244,[],\"\"]\n8:I[43866,[],\"\"]\n9:I[14046,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"ToastContainer\"]\nb:I[86213,[],\"OutletBoundary\"]\nd:I[86213,[],\"MetadataBoundary\"]\nf:I[86213,[],\"ViewportBoundary\"]\n11:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"style\"]\n:HL[\"/search/_next/static/css/4921cfd18b262f8c.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"8r-g2-FTTcZL6JFFobnJN\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"ec61c9de1d8ab67f870e4fffbb9f83ec\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"ec61c9de1d8ab67f870e4fffbb9f83ec\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}]}],[\"$\",\"body\",null,{\"className\":\"__className_62a302\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[[\"$\",\"$L5\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"$L5\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$L9\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"ec61c9de1d8ab67f870e4fffbb9f83ec\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$La\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/4921cfd18b262f8c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"wNi0n0mwLdnRX3uGatws_\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"div\",null,{\"children\":[[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"window.location.replace('/items/visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion');\"}}],[\"$\",\"p\",null,{\"children\":[\"Redirecting to\",\" \",[\"$\",\"a\",null,{\"href\":\"/items/visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\",\"children\":[\"/items/\",\"visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\"]}],\"...\"]}]]}]\n"])</script><script>self.__next_f.push([1,"12:T728,This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval.13:T728,This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implic"])</script><script>self.__next_f.push([1,"it learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval.14:T728,This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the ma"])</script><script>self.__next_f.push([1,"nuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval.e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$12\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$13\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://discoverynext.vercel.app/items/ec61c9de1d8ab67f870e4fffbb9f83ec\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Di"])</script><script>self.__next_f.push([1,"scovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$14\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\nc:null\n"])</script></body></html>