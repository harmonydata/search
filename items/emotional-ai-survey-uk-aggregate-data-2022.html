<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/search/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/2c4d913f25bfc6bf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/chunks/webpack-904c4041abd776f2.js"/><script src="/search/_next/static/chunks/4bd1b696-220750848fc52813.js" async=""></script><script src="/search/_next/static/chunks/1517-45045142ab33e6f1.js" async=""></script><script src="/search/_next/static/chunks/main-app-c0fb4dfbd302de72.js" async=""></script><script src="/search/_next/static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js" async=""></script><script src="/search/_next/static/chunks/f71d1b72-799ff7a6833dc50c.js" async=""></script><script src="/search/_next/static/chunks/6586-1013c110456598c2.js" async=""></script><script src="/search/_next/static/chunks/4889-f0599128dd4090a0.js" async=""></script><script src="/search/_next/static/chunks/9141-d17bf49085d8e296.js" async=""></script><script src="/search/_next/static/chunks/2926-f97573e569b0b5d8.js" async=""></script><script src="/search/_next/static/chunks/8173-30737ce2fc776efb.js" async=""></script><script src="/search/_next/static/chunks/9756-90c6220c809c4148.js" async=""></script><script src="/search/_next/static/chunks/3163-d1a03f172499fcd8.js" async=""></script><script src="/search/_next/static/chunks/app/layout-802ca43371b3eb9d.js" async=""></script><script src="/search/_next/static/chunks/834cb1aa-fe75579b2a50baac.js" async=""></script><script src="/search/_next/static/chunks/2170a4aa-66be1631595ccab0.js" async=""></script><script src="/search/_next/static/chunks/1057-d97430463abd6821.js" async=""></script><script src="/search/_next/static/chunks/2282-26bc5318a4471ee9.js" async=""></script><script src="/search/_next/static/chunks/9234-fce85e807baa599f.js" async=""></script><script src="/search/_next/static/chunks/5733-d0ad15157d7394e5.js" async=""></script><script src="/search/_next/static/chunks/613-3467f3d6fe7e6e6a.js" async=""></script><script src="/search/_next/static/chunks/8738-58586275b0d791e8.js" async=""></script><script src="/search/_next/static/chunks/2649-8ae63f8e6332939b.js" async=""></script><script src="/search/_next/static/chunks/1857-99747bd4076c313b.js" async=""></script><script src="/search/_next/static/chunks/3121-245641670b1233b9.js" async=""></script><script src="/search/_next/static/chunks/app/items/%5Bslug%5D/page-9a644ac5423ff4fd.js" async=""></script><link rel="preload" href="/search/_next/static/css/4921cfd18b262f8c.css" as="style"/><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><title>Emotional AI Survey, UK: Aggregate Data, 2022</title><meta name="description" content="This project aimed to quantitatively understand citizens&#x27; attitudes to Emotional AI via national surveys (as described in point 6 &quot;Project Description&quot;, see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens&#x27; emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet&#x27;s Sidewalk Labs). 

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.
4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.
5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. 
6. To understand diverse citizens&#x27; attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. 
8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.
9. To advance surveillance studies, new media studies, information technology law, science &amp; technology studies, security &amp; policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.

APPLICATIONS/BENEFITS 
We will: 
- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."/><meta property="og:title" content="Emotional AI Survey, UK: Aggregate Data, 2022"/><meta property="og:description" content="This project aimed to quantitatively understand citizens&#x27; attitudes to Emotional AI via national surveys (as described in point 6 &quot;Project Description&quot;, see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens&#x27; emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet&#x27;s Sidewalk Labs). 

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.
4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.
5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. 
6. To understand diverse citizens&#x27; attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. 
8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.
9. To advance surveillance studies, new media studies, information technology law, science &amp; technology studies, security &amp; policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.

APPLICATIONS/BENEFITS 
We will: 
- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/emotional-ai-survey-uk-aggregate-data-2022"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Emotional AI Survey, UK: Aggregate Data, 2022"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Emotional AI Survey, UK: Aggregate Data, 2022"/><meta name="twitter:description" content="This project aimed to quantitatively understand citizens&#x27; attitudes to Emotional AI via national surveys (as described in point 6 &quot;Project Description&quot;, see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT
Emotional AI (EAI) technologies sense, learn and interact with citizens&#x27; emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet&#x27;s Sidewalk Labs). 

We need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.

Building on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.

AIMS/OBJECTIVES
1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.
2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.
3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.
4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.
5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. 
6. To understand diverse citizens&#x27; attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. 
8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.
9. To advance surveillance studies, new media studies, information technology law, science &amp; technology studies, security &amp; policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.

APPLICATIONS/BENEFITS 
We will: 
- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global o39zl1">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback';font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body class="__className_62a302"><script src="/search/_next/static/chunks/webpack-904c4041abd776f2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n3:I[10683,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"AuthProvider\"]\n4:I[63612,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"SearchProvider\"]\n5:I[68998,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"stati"])</script><script>self.__next_f.push([1,"c/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n6:I[98904,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n7:I[15244,[],\"\"]\n8:I[43866,[],\"\"]\n9:I[14046,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"ToastContainer\"]\nb:I[86213,[],\"OutletBoundary\"]\nd:I[86213,[],\"MetadataBoundary\"]\nf:I[86213,[],\"ViewportBoundary\"]\n11:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"style\"]\n:HL[\"/search/_next/static/css/4921cfd18b262f8c.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"qK7gJPt1J2SaqNE9Hkvkt\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"emotional-ai-survey-uk-aggregate-data-2022\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"emotional-ai-survey-uk-aggregate-data-2022\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}]}],[\"$\",\"body\",null,{\"className\":\"__className_62a302\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[[\"$\",\"$L5\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"$L5\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$L9\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"emotional-ai-survey-uk-aggregate-data-2022\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$La\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/4921cfd18b262f8c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"nc3fnpr9023la40Za3BdO\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:I[53704,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"2154\",\"static/chunks/834cb1aa-fe75579b2a50baac.js\",\"3524\",\"static/chunks/2170a4aa-66be1631595ccab0.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"1057\",\"static/chunks/1057-d97430463abd6821.js\",\"2282\",\"static/chunks/2282-26bc5318a4471ee9.js\",\"9234\",\"static/chunks/9234-fce85e807baa599f.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"5733\",\"static/chunks/5733-d0ad15157d7394e5.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"613\",\"static/chunks/613-3467f3d6fe7e6e6a.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"8738\",\"static/chunks/8738-58586275b0d791e8.js\",\"2649\",\"static/chunks/2649-8ae63f8e6332939b.js\",\"1857\",\"static/chunks/1857-99747bd4076c313b.js\",\"3121\",\"static/chunks/3121-245641670b1233b9.js\",\"6387\",\"static/chunks/app/items/%5Bslug%5D/page-9a644ac5423ff4fd.js\"],\"\"]\n14:I[5749,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"2154\",\"static/chunks/834cb1aa-fe75579b2a50baac.js\",\"3524\",\"static/chunks/2170a4aa-66be1631595ccab0.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"1057\",\"static/chunks/1057-d97430463abd6821.js\",\"2282\",\"static/chunks/2282-26bc5318a4471ee9.js\",\"9234\",\"static/chunks/9234-fce85e807baa599f.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"5733\",\"static/chunks/5733-d0ad15157d7394e5.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"613\",\"static/chunks/613-3467f3d6fe7e6e6a.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"8738\",\"static/chunks/8738-58586275b0d791e8.js\",\"2649\",\"static/chunks/2649-8ae63f8e6332939b.js\",\"1857\",\"static/chunks/1857-99747bd4076c313b.js\",\"3121\",\"static/chunks/3121-245641670b1233b9.js\",\"6387\",\"static/chunks/app/items/%5Bslug%5D/page-9a644ac5423ff4fd.js\"],\"default\"]\n13:T14ad,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Emotional AI Survey, UK: Aggregate Data, 2022\",\"description\":\"This project aimed to quantitatively understand citizens' attitudes to Emotional AI via national surveys (as described in point 6 \\\"Project Description\\\", see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT\\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs). \\n\\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\\n\\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\\n\\nAIMS/OBJECTIVES\\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\\n3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.\\n4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.\\n5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. \\n6. To understand diverse citizens' attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. \\n8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.\\n9. To advance surveillance studies, new media studies, information technology law, science \u0026 technology studies, security \u0026 policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.\\n\\nAPPLICATIONS/BENEFITS \\nWe will: \\n- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories.\",\"url\":\"https://harmonydata.ac.uk/search/items/emotional-ai-survey-uk-aggregate-data-2022\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-856708\"],\"keywords\":[\"ARTIFICIAL INTELLIGENCE\",\"POLICE SURVEILLANCE\",\"SECURITY SURVEILLANCE SYSTEMS\",\"SURVEYS\",\"COMMUNICATIONS\",\"POLITICAL CAMPAIGNS\",\"HEALTH\",\"TRANSPORT\",\"EDUCATION\",\"ROBOTICS\"],\"temporalCoverage\":\"2022-06-29/2022-07-01\"}"])</script><script>self.__next_f.push([1,"15:T12a3,"])</script><script>self.__next_f.push([1,"This project aimed to quantitatively understand citizens' attitudes to Emotional AI via national surveys (as described in point 6 \"Project Description\", see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs). \n\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\n\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\n\nAIMS/OBJECTIVES\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\n3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.\n4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.\n5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. \n6. To understand diverse citizens' attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. \n8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.\n9. To advance surveillance studies, new media studies, information technology law, science \u0026 technology studies, security \u0026 policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.\n\nAPPLICATIONS/BENEFITS \nWe will: \n- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."])</script><script>self.__next_f.push([1,"a:[[\"$\",\"$L12\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$13\"}}],[\"$\",\"$L14\",null,{\"dataset\":{\"title\":\"Emotional AI Survey, UK: Aggregate Data, 2022\",\"description\":\"$15\",\"image\":\"$undefined\",\"publisher\":\"$undefined\",\"funders\":\"$undefined\",\"geographicCoverage\":\"GB\",\"temporalCoverage\":\"2022-06-29/2022-07-01\",\"ageCoverage\":\"$undefined\",\"studyDesign\":[],\"resourceType\":\"dataset\",\"topics\":[\"ARTIFICIAL INTELLIGENCE\",\"POLICE SURVEILLANCE\",\"SECURITY SURVEILLANCE SYSTEMS\",\"SURVEYS\",\"COMMUNICATIONS\",\"POLITICAL CAMPAIGNS\",\"HEALTH\",\"TRANSPORT\",\"EDUCATION\",\"ROBOTICS\"],\"instruments\":[],\"dataCatalogs\":[{\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=856708\",\"logo\":\"$undefined\"}],\"matchedVariables\":[],\"allVariables\":[],\"additionalLinks\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=856708\",\"https://reshare.ukdataservice.ac.uk/856708\",\"http://dx.doi.org/10.5255/UKDA-SN-856708\",\"http://dx.doi.org/10.5255/UKDA-SN-856708\"],\"child_datasets\":[],\"aiSummary\":null}}]]\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"16:T12a3,"])</script><script>self.__next_f.push([1,"This project aimed to quantitatively understand citizens' attitudes to Emotional AI via national surveys (as described in point 6 \"Project Description\", see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs). \n\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\n\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\n\nAIMS/OBJECTIVES\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\n3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.\n4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.\n5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. \n6. To understand diverse citizens' attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. \n8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.\n9. To advance surveillance studies, new media studies, information technology law, science \u0026 technology studies, security \u0026 policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.\n\nAPPLICATIONS/BENEFITS \nWe will: \n- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."])</script><script>self.__next_f.push([1,"17:T12a3,"])</script><script>self.__next_f.push([1,"This project aimed to quantitatively understand citizens' attitudes to Emotional AI via national surveys (as described in point 6 \"Project Description\", see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs). \n\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\n\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\n\nAIMS/OBJECTIVES\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\n3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.\n4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.\n5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. \n6. To understand diverse citizens' attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. \n8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.\n9. To advance surveillance studies, new media studies, information technology law, science \u0026 technology studies, security \u0026 policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.\n\nAPPLICATIONS/BENEFITS \nWe will: \n- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."])</script><script>self.__next_f.push([1,"18:T12a3,"])</script><script>self.__next_f.push([1,"This project aimed to quantitatively understand citizens' attitudes to Emotional AI via national surveys (as described in point 6 \"Project Description\", see above). We developed a demographically representative survey to gauge citizen attitudes to emotion capture technologies in cities in the UK. The survey introduces the overall topic of emotion profiling with the phrase: ‘We would now like to ask your opinion on use of technologies that try to measure and understand emotions (e.g., through computer analysis of social media posts, facial expression, voice, heart rate, gesture, and other data about the body). Closed-ended questions allowed then to explore 10 different use cases (38 questions in total): security, policing, communications, political campaigning, health, transport, education, toys and robots. For each case, positive and negative themes were tested, by grounding each question in an applied use case. In total, nine themes were explored, (although not across all the use cases to minimise survey fatigue).CONTEXT\nEmotional AI (EAI) technologies sense, learn and interact with citizens' emotions, moods, attention and intentions. Using weak and narrow rather than strong AI, machines read and react to emotion via text, images, voice, computer vision and biometric sensing. Concurrently, life in cities is increasingly technologically mediated. Data-driven sensors, actuators, robots and pervasive networking are changing how citizens experience cities, but not always for the better. Citizen needs and perspectives are often ancillary in emerging smart city deployments, resulting in mistrust in new civic infrastructure and its management (e.g. Alphabet's Sidewalk Labs). \n\nWe need to avoid these issues repeating as EAI is rolled out in cities. Reading the body is an increasingly prevalent concern, as recent pushback against facial detection and recognition technologies demonstrates. EAI is an extension of this, and as it becomes normalised across the next decade we are concerned about how these systems are governed, social impacts on citizens, and how EAI can be designed in a more ethical manner. In both Japan and UK, we are at a critical juncture where these social, technological and governance structures can be appropriately prepared before mass adoption of EAI, to enable citizens, in all their diversity, to live ethically and well with EAI in cities-as-platforms.\n\nBuilding on our ESRC/AHRC seminars in Tokyo (2019) that considered cross-cultural ethics and EAI, our research will enable a multi-stakeholder (commerce, security, media) and citizen-led interdisciplinary response to EAI for Japan and UK. While these are two of the most advanced nations in regard to AI, the social contexts and histories from which these technologies emerge differ, providing rich scope for reflection and mutual learning.\n\nAIMS/OBJECTIVES\n1. To assess what it means to live ethically and well with EAI in cities in cross-cultural (UK-Japan) commercial, security and media contexts.\n2. To map and engage with the ecology of influential actors developing and working with EAI in UK-Japan.\n3. To understand commercial activities, intentions and ethical implications regarding EAI in cities, via interviews with industry, case studies, and analysis of patents.\n4. To ascertain how EAI might impact security/policing stakeholders, and organisations in the new media ecology, via interviews with these stakeholders and case studies in UK-Japan.\n5. To examine governance approaches for collection and use of intimate data about emotions in public spaces to understand how these guide EAI technological developments, and to build a repository of best practice on EAI in cities. \n6. To understand diverse citizens' attitudes to EAI via quantitative national surveys and qualitative workshops to co-design citizen-led, creative visions of what it means to live ethically and well with EAI in cities in UK-Japan. \n8. To feed our insights to stakeholders shaping usage of EAI in cities in UK-Japan.\n9. To advance surveillance studies, new media studies, information technology law, science \u0026 technology studies, security \u0026 policing studies, computer ethics and affective computing via: 24 international conference papers; a conference on EAI; 12 international, refereed journal papers; a Special Issue on EAI.\n\nAPPLICATIONS/BENEFITS \nWe will: \n- Raise awareness of UK-Japanese stakeholders (technology industry, policymakers, NGOs, security services, urban planners, media outlets, citizens) on how to live ethically and well with EAI in cities, via co-designed, citizen-led, qualitative visions fed into Stakeholder Policy Workshops; a Final Report with clear criteria on ethical usage of EAI in cites; 24 talks with stakeholders; multiple news stories."])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Emotional AI Survey, UK: Aggregate Data, 2022\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$16\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Emotional AI Survey, UK: Aggregate Data, 2022\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$17\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/emotional-ai-survey-uk-aggregate-data-2022\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"Emotional AI Survey, UK: Aggregate Data, 2022\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Emotional AI Survey, UK: Aggregate Data, 2022\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$18\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script></body></html>