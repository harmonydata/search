<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/search/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/2c4d913f25bfc6bf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/chunks/webpack-904c4041abd776f2.js"/><script src="/search/_next/static/chunks/4bd1b696-220750848fc52813.js" async=""></script><script src="/search/_next/static/chunks/1517-45045142ab33e6f1.js" async=""></script><script src="/search/_next/static/chunks/main-app-c0fb4dfbd302de72.js" async=""></script><script src="/search/_next/static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js" async=""></script><script src="/search/_next/static/chunks/f71d1b72-799ff7a6833dc50c.js" async=""></script><script src="/search/_next/static/chunks/6586-1013c110456598c2.js" async=""></script><script src="/search/_next/static/chunks/4889-f0599128dd4090a0.js" async=""></script><script src="/search/_next/static/chunks/9141-d17bf49085d8e296.js" async=""></script><script src="/search/_next/static/chunks/2926-f97573e569b0b5d8.js" async=""></script><script src="/search/_next/static/chunks/8173-30737ce2fc776efb.js" async=""></script><script src="/search/_next/static/chunks/9756-90c6220c809c4148.js" async=""></script><script src="/search/_next/static/chunks/3163-d1a03f172499fcd8.js" async=""></script><script src="/search/_next/static/chunks/app/layout-802ca43371b3eb9d.js" async=""></script><link rel="preload" href="/search/_next/static/css/4921cfd18b262f8c.css" as="style"/><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><title>Understanding and Improving Data Linkage Consent in Surveys, 2018-2019</title><meta name="description" content="Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. 
The overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: 
1.	To understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.
2.	To develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. 
3.	To develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. 
4.	As a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. 

Our findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).
Since the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.
A total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).
The experiments, and the survey(s) on which they were conducted, are briefly summarized here:  
1.	Easy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. 
2.	Early vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. 
3.	Web vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. 
4.	Default question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.
5.	Additional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.
6.	Data linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.
7.	Trust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.
8.	Format of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.
9.	Order of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  
For all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   
In additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  

Key Findings
Correlates of consent:
(1)	Respondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. 
(2)	As in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.
(3)	Respondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  
(4)	Priming respondents to think about trust in the organisations involved in the data linkage increases consent. 
(5)	The only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. 
(6)	Easy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. 

The consent decision process: 
(7)	Respondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.
(8)	Different decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. 
(9)	Placing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.

Effects of mode of data collection on consent:
(10)	As in previous studies, respondents are less likely to consent online than with an interviewer.
(11)	Web respondents have lower levels of understanding than face-to-face respondents.
(12)	There is no difference by mode in respondents’ confidence in their decisions.
(13)	Web respondents report higher levels of concern about data security than face-to-face respondents.
(14)	Web respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.
(15)	Easier wording of the consent request does not reduce mode effects on rates of consent.
(16)	Respondents rarely ask questions and interviewers rarely provide additional information.

Multiple consent requests: 
(17)	The format in which a sequence of consent requests is asked does not seem to matter.
(18)	The order of multiple consent requests affects consent rates, but not in a consistent way.
(19)	Objective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. 
(20)	The order effects of multiple consent requests from Study 1 do not replicate in Study 2.

Conclusions and Recommendation
This series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. 
This research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). 
In the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. 
Our aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."/><meta property="og:title" content="Understanding and Improving Data Linkage Consent in Surveys, 2018-2019"/><meta property="og:description" content="Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. 
The overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: 
1.	To understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.
2.	To develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. 
3.	To develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. 
4.	As a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. 

Our findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).
Since the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.
A total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).
The experiments, and the survey(s) on which they were conducted, are briefly summarized here:  
1.	Easy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. 
2.	Early vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. 
3.	Web vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. 
4.	Default question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.
5.	Additional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.
6.	Data linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.
7.	Trust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.
8.	Format of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.
9.	Order of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  
For all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   
In additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  

Key Findings
Correlates of consent:
(1)	Respondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. 
(2)	As in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.
(3)	Respondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  
(4)	Priming respondents to think about trust in the organisations involved in the data linkage increases consent. 
(5)	The only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. 
(6)	Easy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. 

The consent decision process: 
(7)	Respondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.
(8)	Different decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. 
(9)	Placing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.

Effects of mode of data collection on consent:
(10)	As in previous studies, respondents are less likely to consent online than with an interviewer.
(11)	Web respondents have lower levels of understanding than face-to-face respondents.
(12)	There is no difference by mode in respondents’ confidence in their decisions.
(13)	Web respondents report higher levels of concern about data security than face-to-face respondents.
(14)	Web respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.
(15)	Easier wording of the consent request does not reduce mode effects on rates of consent.
(16)	Respondents rarely ask questions and interviewers rarely provide additional information.

Multiple consent requests: 
(17)	The format in which a sequence of consent requests is asked does not seem to matter.
(18)	The order of multiple consent requests affects consent rates, but not in a consistent way.
(19)	Objective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. 
(20)	The order effects of multiple consent requests from Study 1 do not replicate in Study 2.

Conclusions and Recommendation
This series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. 
This research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). 
In the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. 
Our aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."/><meta property="og:url" content="https://discoverynext.vercel.app/items/fd2364a5babd9e520663249a6ba20a73"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Understanding and Improving Data Linkage Consent in Surveys, 2018-2019"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Understanding and Improving Data Linkage Consent in Surveys, 2018-2019"/><meta name="twitter:description" content="Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. 
The overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: 
1.	To understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.
2.	To develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. 
3.	To develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. 
4.	As a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. 

Our findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).
Since the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.
A total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).
The experiments, and the survey(s) on which they were conducted, are briefly summarized here:  
1.	Easy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. 
2.	Early vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. 
3.	Web vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. 
4.	Default question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.
5.	Additional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.
6.	Data linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.
7.	Trust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.
8.	Format of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.
9.	Order of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  
For all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   
In additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  

Key Findings
Correlates of consent:
(1)	Respondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. 
(2)	As in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.
(3)	Respondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  
(4)	Priming respondents to think about trust in the organisations involved in the data linkage increases consent. 
(5)	The only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. 
(6)	Easy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. 

The consent decision process: 
(7)	Respondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.
(8)	Different decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. 
(9)	Placing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.

Effects of mode of data collection on consent:
(10)	As in previous studies, respondents are less likely to consent online than with an interviewer.
(11)	Web respondents have lower levels of understanding than face-to-face respondents.
(12)	There is no difference by mode in respondents’ confidence in their decisions.
(13)	Web respondents report higher levels of concern about data security than face-to-face respondents.
(14)	Web respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.
(15)	Easier wording of the consent request does not reduce mode effects on rates of consent.
(16)	Respondents rarely ask questions and interviewers rarely provide additional information.

Multiple consent requests: 
(17)	The format in which a sequence of consent requests is asked does not seem to matter.
(18)	The order of multiple consent requests affects consent rates, but not in a consistent way.
(19)	Objective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. 
(20)	The order effects of multiple consent requests from Study 1 do not replicate in Study 2.

Conclusions and Recommendation
This series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. 
This research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). 
In the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. 
Our aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global o39zl1">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback';font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body class="__className_62a302"><script src="/search/_next/static/chunks/webpack-904c4041abd776f2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n3:I[10683,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"AuthProvider\"]\n4:I[63612,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"SearchProvider\"]\n5:I[68998,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"stati"])</script><script>self.__next_f.push([1,"c/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n6:I[98904,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"default\"]\n7:I[15244,[],\"\"]\n8:I[43866,[],\"\"]\n9:I[14046,[\"2992\",\"static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js\",\"9895\",\"static/chunks/f71d1b72-799ff7a6833dc50c.js\",\"6586\",\"static/chunks/6586-1013c110456598c2.js\",\"4889\",\"static/chunks/4889-f0599128dd4090a0.js\",\"9141\",\"static/chunks/9141-d17bf49085d8e296.js\",\"2926\",\"static/chunks/2926-f97573e569b0b5d8.js\",\"8173\",\"static/chunks/8173-30737ce2fc776efb.js\",\"9756\",\"static/chunks/9756-90c6220c809c4148.js\",\"3163\",\"static/chunks/3163-d1a03f172499fcd8.js\",\"7177\",\"static/chunks/app/layout-802ca43371b3eb9d.js\"],\"ToastContainer\"]\nb:I[86213,[],\"OutletBoundary\"]\nd:I[86213,[],\"MetadataBoundary\"]\nf:I[86213,[],\"ViewportBoundary\"]\n11:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"style\"]\n:HL[\"/search/_next/static/css/4921cfd18b262f8c.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"s_DTI9faTgGaCM3x3n4Zl\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"fd2364a5babd9e520663249a6ba20a73\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"fd2364a5babd9e520663249a6ba20a73\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/2c4d913f25bfc6bf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}]}],[\"$\",\"body\",null,{\"className\":\"__className_62a302\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[[\"$\",\"$L5\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L6\",null,{}],[\"$\",\"$L5\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$L9\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"fd2364a5babd9e520663249a6ba20a73\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L7\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L8\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$La\",[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/4921cfd18b262f8c.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"lxiPve9lmrgGPtoW_BUaz\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"div\",null,{\"children\":[[\"$\",\"script\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"window.location.replace('/items/understanding-and-improving-data-linkage-consent-in-surveys-2018-2019');\"}}],[\"$\",\"p\",null,{\"children\":[\"Redirecting to\",\" \",[\"$\",\"a\",null,{\"href\":\"/items/understanding-and-improving-data-linkage-consent-in-surveys-2018-2019\",\"children\":[\"/items/\",\"understanding-and-improving-data-linkage-consent-in-surveys-2018-2019\"]}],\"...\"]}]]}]\n"])</script><script>self.__next_f.push([1,"12:T3496,"])</script><script>self.__next_f.push([1,"Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. \nThe overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: \n1.\tTo understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.\n2.\tTo develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. \n3.\tTo develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. \n4.\tAs a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. \n\nOur findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).\nSince the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.\nA total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).\nThe experiments, and the survey(s) on which they were conducted, are briefly summarized here:  \n1.\tEasy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. \n2.\tEarly vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. \n3.\tWeb vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. \n4.\tDefault question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.\n5.\tAdditional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.\n6.\tData linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.\n7.\tTrust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.\n8.\tFormat of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.\n9.\tOrder of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  \nFor all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   \nIn additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  \n\nKey Findings\nCorrelates of consent:\n(1)\tRespondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. \n(2)\tAs in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.\n(3)\tRespondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  \n(4)\tPriming respondents to think about trust in the organisations involved in the data linkage increases consent. \n(5)\tThe only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. \n(6)\tEasy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. \n\nThe consent decision process: \n(7)\tRespondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.\n(8)\tDifferent decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. \n(9)\tPlacing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.\n\nEffects of mode of data collection on consent:\n(10)\tAs in previous studies, respondents are less likely to consent online than with an interviewer.\n(11)\tWeb respondents have lower levels of understanding than face-to-face respondents.\n(12)\tThere is no difference by mode in respondents’ confidence in their decisions.\n(13)\tWeb respondents report higher levels of concern about data security than face-to-face respondents.\n(14)\tWeb respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.\n(15)\tEasier wording of the consent request does not reduce mode effects on rates of consent.\n(16)\tRespondents rarely ask questions and interviewers rarely provide additional information.\n\nMultiple consent requests: \n(17)\tThe format in which a sequence of consent requests is asked does not seem to matter.\n(18)\tThe order of multiple consent requests affects consent rates, but not in a consistent way.\n(19)\tObjective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. \n(20)\tThe order effects of multiple consent requests from Study 1 do not replicate in Study 2.\n\nConclusions and Recommendation\nThis series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. \nThis research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). \nIn the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. \nOur aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."])</script><script>self.__next_f.push([1,"13:T3496,"])</script><script>self.__next_f.push([1,"Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. \nThe overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: \n1.\tTo understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.\n2.\tTo develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. \n3.\tTo develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. \n4.\tAs a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. \n\nOur findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).\nSince the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.\nA total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).\nThe experiments, and the survey(s) on which they were conducted, are briefly summarized here:  \n1.\tEasy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. \n2.\tEarly vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. \n3.\tWeb vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. \n4.\tDefault question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.\n5.\tAdditional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.\n6.\tData linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.\n7.\tTrust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.\n8.\tFormat of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.\n9.\tOrder of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  \nFor all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   \nIn additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  \n\nKey Findings\nCorrelates of consent:\n(1)\tRespondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. \n(2)\tAs in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.\n(3)\tRespondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  \n(4)\tPriming respondents to think about trust in the organisations involved in the data linkage increases consent. \n(5)\tThe only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. \n(6)\tEasy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. \n\nThe consent decision process: \n(7)\tRespondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.\n(8)\tDifferent decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. \n(9)\tPlacing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.\n\nEffects of mode of data collection on consent:\n(10)\tAs in previous studies, respondents are less likely to consent online than with an interviewer.\n(11)\tWeb respondents have lower levels of understanding than face-to-face respondents.\n(12)\tThere is no difference by mode in respondents’ confidence in their decisions.\n(13)\tWeb respondents report higher levels of concern about data security than face-to-face respondents.\n(14)\tWeb respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.\n(15)\tEasier wording of the consent request does not reduce mode effects on rates of consent.\n(16)\tRespondents rarely ask questions and interviewers rarely provide additional information.\n\nMultiple consent requests: \n(17)\tThe format in which a sequence of consent requests is asked does not seem to matter.\n(18)\tThe order of multiple consent requests affects consent rates, but not in a consistent way.\n(19)\tObjective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. \n(20)\tThe order effects of multiple consent requests from Study 1 do not replicate in Study 2.\n\nConclusions and Recommendation\nThis series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. \nThis research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). \nIn the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. \nOur aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."])</script><script>self.__next_f.push([1,"14:T3496,"])</script><script>self.__next_f.push([1,"Linking survey and administrative data offers the possibility of combining the strengths, and mitigating the weaknesses, of both. Such linkage is therefore an extremely promising basis for future empirical research in social science. For ethical and legal reasons, linking administrative data to survey responses will usually require obtaining explicit consent. It is well known that not all respondents give consent. Past research on consent has generated many null and inconsistent findings. A weakness of the existing literature is that little effort has been made to understand the cognitive processes of how respondents make the decision whether or not to consent. \nThe overall aim of this project was to improve our understanding about how to pursue the twin goals of maximizing consent and ensuring that consent is genuinely informed. The ultimate objective is to strengthen the data infrastructure for social science and policy research in the UK. Specific aims were: \n1.\tTo understand how respondents process requests for data linkage: which factors influence their understanding of data linkage, which factors influence their decision to consent, and to open the black box of consent decisions to begin to understand how respondents make the decision.\n2.\tTo develop and test methods of maximising consent in web surveys, by understanding why web respondents are less likely to give consent than face-to-face respondents. \n3.\tTo develop and test methods of maximising consent with requests for linkage to multiple data sets, by understanding how respondents process multiple requests. \n4.\tAs a by-product of testing hypotheses about the previous points, to test the effects of different approaches to wording consent questions on informed consent. \n\nOur findings are based on a series of experiments conducted in four surveys using two different studies: The Understanding Society Innovation Panel (IP) and the PopulusLive online access panel (AP). The Innovation Panel is part of Understanding Society: the UK Household Longitudinal Study. It is a probability sample of households in Great Britain used for methodological testing, with a design that mirrors that of the main Understanding Society survey. The Innovation Panel survey was conducted in wave 11, fielded in 2018. The Innovation Panel data are available from the UK Data Service (SN: 6849, http://doi.org/10.5255/UKDA-SN-6849-12).\nSince the Innovation Panel sample size (around 2,900 respondents) constrained the number of experimental treatment groups we could implement, we fielded a parallel survey with additional experiments, using a different sample. PopulusLive is a non-probability online panel with around 130,000 active sample members, who are recruited through web advertising, word of mouth, and database partners. We used age, gender and education quotas to match the sample composition of the Innovation Panel.\nA total of nine experiments were conducted across the two sample sources. Experiments 1 to 5 all used variations of a single consent question, about linkage to tax data (held by HM Revenue and Customs, HMRC). Experiments 6 and 7 also used single consent questions, but respondents were either assigned to questions on tax or health data (held by the National Health Service, NHS) linkage. Experiments 8 and 9 used five different data linkage requests: tax data (held by HMRC), health data (held by the NHS), education data (held by the Department for Education in England, DfE, and equivalent departments in Scotland and Wales), household energy data (held the Department for Business, Energy and Industrial Strategy, BEIS), and benefit and pensions data (held by the Department for Work and Pensions, DWP).\nThe experiments, and the survey(s) on which they were conducted, are briefly summarized here:  \n1.\tEasy vs. standard wording of consent request (IP and AP).  Half the respondents were allocated to the ‘standard’ question wording, used previously in Understanding Society. The balance was allocated to an ‘easy’ version, where the text was rewritten to reduce reading difficulty and to provide all essential information about the linkage in the question text rather than an additional information leaflet. \n2.\tEarly vs. late placement of consent question (IP). Half the respondents were asked for consent early in the interview, the other half were asked at the end. \n3.\tWeb vs. face-to-face interview (IP). This experiment exploits the random assignment of IP cases to explore mode effects on consent. \n4.\tDefault question wording (AP). Experiment 4 tested a default approach to giving consent, asking respondents to “Press ‘next’ to continue” or explicitly opt out, versus the standard opt-in consent procedure.\n5.\tAdditional information question wording (AP). This experiment tested the effect of offering additional information, with a version that added a third response option (“I need more information before making a decision”) to the standard ‘yes’ or no’ options.\n6.\tData linkage domain (AP). Half the respondents were assigned to a question asking for consent to link to HMRC data; the other half were asked for linkage to NHS data.\n7.\tTrust priming (AP).This experiment was crossed with the data linkage domain experiment, and focused on the effect of priming trust on consent. Half the sample saw an additional statement: “HMRC / The NHS is a trusted data holder” on an introductory screen prior to the consent question. This was followed by an icon symbolizing data security: a shield and lock symbol with the heading “Trust”. The balance was not shown the additional statement or icon.\n8.\tFormat of multiple consents (AP). For one group, the five consent questions were each presented on a separate page, with respondents consenting to each in turn. For the second group the questions were all presented on one page; however, the respondent still had to answer each consent question individually. For the third group all five data requests were presented on a single page and the respondent answered a single yes/no question, whether they consented to all the linkages or not.\n9.\tOrder of multiple consents (AP). One version asked the five consent questions in ascending order of sensitivity of the request (based on previous data), with NHS asked first. The other version reversed the order, with consent to linkage to HMRC data asked first.  \nFor all of the experiments described above, we examined the rates of consent. We also tested comprehension of the consent request, using a series of knowledge questions about the consent process. We also measured subjective understanding, to get a sense of how much respondents felt they understood about the request. Finally, we also ascertained subjective confidence in the decision they had made.   \nIn additional to the experiments, we used digital audio-recordings of the IP11 face-to-face interviews (recorded with respondents’ permission) to explore how interviewers communicate the consent request to respondents, whether and how they provide additional information or attempt to persuade respondents to consent, and whether respondents raise questions when asked for consent to data linkage.  \n\nKey Findings\nCorrelates of consent:\n(1)\tRespondents who have better understanding of the data linkage request (as measured by a set of knowledge questions) are also more likely to consent. \n(2)\tAs in previous studies, we find no socio-demographic characteristics that consistently predict consent in all samples. The only consistent predictors are positive attitudes towards data sharing, trust in HMRC, and knowledge of what data HMRC have.\n(3)\tRespondents are less likely to consent to data linkage if the wording of the request is difficult and the question is asked late in the questionnaire. Position has no effect on consent if the wording is easy; wording has no effect on consent if the position is early.  \n(4)\tPriming respondents to think about trust in the organisations involved in the data linkage increases consent. \n(5)\tThe only socio-demographic characteristic that consistently predicts objective understanding of the linkage request is education. Understanding is positively associated with the number of online data sharing behaviours (e.g., posting text or images on social media, downloading apps, online purchases or banking) and with trust in HMRC. \n(6)\tEasy wording of the consent question increases objective understanding of the linkage request. Position of the consent question in the questionnaire has no effect on understanding. \n\nThe consent decision process: \n(7)\tRespondents decide about the consent request in different ways: some use more reflective decision-making strategies, others use less reflective strategies.\n(8)\tDifferent decision processes are associated with very different levels of consent, comprehension, and confidence in the consent decision. \n(9)\tPlacing the consent request earlier in the survey increases the probability of the respondent using a reflective decision-making process.\n\nEffects of mode of data collection on consent:\n(10)\tAs in previous studies, respondents are less likely to consent online than with an interviewer.\n(11)\tWeb respondents have lower levels of understanding than face-to-face respondents.\n(12)\tThere is no difference by mode in respondents’ confidence in their decisions.\n(13)\tWeb respondents report higher levels of concern about data security than face-to-face respondents.\n(14)\tWeb respondents are less likely to use reflective strategies to make their decision than face-to-face respondents, and instead more likely to make habit-based decisions.\n(15)\tEasier wording of the consent request does not reduce mode effects on rates of consent.\n(16)\tRespondents rarely ask questions and interviewers rarely provide additional information.\n\nMultiple consent requests: \n(17)\tThe format in which a sequence of consent requests is asked does not seem to matter.\n(18)\tThe order of multiple consent requests affects consent rates, but not in a consistent way.\n(19)\tObjective knowledge, subjective understanding and subjective confidence in the decision do not differ much by order and format of sequential consent requests. \n(20)\tThe order effects of multiple consent requests from Study 1 do not replicate in Study 2.\n\nConclusions and Recommendation\nThis series of studies has shed light on some of the processes underlying the consent process and offered a theoretical framework for better understanding how the consent decision is made. The different decision processes employed by survey respondents are associated with different levels of consent, comprehension, and confidence in the consent decision. Generally, respondents reach a consent decision relatively quickly. Given this, simply providing more information on the consent process is unlikely to be effective. Rather, wording consent requests in an easy-to-read format and emphasising trust in the organisations involved will likely increase rates of consent without compromising understanding of the request or confidence in the decision. \nThis research has advanced our understanding on how the decision to consent to administrative data linkages is made. It points to the importance of understanding how respondents process the request for consent in different ways, suggesting that targeting different strategies based on respondents’ decision-making preferences may be effective at increasing informed consent. Our work also points to the importance of focusing not only on the outcome of the request (i.e., maximizing consent rates) but also on understanding how informed the consent is, measured both objectively and subjectively. However, more work remains to achieve the goal of maximizing informed consent to administrative record linkage in surveys, especially those administered online.One of the most promising avenues for empirical social science research involves linking administrative or process generated data with survey data. Administrative data (whether held by government or private entities) are useful on their own, but will be much more useful if we can use surveys to “fill the gaps”. Sometimes the gaps will be specific types of information (e.g. administrative data do not contain information on expectations or subjective wellbeing), and sometimes it will be to provide a suitable frame to allow inference to the general population (especially in the UK where there is not an appropriate individual identifier, or register, to provide a frame). \nIn the UK, survey data can only be linked to administrative or other process generated data, if survey respondents give informed consent to the linkage. Previous research suggests that people do not have strong fixed views on consent and that the decision to consent can be influenced. \nOur aims are to examine which factors influence the decision to consent and to develop and test ways of maximising informed consent, in particular in web surveys and when consent for linkages to multiple datasets are requested. We will design experiments to test whether different features of the consent request are effective for different types of people, to measure the respondent decision-making process, to ascertain how informed the consent decision is, whether and how informed consent varies with the experimental treatments and respondent characteristics, and how it differs between face-to-face interviews and self-completion web surveys."])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Understanding and Improving Data Linkage Consent in Surveys, 2018-2019\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$12\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Understanding and Improving Data Linkage Consent in Surveys, 2018-2019\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$13\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://discoverynext.vercel.app/items/fd2364a5babd9e520663249a6ba20a73\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"Understanding and Improving Data Linkage Consent in Surveys, 2018-2019\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Understanding and Improving Data Linkage Consent in Surveys, 2018-2019\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$14\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\nc:null\n"])</script></body></html>