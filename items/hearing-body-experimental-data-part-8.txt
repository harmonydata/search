1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"AuthProvider"]
4:I[83705,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"FirebaseProvider"]
5:"$Sreact.suspense"
6:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"SearchProvider"]
7:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"default"]
8:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"default"]
9:I[15244,[],""]
a:I[43866,[],""]
b:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","4398","static/js/4398.8644925b.js","7177","static/js/app/layout.0819bb7e.js"],"ToastContainer"]
d:I[86213,[],"OutletBoundary"]
f:I[86213,[],"MetadataBoundary"]
11:I[86213,[],"ViewportBoundary"]
13:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"hHFVRgYXxM8of7-CzK8yz","p":"/search","c":["","items","hearing-body-experimental-data-part-8"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","hearing-body-experimental-data-part-8","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":["$","$L6",null,{"children":[["$","$L7",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L8",null,{}],["$","$L7",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$Lb",null,{"position":"bottom-right"}]]}]}]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","hearing-body-experimental-data-part-8","d"],["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":"$Le"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","_Zdkx_lfO__9OjpymLOmL",{"children":[["$","$Lf",null,{"children":"$L10"}],["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$13","$undefined"],"s":false,"S":true}
14:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.95608f08.js","4398","static/js/4398.8644925b.js","1857","static/js/1857.a01744c0.js","7626","static/js/7626.2947408f.js","6387","static/js/app/items/%5Bslug%5D/page.0f65d92f.js"],""]
16:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.95608f08.js","4398","static/js/4398.8644925b.js","1857","static/js/1857.a01744c0.js","7626","static/js/7626.2947408f.js","6387","static/js/app/items/%5Bslug%5D/page.0f65d92f.js"],"default"]
15:Tf61,{"@context":"https://schema.org/","@type":"Dataset","name":"The hearing body: Experimental data, Part 8\n","description":"People’s mental representations of their own body are malleable and continuously updated through sensory cues. Altering one’s body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like attributes. Here we tested the contribution of auditory cues related to one’s own voice to these visually-driven effects. In a 2x2 factorial design, visual and auditory feedback on one’s own body were varied across conditions, which included embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of the illusion of owning a child’s body, opening up possibilities for health applications.\n \nThe data in this collection are part of The Hearing Body project, a project investigating how the manipulation of action sounds may alter the mental representation of one's body and the related emotional state and body behaviour. Other data collections part of The Hearing Body project have been deposited (Please see Related Resources section below). All parts 1 to 8 consist of experimental data, but they are data from different studies. Part 1, 2, 5 and 7 contain subjective reports and behavioural data; Part 3 and 4 contain subjective reports, behavioural data and data on electrodermal activity changes; Part 6 contains subjective reports, behavioural data and data on muscle activity changes (EMG); Part 8 contains subjective reports, behavioural data and data on voice frequency changes.The mental representation we have of our body is essential for successful interaction with the environment. This representation is not fixed, but is continuously updated in response to the available sensory information. While previous studies have highlighted the role of vision, touch and proprioception in constructing the body-representation in the brain, the role of auditory information remains largely unknown. Interestingly, the sounds that accompany almost every bodily movement are highly rich in information about the body and the space immediately surrounding it. For instance, the sounds produced when tapping on a surface inform us about the length and strength of our arm. \nThis project will investigate how auditory information generated by our bodies updates our body-representation. A series of psychological experiments will explore how altering self-produced sounds in real-time changes different body-representations, including the representation of the space surrounding the body, the potential actions that we can perform and the emotional states linked to our body capabilities. This multidisciplinary and innovative research project will provide novel insights into the nature of body-representations and, ultimately, guide the design of audio-based applications that can improve body-image, self-esteem, movement patterns and social interactions to support wellbeing and rehabilitation for people with movement impairments.","url":"https://harmonydata.ac.uk/search/items/hearing-body-experimental-data-part-8","identifier":["http://dx.doi.org/10.5255/UKDA-SN-852815"],"keywords":["SENSORY SYSTEM","PERCEPTION"],"temporalCoverage":"2012-11-01/2015-12-31"}17:Tdfd,People’s mental representations of their own body are malleable and continuously updated through sensory cues. Altering one’s body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like attributes. Here we tested the contribution of auditory cues related to one’s own voice to these visually-driven effects. In a 2x2 factorial design, visual and auditory feedback on one’s own body were varied across conditions, which included embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of the illusion of owning a child’s body, opening up possibilities for health applications.
 
The data in this collection are part of The Hearing Body project, a project investigating how the manipulation of action sounds may alter the mental representation of one's body and the related emotional state and body behaviour. Other data collections part of The Hearing Body project have been deposited (Please see Related Resources section below). All parts 1 to 8 consist of experimental data, but they are data from different studies. Part 1, 2, 5 and 7 contain subjective reports and behavioural data; Part 3 and 4 contain subjective reports, behavioural data and data on electrodermal activity changes; Part 6 contains subjective reports, behavioural data and data on muscle activity changes (EMG); Part 8 contains subjective reports, behavioural data and data on voice frequency changes.The mental representation we have of our body is essential for successful interaction with the environment. This representation is not fixed, but is continuously updated in response to the available sensory information. While previous studies have highlighted the role of vision, touch and proprioception in constructing the body-representation in the brain, the role of auditory information remains largely unknown. Interestingly, the sounds that accompany almost every bodily movement are highly rich in information about the body and the space immediately surrounding it. For instance, the sounds produced when tapping on a surface inform us about the length and strength of our arm. 
This project will investigate how auditory information generated by our bodies updates our body-representation. A series of psychological experiments will explore how altering self-produced sounds in real-time changes different body-representations, including the representation of the space surrounding the body, the potential actions that we can perform and the emotional states linked to our body capabilities. This multidisciplinary and innovative research project will provide novel insights into the nature of body-representations and, ultimately, guide the design of audio-based applications that can improve body-image, self-esteem, movement patterns and social interactions to support wellbeing and rehabilitation for people with movement impairments.c:["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":[["$","$L14",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$15"}}],["$","$L16",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"The hearing body: Experimental data, Part 8\n","description":"$17","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852815","https://reshare.ukdataservice.ac.uk/852815"],"keywords":["SENSORY SYSTEM","PERCEPTION"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-852815"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852815"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"}],"temporalCoverage":"2012-11-01/2015-12-31"},"extra_data":{"language_codes":["en"],"harmony_id":"ukds/852815","genetic_data_collected":false,"data_access":"The Data Collection is available to any user without the requirement for registration for download/access.","end_year":2015,"sex":"male","source":["ukds"],"slug":"hearing-body-experimental-data-part-8","geographic_coverage":"","country_codes":["GB"],"resource_type":"dataset","ai_summary":null,"instruments":[],"study_design":[],"name":"The hearing body: Experimental data, Part 8\n","dois":["http://dx.doi.org/10.5255/UKDA-SN-852815"],"duration_years":3,"start_year":2012,"urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852815","https://reshare.ukdataservice.ac.uk/852815"],"num_variables":null,"uuid":"022a8f9016c50cb1c8f3e023fad043bb"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]}]
12:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
18:Tdfd,People’s mental representations of their own body are malleable and continuously updated through sensory cues. Altering one’s body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like attributes. Here we tested the contribution of auditory cues related to one’s own voice to these visually-driven effects. In a 2x2 factorial design, visual and auditory feedback on one’s own body were varied across conditions, which included embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of the illusion of owning a child’s body, opening up possibilities for health applications.
 
The data in this collection are part of The Hearing Body project, a project investigating how the manipulation of action sounds may alter the mental representation of one's body and the related emotional state and body behaviour. Other data collections part of The Hearing Body project have been deposited (Please see Related Resources section below). All parts 1 to 8 consist of experimental data, but they are data from different studies. Part 1, 2, 5 and 7 contain subjective reports and behavioural data; Part 3 and 4 contain subjective reports, behavioural data and data on electrodermal activity changes; Part 6 contains subjective reports, behavioural data and data on muscle activity changes (EMG); Part 8 contains subjective reports, behavioural data and data on voice frequency changes.The mental representation we have of our body is essential for successful interaction with the environment. This representation is not fixed, but is continuously updated in response to the available sensory information. While previous studies have highlighted the role of vision, touch and proprioception in constructing the body-representation in the brain, the role of auditory information remains largely unknown. Interestingly, the sounds that accompany almost every bodily movement are highly rich in information about the body and the space immediately surrounding it. For instance, the sounds produced when tapping on a surface inform us about the length and strength of our arm. 
This project will investigate how auditory information generated by our bodies updates our body-representation. A series of psychological experiments will explore how altering self-produced sounds in real-time changes different body-representations, including the representation of the space surrounding the body, the potential actions that we can perform and the emotional states linked to our body capabilities. This multidisciplinary and innovative research project will provide novel insights into the nature of body-representations and, ultimately, guide the design of audio-based applications that can improve body-image, self-esteem, movement patterns and social interactions to support wellbeing and rehabilitation for people with movement impairments.19:Tdfd,People’s mental representations of their own body are malleable and continuously updated through sensory cues. Altering one’s body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like attributes. Here we tested the contribution of auditory cues related to one’s own voice to these visually-driven effects. In a 2x2 factorial design, visual and auditory feedback on one’s own body were varied across conditions, which included embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of the illusion of owning a child’s body, opening up possibilities for health applications.
 
The data in this collection are part of The Hearing Body project, a project investigating how the manipulation of action sounds may alter the mental representation of one's body and the related emotional state and body behaviour. Other data collections part of The Hearing Body project have been deposited (Please see Related Resources section below). All parts 1 to 8 consist of experimental data, but they are data from different studies. Part 1, 2, 5 and 7 contain subjective reports and behavioural data; Part 3 and 4 contain subjective reports, behavioural data and data on electrodermal activity changes; Part 6 contains subjective reports, behavioural data and data on muscle activity changes (EMG); Part 8 contains subjective reports, behavioural data and data on voice frequency changes.The mental representation we have of our body is essential for successful interaction with the environment. This representation is not fixed, but is continuously updated in response to the available sensory information. While previous studies have highlighted the role of vision, touch and proprioception in constructing the body-representation in the brain, the role of auditory information remains largely unknown. Interestingly, the sounds that accompany almost every bodily movement are highly rich in information about the body and the space immediately surrounding it. For instance, the sounds produced when tapping on a surface inform us about the length and strength of our arm. 
This project will investigate how auditory information generated by our bodies updates our body-representation. A series of psychological experiments will explore how altering self-produced sounds in real-time changes different body-representations, including the representation of the space surrounding the body, the potential actions that we can perform and the emotional states linked to our body capabilities. This multidisciplinary and innovative research project will provide novel insights into the nature of body-representations and, ultimately, guide the design of audio-based applications that can improve body-image, self-esteem, movement patterns and social interactions to support wellbeing and rehabilitation for people with movement impairments.1a:Tdfd,People’s mental representations of their own body are malleable and continuously updated through sensory cues. Altering one’s body-representation can lead to changes in object perception and implicit attitudes. Virtual reality has been used to embody adults in the body of a 4-year-old child or a scaled-down adult body. Child embodiment was found to cause an overestimation of object sizes, approximately double that during adult embodiment, and identification of the self with child-like attributes. Here we tested the contribution of auditory cues related to one’s own voice to these visually-driven effects. In a 2x2 factorial design, visual and auditory feedback on one’s own body were varied across conditions, which included embodiment in a child or scaled-down adult body, and real (undistorted) or child-like voice feedback. The results replicated, in an older population, previous findings regarding size estimations and implicit attitudes. Further, although auditory cues were not found to enhance these effects, we show that the strength of the embodiment illusion depends on the child-like voice feedback being congruent or incongruent with the age of the virtual body. Results also showed the positive emotional impact of the illusion of owning a child’s body, opening up possibilities for health applications.
 
The data in this collection are part of The Hearing Body project, a project investigating how the manipulation of action sounds may alter the mental representation of one's body and the related emotional state and body behaviour. Other data collections part of The Hearing Body project have been deposited (Please see Related Resources section below). All parts 1 to 8 consist of experimental data, but they are data from different studies. Part 1, 2, 5 and 7 contain subjective reports and behavioural data; Part 3 and 4 contain subjective reports, behavioural data and data on electrodermal activity changes; Part 6 contains subjective reports, behavioural data and data on muscle activity changes (EMG); Part 8 contains subjective reports, behavioural data and data on voice frequency changes.The mental representation we have of our body is essential for successful interaction with the environment. This representation is not fixed, but is continuously updated in response to the available sensory information. While previous studies have highlighted the role of vision, touch and proprioception in constructing the body-representation in the brain, the role of auditory information remains largely unknown. Interestingly, the sounds that accompany almost every bodily movement are highly rich in information about the body and the space immediately surrounding it. For instance, the sounds produced when tapping on a surface inform us about the length and strength of our arm. 
This project will investigate how auditory information generated by our bodies updates our body-representation. A series of psychological experiments will explore how altering self-produced sounds in real-time changes different body-representations, including the representation of the space surrounding the body, the potential actions that we can perform and the emotional states linked to our body capabilities. This multidisciplinary and innovative research project will provide novel insights into the nature of body-representations and, ultimately, guide the design of audio-based applications that can improve body-image, self-esteem, movement patterns and social interactions to support wellbeing and rehabilitation for people with movement impairments.10:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"The hearing body: Experimental data, Part 8\n"}],["$","meta","2",{"name":"description","content":"$18"}],["$","meta","3",{"property":"og:title","content":"The hearing body: Experimental data, Part 8\n"}],["$","meta","4",{"property":"og:description","content":"$19"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/hearing-body-experimental-data-part-8"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"The hearing body: Experimental data, Part 8\n"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"The hearing body: Experimental data, Part 8\n"}],["$","meta","15",{"name":"twitter:description","content":"$1a"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
e:null
