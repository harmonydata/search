1:"$Sreact.fragment"
2:I[52332,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
3:I[65380,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"AuthProvider"]
4:I[41627,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"FirebaseProvider"]
5:"$Sreact.suspense"
6:I[92114,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"SearchProvider"]
7:I[94049,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
8:I[20190,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"default"]
9:I[9766,[],""]
a:I[98924,[],""]
b:I[74744,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","7213","static/js/7213.f8248d79.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","2619","static/js/2619.b8db57ac.js","3820","static/js/3820.af314958.js","5906","static/js/5906.206ff298.js","5738","static/js/5738.d28a9943.js","7177","static/js/app/layout.079f6f03.js"],"ToastContainer"]
d:I[24431,[],"OutletBoundary"]
f:I[15278,[],"AsyncMetadataOutlet"]
11:I[24431,[],"ViewportBoundary"]
13:I[24431,[],"MetadataBoundary"]
15:I[57150,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/e446a64f2ff89daf.css","style"]
0:{"P":null,"b":"669YHYfowfluJ5cB834U0","p":"/search","c":["","items","i-see-what-you-say-non-linguistic-factors-in-speechreading"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","i-see-what-you-say-non-linguistic-factors-in-speechreading","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/e446a64f2ff89daf.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":["$","$L6",null,{"children":[["$","$L7",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L8",null,{}],["$","$L7",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$Lb",null,{"position":"bottom-right"}]]}]}]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","i-see-what-you-say-non-linguistic-factors-in-speechreading","d"],["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":["$Le",["$","$Lf",null,{"promise":"$@10"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$L13",null,{"children":["$","div",null,{"hidden":true,"children":["$","$5",null,{"fallback":null,"children":"$L14"}]}]}]]}],false]],"m":"$undefined","G":["$15",[]],"s":false,"S":true}
16:I[41402,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","867","static/js/867.7f6bef5e.js","2939","static/js/2939.aa50df5c.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.87b66c06.js","8977","static/js/8977.89625695.js","6387","static/js/app/items/%5Bslug%5D/page.cedc9485.js"],""]
18:I[78977,["9692","static/js/9692.83f9877c.js","1828","static/js/1828.31087444.js","690","static/js/690.e023e61b.js","7133","static/js/7133.521b2ecd.js","9829","static/js/9829.124a89b0.js","867","static/js/867.7f6bef5e.js","2939","static/js/2939.aa50df5c.js","5183","static/js/5183.9f1a7545.js","5738","static/js/5738.d28a9943.js","3055","static/js/3055.87b66c06.js","8977","static/js/8977.89625695.js","6387","static/js/app/items/%5Bslug%5D/page.cedc9485.js"],"default"]
17:T67b,{"@context":"https://schema.org/","@type":"Dataset","name":"I see what you say: Non-linguistic factors in speechreading","description":"Visual information from a talker's mouth and face plays an important role in the perception and understanding of spoken language. Despite the importance of speechreading, relatively little is known about why some speakers are easier to speechread than others. For example, is it easier to speechread a familiar face compared with an unfamiliar one? Does the amount and manner of speech movement shown by the face affect speechreading performance? What about the structural make-up of the face? The aim of this new grant is to investigate these questions, focusing on non-linguistic factors that may influence why some faces are easier to speechread than others. In this grant we aim to manipulate the familiarity of different faces and measure how easy they are to speechread. In addition, we will compare the effects of speech manner and motion on the speechreadability of faces. Finally we will investigate the importance of facial hair, lip and teeth visability on speechreading performance. Investigation of these topics is important for practical and theoretical reasons. Understanding of this issue should help maximise the effectiveness of faces in conveying visual speech information. This may be particularly important for increasing communication, both with and by, hearing impaired people.","url":"https://harmonydata.ac.uk/search/items/i-see-what-you-say-non-linguistic-factors-in-speechreading","identifier":["http://dx.doi.org/10.5255/UKDA-SN-850204"],"keywords":[],"temporalCoverage":"2006-01-31/2008-07-31"}19:T514,Visual information from a talker's mouth and face plays an important role in the perception and understanding of spoken language. Despite the importance of speechreading, relatively little is known about why some speakers are easier to speechread than others. For example, is it easier to speechread a familiar face compared with an unfamiliar one? Does the amount and manner of speech movement shown by the face affect speechreading performance? What about the structural make-up of the face? The aim of this new grant is to investigate these questions, focusing on non-linguistic factors that may influence why some faces are easier to speechread than others. In this grant we aim to manipulate the familiarity of different faces and measure how easy they are to speechread. In addition, we will compare the effects of speech manner and motion on the speechreadability of faces. Finally we will investigate the importance of facial hair, lip and teeth visability on speechreading performance. Investigation of these topics is important for practical and theoretical reasons. Understanding of this issue should help maximise the effectiveness of faces in conveying visual speech information. This may be particularly important for increasing communication, both with and by, hearing impaired people.c:["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":[["$","$L16",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$17"}}],["$","$L18",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"I see what you say: Non-linguistic factors in speechreading","description":"$19","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850204","https://reshare.ukdataservice.ac.uk/850204"],"keywords":[],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-850204"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850204"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"}],"temporalCoverage":"2006-01-31/2008-07-31"},"extra_data":{"duration_years":2,"harmony_id":"ukds/850204","start_year":2006,"end_year":2008,"data_access":"The Data Collection is available for download to users registered with the UK Data Service.","urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850204","https://reshare.ukdataservice.ac.uk/850204"],"source":["ukds"],"geographic_coverage":"","num_variables":null,"genetic_data_collected":false,"language_codes":["en"],"dois":["http://dx.doi.org/10.5255/UKDA-SN-850204"],"sex":"male","instruments":[],"slug":"i-see-what-you-say-non-linguistic-factors-in-speechreading","ai_summary":null,"country_codes":["GB"],"study_design":[],"name":"I see what you say: Non-linguistic factors in speechreading","resource_type":"dataset","uuid":"2b72fdc7fcfc84a7d437d9e63241919d"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]}]
12:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
e:null
1a:T514,Visual information from a talker's mouth and face plays an important role in the perception and understanding of spoken language. Despite the importance of speechreading, relatively little is known about why some speakers are easier to speechread than others. For example, is it easier to speechread a familiar face compared with an unfamiliar one? Does the amount and manner of speech movement shown by the face affect speechreading performance? What about the structural make-up of the face? The aim of this new grant is to investigate these questions, focusing on non-linguistic factors that may influence why some faces are easier to speechread than others. In this grant we aim to manipulate the familiarity of different faces and measure how easy they are to speechread. In addition, we will compare the effects of speech manner and motion on the speechreadability of faces. Finally we will investigate the importance of facial hair, lip and teeth visability on speechreading performance. Investigation of these topics is important for practical and theoretical reasons. Understanding of this issue should help maximise the effectiveness of faces in conveying visual speech information. This may be particularly important for increasing communication, both with and by, hearing impaired people.1b:T514,Visual information from a talker's mouth and face plays an important role in the perception and understanding of spoken language. Despite the importance of speechreading, relatively little is known about why some speakers are easier to speechread than others. For example, is it easier to speechread a familiar face compared with an unfamiliar one? Does the amount and manner of speech movement shown by the face affect speechreading performance? What about the structural make-up of the face? The aim of this new grant is to investigate these questions, focusing on non-linguistic factors that may influence why some faces are easier to speechread than others. In this grant we aim to manipulate the familiarity of different faces and measure how easy they are to speechread. In addition, we will compare the effects of speech manner and motion on the speechreadability of faces. Finally we will investigate the importance of facial hair, lip and teeth visability on speechreading performance. Investigation of these topics is important for practical and theoretical reasons. Understanding of this issue should help maximise the effectiveness of faces in conveying visual speech information. This may be particularly important for increasing communication, both with and by, hearing impaired people.10:{"metadata":[["$","title","0",{"children":"I see what you say: Non-linguistic factors in speechreading"}],["$","meta","1",{"name":"description","content":"$1a"}],["$","meta","2",{"property":"og:title","content":"I see what you say: Non-linguistic factors in speechreading"}],["$","meta","3",{"property":"og:description","content":"$1b"}],["$","meta","4",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/i-see-what-you-say-non-linguistic-factors-in-speechreading"}],["$","meta","5",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","6",{"property":"og:locale","content":"en_US"}],["$","meta","7",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","8",{"property":"og:image:width","content":"1200"}],"$L1c","$L1d","$L1e","$L1f","$L20","$L21","$L22","$L23","$L24"],"error":null,"digest":"$undefined"}
26:I[80622,[],"IconMark"]
1c:["$","meta","9",{"property":"og:image:height","content":"630"}]
1d:["$","meta","10",{"property":"og:image:alt","content":"I see what you say: Non-linguistic factors in speechreading"}]
1e:["$","meta","11",{"property":"og:type","content":"website"}]
1f:["$","meta","12",{"name":"twitter:card","content":"summary_large_image"}]
20:["$","meta","13",{"name":"twitter:title","content":"I see what you say: Non-linguistic factors in speechreading"}]
25:T514,Visual information from a talker's mouth and face plays an important role in the perception and understanding of spoken language. Despite the importance of speechreading, relatively little is known about why some speakers are easier to speechread than others. For example, is it easier to speechread a familiar face compared with an unfamiliar one? Does the amount and manner of speech movement shown by the face affect speechreading performance? What about the structural make-up of the face? The aim of this new grant is to investigate these questions, focusing on non-linguistic factors that may influence why some faces are easier to speechread than others. In this grant we aim to manipulate the familiarity of different faces and measure how easy they are to speechread. In addition, we will compare the effects of speech manner and motion on the speechreadability of faces. Finally we will investigate the importance of facial hair, lip and teeth visability on speechreading performance. Investigation of these topics is important for practical and theoretical reasons. Understanding of this issue should help maximise the effectiveness of faces in conveying visual speech information. This may be particularly important for increasing communication, both with and by, hearing impaired people.21:["$","meta","14",{"name":"twitter:description","content":"$25"}]
22:["$","meta","15",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}]
23:["$","link","16",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]
24:["$","$L26","17",{}]
14:"$10:metadata"
