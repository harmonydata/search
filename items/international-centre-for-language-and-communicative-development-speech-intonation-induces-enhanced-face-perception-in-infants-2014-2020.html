<!DOCTYPE html><!--669YHYfowfluJ5cB834U0--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/e446a64f2ff89daf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.1a25c7f6.js"/><script src="/search/_next/static/js/4bd1b696.100b9d70.js" async=""></script><script src="/search/_next/static/js/1255.90e9842b.js" async=""></script><script src="/search/_next/static/js/main-app.0e7376d5.js" async=""></script><script src="/search/_next/static/js/9692.83f9877c.js" async=""></script><script src="/search/_next/static/js/1828.31087444.js" async=""></script><script src="/search/_next/static/js/7213.f8248d79.js" async=""></script><script src="/search/_next/static/js/690.e023e61b.js" async=""></script><script src="/search/_next/static/js/7133.521b2ecd.js" async=""></script><script src="/search/_next/static/js/9829.124a89b0.js" async=""></script><script src="/search/_next/static/js/2619.b8db57ac.js" async=""></script><script src="/search/_next/static/js/3820.af314958.js" async=""></script><script src="/search/_next/static/js/5906.206ff298.js" async=""></script><script src="/search/_next/static/js/5738.d28a9943.js" async=""></script><script src="/search/_next/static/js/app/layout.079f6f03.js" async=""></script><script src="/search/_next/static/js/867.7f6bef5e.js" async=""></script><script src="/search/_next/static/js/2939.aa50df5c.js" async=""></script><script src="/search/_next/static/js/5183.9f1a7545.js" async=""></script><script src="/search/_next/static/js/3055.87b66c06.js" async=""></script><script src="/search/_next/static/js/8977.89625695.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.cedc9485.js" async=""></script><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><meta name="next-size-adjust" content=""/><title>International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020</title><meta name="description" content="Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.

Learning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children&#x27;s brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.

The LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. 

LuCiD&#x27;s RESEARCH AGENDA will address four key questions in language and communicative development: 
1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? 
2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? 
3. COMMUNICATION: How do children learn to use their language to communicate effectively? 
4. VARIATION: How do children learn languages with different structures and in different cultural environments?

The fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children&#x27;s language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.

Applying different methods to study children&#x27;s language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children&#x27;s language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.

LuciD&#x27;s TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a &#x27;big data&#x27; management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER&#x27;S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children&#x27;s language development.

With the help of six IMPACT CHAMPIONS, LuCiD&#x27;s COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."/><meta property="og:title" content="International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020"/><meta property="og:description" content="Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.

Learning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children&#x27;s brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.

The LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. 

LuCiD&#x27;s RESEARCH AGENDA will address four key questions in language and communicative development: 
1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? 
2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? 
3. COMMUNICATION: How do children learn to use their language to communicate effectively? 
4. VARIATION: How do children learn languages with different structures and in different cultural environments?

The fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children&#x27;s language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.

Applying different methods to study children&#x27;s language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children&#x27;s language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.

LuciD&#x27;s TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a &#x27;big data&#x27; management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER&#x27;S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children&#x27;s language development.

With the help of six IMPACT CHAMPIONS, LuCiD&#x27;s COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020"/><meta name="twitter:description" content="Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.

Learning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children&#x27;s brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.

The LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. 

LuCiD&#x27;s RESEARCH AGENDA will address four key questions in language and communicative development: 
1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? 
2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? 
3. COMMUNICATION: How do children learn to use their language to communicate effectively? 
4. VARIATION: How do children learn languages with different structures and in different cultural environments?

The fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children&#x27;s language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.

Applying different methods to study children&#x27;s language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children&#x27;s language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.

LuciD&#x27;s TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a &#x27;big data&#x27; management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER&#x27;S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children&#x27;s language development.

With the help of six IMPACT CHAMPIONS, LuCiD&#x27;s COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><div hidden=""><!--$--><!--/$--></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.1a25c7f6.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[52332,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n3:I[65380,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"AuthProvider\"]\n4:I[41627,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[92114,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"SearchProvider\"]\n7:I[94049,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958."])</script><script>self.__next_f.push([1,"js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n8:I[20190,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n9:I[9766,[],\"\"]\na:I[98924,[],\"\"]\nb:I[74744,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"ToastContainer\"]\nd:I[24431,[],\"OutletBoundary\"]\n11:I[57150,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/e446a64f2ff89daf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"669YHYfowfluJ5cB834U0\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/e446a64f2ff89daf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",\"$Lf\"]}]]}],{},null,false]},null,false]},null,false]},null,false],\"$L10\",false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:I[15278,[],\"AsyncMetadataOutlet\"]\n14:I[24431,[],\"ViewportBoundary\"]\n16:I[24431,[],\"MetadataBoundary\"]\nf:[\"$\",\"$L12\",null,{\"promise\":\"$@13\"}]\n10:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L14\",null,{\"children\":\"$L15\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L16\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$5\",null,{\"fallback\":null,\"children\":\"$L17\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"18:I[41402,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"\"]\n19:T151e,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\",\"description\":\"Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.\\n\\nLearning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children's brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.\\n\\nThe LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. \\n\\nLuCiD's RESEARCH AGENDA will address four key questions in language and communicative development: \\n1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? \\n2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? \\n3. COMMUNICATION: How do children learn to use their language to communicate effectively? \\n4. VARIATION: How do children learn languages with different structures and in different cultural environments?\\n\\nThe fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children's language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.\\n\\nApplying different methods to study children's language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children's language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.\\n\\nLuciD's TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a 'big data' management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER'S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children's language development.\\n\\nWith the help of six IMPACT CHAMPIONS, LuCiD's COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings.\",\"url\":\"https://harmonydata.ac.uk/search/items/international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-854902\"],\"keywords\":[\"HUMAN BEHAVIOUR\",\"SOCIAL BEHAVIOUR\",\"LANGUAGE DEVELOPMENT\",\"INFANTS\"],\"temporalCoverage\":\"2014-09-01/2020-05-31\"}"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L18\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}],\"$L1a\"]}]\n"])</script><script>self.__next_f.push([1,"1b:I[78977,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"default\"]\n1c:T12c5,"])</script><script>self.__next_f.push([1,"Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.\n\nLearning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children's brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.\n\nThe LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. \n\nLuCiD's RESEARCH AGENDA will address four key questions in language and communicative development: \n1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? \n2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? \n3. COMMUNICATION: How do children learn to use their language to communicate effectively? \n4. VARIATION: How do children learn languages with different structures and in different cultural environments?\n\nThe fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children's language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.\n\nApplying different methods to study children's language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children's language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.\n\nLuciD's TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a 'big data' management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER'S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children's language development.\n\nWith the help of six IMPACT CHAMPIONS, LuCiD's COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."])</script><script>self.__next_f.push([1,"1a:[\"$\",\"$L1b\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\",\"description\":\"$1c\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854902\",\"https://reshare.ukdataservice.ac.uk/854902\"],\"keywords\":[\"HUMAN BEHAVIOUR\",\"SOCIAL BEHAVIOUR\",\"LANGUAGE DEVELOPMENT\",\"INFANTS\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-854902\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854902\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"ESRC\"}],\"temporalCoverage\":\"2014-09-01/2020-05-31\"},\"extra_data\":{\"instruments\":[],\"start_year\":2014,\"harmony_id\":\"ukds/854902\",\"end_year\":2020,\"data_access\":\"The Data Collection is available to any user without the requirement for registration for download/access.\",\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=854902\",\"https://reshare.ukdataservice.ac.uk/854902\"],\"source\":[\"ukds\"],\"geographic_coverage\":\"Lancaster\",\"genetic_data_collected\":false,\"num_variables\":null,\"slug\":\"international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\",\"language_codes\":[\"en\"],\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-854902\"],\"sex\":\"all\",\"study_design\":[],\"ai_summary\":null,\"resource_type\":\"dataset\",\"duration_years\":6,\"name\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\",\"country_codes\":[\"GB\"],\"uuid\":\"769b85e35719720730e4b6dacf5c14e2\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]\n"])</script><script>self.__next_f.push([1,"15:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"1d:T12c5,"])</script><script>self.__next_f.push([1,"Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.\n\nLearning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children's brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.\n\nThe LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. \n\nLuCiD's RESEARCH AGENDA will address four key questions in language and communicative development: \n1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? \n2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? \n3. COMMUNICATION: How do children learn to use their language to communicate effectively? \n4. VARIATION: How do children learn languages with different structures and in different cultural environments?\n\nThe fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children's language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.\n\nApplying different methods to study children's language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children's language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.\n\nLuciD's TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a 'big data' management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER'S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children's language development.\n\nWith the help of six IMPACT CHAMPIONS, LuCiD's COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."])</script><script>self.__next_f.push([1,"13:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$1d\"}],\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\",\"$L2d\"],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"30:I[80622,[],\"IconMark\"]\n1e:[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\"}]\n2e:T12c5,"])</script><script>self.__next_f.push([1,"Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.\n\nLearning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children's brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.\n\nThe LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. \n\nLuCiD's RESEARCH AGENDA will address four key questions in language and communicative development: \n1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? \n2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? \n3. COMMUNICATION: How do children learn to use their language to communicate effectively? \n4. VARIATION: How do children learn languages with different structures and in different cultural environments?\n\nThe fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children's language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.\n\nApplying different methods to study children's language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children's language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.\n\nLuciD's TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a 'big data' management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER'S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children's language development.\n\nWith the help of six IMPACT CHAMPIONS, LuCiD's COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."])</script><script>self.__next_f.push([1,"1f:[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"$2e\"}]\n20:[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/international-centre-for-language-and-communicative-development-speech-intonation-induces-enhanced-face-perception-in-infants-2014-2020\"}]\n21:[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}]\n22:[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}]\n23:[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n24:[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}]\n25:[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}]\n26:[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\"}]\n27:[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}]\n28:[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}]\n29:[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"International Centre for Language and Communicative Development: Speech Intonation Induces Enhanced Face Perception in Infants, 2014-2020\"}]\n2f:T12c5,"])</script><script>self.__next_f.push([1,"Infants’ preference for faces with direct compared to averted eye gaze, and for infant-directed over adult-directed speech, reflects early sensitivity to social communication. Here, we studied whether infant-directed speech (IDS), could affect the processing of a face with direct gaze in 4-month-olds. In a new ERP paradigm, the word ‘hello’ was uttered either in IDS or adult-direct speech (ADS) followed by an upright or inverted face. We show that the face-specific N290 ERP component was larger when faces were preceded by IDS relative to ADS. Crucially, this effect is specific to upright faces, whereas inverted faces preceded by IDS elicited larger attention-related P1 and Nc. These results suggest that IDS generates communicative expectations in infants. When such expectations are met by a following social stimulus – an upright face – infants are already prepared to process it. When the stimulus is a non-social one –inverted face – IDS merely increases general attention.The International Centre for Language and Communicative Development (LuCiD) will bring about a transformation in our understanding of how children learn to communicate, and deliver the crucial information needed to design effective interventions in child healthcare, communicative development and early years education.\n\nLearning to use language to communicate is hugely important for society. Failure to develop language and communication skills at the right age is a major predictor of educational and social inequality in later life. To tackle this problem, we need to know the answers to a number of questions: How do children learn language from what they see and hear? What do measures of children's brain activity tell us about what they know? and How do differences between children and differences in their environments affect how children learn to talk? Answering these questions is a major challenge for researchers. LuCiD will bring together researchers from a wide range of different backgrounds to address this challenge.\n\nThe LuCiD Centre will be based in the North West of England and will coordinate five streams of research in the UK and abroad. It will use multiple methods to address central issues, create new technology products, and communicate evidence-based information directly to other researchers and to parents, practitioners and policy-makers. \n\nLuCiD's RESEARCH AGENDA will address four key questions in language and communicative development: \n1. ENVIRONMENT: How do children combine the different kinds of information that they see and hear to learn language? \n2. KNOWLEDGE: How do children learn the word meanings and grammatical categories of their language? \n3. COMMUNICATION: How do children learn to use their language to communicate effectively? \n4. VARIATION: How do children learn languages with different structures and in different cultural environments?\n\nThe fifth stream, the LANGUAGE 0-5 PROJECT, will connect the other four streams. It will follow 80 English learning children from 6 months to 5 years, studying how and why some children's language development is different from others. A key feature of this project is that the children will take part in studies within the other four streams. This will enable us to build a complete picture of language development from the very beginning through to school readiness.\n\nApplying different methods to study children's language development will constrain the types of explanations that can be proposed, helping us create much more accurate theories of language development. We will observe and record children in natural interaction as well as studying their language in more controlled experiments, using behavioural measures and correlations with brain activity (EEG). Transcripts of children's language and interaction will be analysed and used to model how these two are related using powerful computer algorithms.\n\nLuciD's TECHNOLOGY AGENDA will develop new multi-method approaches and create new technology products for researchers, healthcare and education professionals. We will build a 'big data' management and sharing system to make all our data freely available; create a toolkit of software (LANGUAGE RESEARCHER'S TOOLKIT) so that researchers can analyse speech more easily and more accurately; and develop a smartphone app (the BABYTALK APP) that will allow parents, researchers and practitioners to monitor, assess and promote children's language development.\n\nWith the help of six IMPACT CHAMPIONS, LuCiD's COMMUNICATIONS AGENDA will ensure that parents know how they can best help their children learn to talk, and give healthcare and education professionals and policy-makers the information they need to create intervention programmes that are firmly rooted in the latest research findings."])</script><script>self.__next_f.push([1,"2a:[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"$2f\"}]\n2b:[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n2c:[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]\n2d:[\"$\",\"$L30\",\"17\",{}]\n17:\"$13:metadata\"\n"])</script></body></html>