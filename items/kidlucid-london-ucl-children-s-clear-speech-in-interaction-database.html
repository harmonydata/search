<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/0d5b820fee8240e5.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.22ffbd0e.js"/><script src="/search/_next/static/js/4bd1b696.f7584cea.js" async=""></script><script src="/search/_next/static/js/1517.db76c303.js" async=""></script><script src="/search/_next/static/js/main-app.bd11093a.js" async=""></script><script src="/search/_next/static/js/6586.2e946dbf.js" async=""></script><script src="/search/_next/static/js/9197.61b93e42.js" async=""></script><script src="/search/_next/static/js/8378.a1bea36e.js" async=""></script><script src="/search/_next/static/js/2926.76e4f620.js" async=""></script><script src="/search/_next/static/js/8173.582c8c90.js" async=""></script><script src="/search/_next/static/js/1702.de0c2d51.js" async=""></script><script src="/search/_next/static/js/1983.ec5be3f4.js" async=""></script><script src="/search/_next/static/js/7184.52d31c32.js" async=""></script><script src="/search/_next/static/js/4398.8644925b.js" async=""></script><script src="/search/_next/static/js/app/layout.0819bb7e.js" async=""></script><script src="/search/_next/static/js/2282.e20001b9.js" async=""></script><script src="/search/_next/static/js/5135.b8bfc30e.js" async=""></script><script src="/search/_next/static/js/9387.65629b75.js" async=""></script><script src="/search/_next/static/js/2649.95608f08.js" async=""></script><script src="/search/_next/static/js/1857.a01744c0.js" async=""></script><script src="/search/_next/static/js/7626.2947408f.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.0f65d92f.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>kidLUCID: London UCL Children&#x27;s clear speech in interaction database</title><meta name="description" content="This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.
The SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  
This project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.
A large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.
We investigated how the ability to produce &#x27;clear&#x27; speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.
This work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."/><meta property="og:title" content="kidLUCID: London UCL Children&#x27;s clear speech in interaction database"/><meta property="og:description" content="This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.
The SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  
This project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.
A large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.
We investigated how the ability to produce &#x27;clear&#x27; speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.
This work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/kidlucid-london-ucl-children-s-clear-speech-in-interaction-database"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="kidLUCID: London UCL Children&#x27;s clear speech in interaction database"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="kidLUCID: London UCL Children&#x27;s clear speech in interaction database"/><meta name="twitter:description" content="This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.
The SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  
This project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.
A large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.
We investigated how the ability to produce &#x27;clear&#x27; speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.
This work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.22ffbd0e.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n3:I[17146,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"AuthProvider\"]\n4:I[83705,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[63612,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"SearchProvider\"]\n7:I[68998,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n8:I[98904,[\"6586\",\"static/js/6586.2e946d"])</script><script>self.__next_f.push([1,"bf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n9:I[15244,[],\"\"]\na:I[43866,[],\"\"]\nb:I[14046,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"ToastContainer\"]\nd:I[86213,[],\"OutletBoundary\"]\nf:I[86213,[],\"MetadataBoundary\"]\n11:I[86213,[],\"ViewportBoundary\"]\n13:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/0d5b820fee8240e5.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"hHFVRgYXxM8of7-CzK8yz\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/0d5b820fee8240e5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"8rbG8SG_PBtrAATgpK9XO\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$13\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"14:I[53704,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"5135\",\"static/js/5135.b8bfc30e.js\",\"9387\",\"static/js/9387.65629b75.js\",\"2649\",\"static/js/2649.95608f08.js\",\"4398\",\"static/js/4398.8644925b.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.2947408f.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0f65d92f.js\"],\"\"]\n16:I[77626,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"5135\",\"static/js/5135.b8bfc30e.js\",\"9387\",\"static/js/9387.65629b75.js\",\"2649\",\"static/js/2649.95608f08.js\",\"4398\",\"static/js/4398.8644925b.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.2947408f.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0f65d92f.js\"],\"default\"]\n15:Tb1f,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"kidLUCID: London UCL Children's clear speech in interaction database\",\"description\":\"This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.\\nThe SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  \\nThis project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.\\nA large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.\\nWe investigated how the ability to produce 'clear' speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.\\nThis work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech.\",\"url\":\"https://harmonydata.ac.uk/search/items/kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-851525\"],\"keywords\":[\"SPEECH\",\"ACOUSTICS\",\"COMMUNICATION RESEARCH\"],\"temporalCoverage\":\"2011-06-01/2014-05-31\"}"])</script><script>self.__next_f.push([1,"17:T974,"])</script><script>self.__next_f.push([1,"This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.\nThe SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  \nThis project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.\nA large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.\nWe investigated how the ability to produce 'clear' speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.\nThis work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L14\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}],[\"$\",\"$L16\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"kidLUCID: London UCL Children's clear speech in interaction database\",\"description\":\"$17\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851525\",\"https://reshare.ukdataservice.ac.uk/851525\"],\"keywords\":[\"SPEECH\",\"ACOUSTICS\",\"COMMUNICATION RESEARCH\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-851525\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851525\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"Economic and Social Research Council\"}],\"temporalCoverage\":\"2011-06-01/2014-05-31\"},\"extra_data\":{\"language_codes\":[\"en\"],\"harmony_id\":\"ukds/851525\",\"genetic_data_collected\":false,\"data_access\":\"The Data Collection is available to any user without the requirement for registration for download/access.\\n\",\"sex\":\"male\",\"source\":[\"ukds\"],\"slug\":\"kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\",\"geographic_coverage\":\"London\",\"duration_years\":3,\"resource_type\":\"dataset\",\"end_year\":2014,\"instruments\":[],\"study_design\":[],\"ai_summary\":null,\"name\":\"kidLUCID: London UCL Children's clear speech in interaction database\",\"country_codes\":[\"GB\"],\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-851525\"],\"start_year\":2011,\"num_variables\":null,\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=851525\",\"https://reshare.ukdataservice.ac.uk/851525\"],\"uuid\":\"94ef8448cea1d7a28f3f4f4a1f757579\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]]}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"18:T974,"])</script><script>self.__next_f.push([1,"This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.\nThe SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  \nThis project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.\nA large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.\nWe investigated how the ability to produce 'clear' speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.\nThis work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."])</script><script>self.__next_f.push([1,"19:T974,"])</script><script>self.__next_f.push([1,"This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.\nThe SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  \nThis project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.\nA large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.\nWe investigated how the ability to produce 'clear' speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.\nThis work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."])</script><script>self.__next_f.push([1,"1a:T974,"])</script><script>self.__next_f.push([1,"This collection contains the quantitative data resulting from the analysis of the kidLUCID audio corpus – a set of speech recordings collected for 96 children aged 9 to 14 years inclusive. Recordings were made while participants carried out a collaborative ‘spot the difference’ picture task (‘diapix’) in pairs in three different conditions: (1) in good listening conditions when both could hear each other normally (‘no barrier’ or NB condition), or when perception was impaired for one of the participants by (2) distorting the input they received from their conversation partner via a three channel vocoder (VOC condition) or (3) by adding multispeaker babble noise (BAB condition). The aim was to examine the clarification strategies used by children in adverse communicative conditions to maintain effective communication.\nThe SPSS spreadsheet contains, for each of the 96 participants, quantitative data resulting from (a) the acoustic analysis of the recordings, (b) measures of communication efficiency and (c) perceptual ratings of clarity collected for excerpts from the recordings.  \nThis project investigates how children learn to adapt their speech to maximise communication effectiveness in difficult listening situations. Little is known about how this crucial skill develops and at what age it reaches maturity.\nA large corpus of speech from 96 children aged 9-14 years was recorded, with pairs of children working cooperatively to complete a ‘spot the difference’ picture task. The task was conducted in good and poor listening conditions so as to be able to analyse how children clarify their speech to overcome the communication barrier.\nWe investigated how the ability to produce 'clear' speech develops, whether children make similar acoustic-phonetic enhancements as adults, and whether these vary according to the communication barrier. We related the perceived clarity of individual speakers to the acoustic-phonetic characteristics of their speech.\nThis work helps to expand models of speech production such as Lindblom’s Hyper-Hypo model. Understanding how children control their speech production is important for developing better strategies for communication with children with hearing or language impairments, and in noisy environments. The LUCID Child corpus (kidLUCID), fully transcribed and web-accessible, is a rich resource for a range of analyses of child speech."])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"kidLUCID: London UCL Children's clear speech in interaction database\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$18\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"kidLUCID: London UCL Children's clear speech in interaction database\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$19\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/kidlucid-london-ucl-children-s-clear-speech-in-interaction-database\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"kidLUCID: London UCL Children's clear speech in interaction database\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"kidLUCID: London UCL Children's clear speech in interaction database\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$1a\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"e:null\n"])</script></body></html>