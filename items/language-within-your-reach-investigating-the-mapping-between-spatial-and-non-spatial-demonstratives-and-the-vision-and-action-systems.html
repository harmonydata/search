<!DOCTYPE html><!--cvcjOqEnh44pDWmtY9X7b--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/e446a64f2ff89daf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.ccaf2443.js"/><script src="/search/_next/static/js/4bd1b696.100b9d70.js" async=""></script><script src="/search/_next/static/js/1255.90e9842b.js" async=""></script><script src="/search/_next/static/js/main-app.0e7376d5.js" async=""></script><script src="/search/_next/static/js/9692.83f9877c.js" async=""></script><script src="/search/_next/static/js/421.98ca62d9.js" async=""></script><script src="/search/_next/static/js/1759.b13f3ee1.js" async=""></script><script src="/search/_next/static/js/3535.878ceef2.js" async=""></script><script src="/search/_next/static/js/2619.b8db57ac.js" async=""></script><script src="/search/_next/static/js/3820.af314958.js" async=""></script><script src="/search/_next/static/js/574.fd20103e.js" async=""></script><script src="/search/_next/static/js/5738.d28a9943.js" async=""></script><script src="/search/_next/static/js/app/layout.7ef30b9e.js" async=""></script><script src="/search/_next/static/js/690.e023e61b.js" async=""></script><script src="/search/_next/static/js/5332.4ca3e6c6.js" async=""></script><script src="/search/_next/static/js/2410.ec36c5aa.js" async=""></script><script src="/search/_next/static/js/5183.9f1a7545.js" async=""></script><script src="/search/_next/static/js/3055.2a4989ee.js" async=""></script><script src="/search/_next/static/js/8977.d520dad7.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.0819d17d.js" async=""></script><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><meta name="next-size-adjust" content=""/><title>Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems</title><meta name="description" content="Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg &#x27;this cup&#x27;, &#x27;that spoon&#x27;) to describe where objects are placed and when they were placed. Using the &#x27;memory game&#x27; method (Coventry, Vald&#x27;s, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"/><meta property="og:title" content="Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems"/><meta property="og:description" content="Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg &#x27;this cup&#x27;, &#x27;that spoon&#x27;) to describe where objects are placed and when they were placed. Using the &#x27;memory game&#x27; method (Coventry, Vald&#x27;s, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems"/><meta name="twitter:description" content="Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg &#x27;this cup&#x27;, &#x27;that spoon&#x27;) to describe where objects are placed and when they were placed. Using the &#x27;memory game&#x27; method (Coventry, Vald&#x27;s, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><div hidden=""><!--$--><!--/$--></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.ccaf2443.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[52332,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n3:I[65380,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"AuthProvider\"]\n4:I[41627,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[92114,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"SearchProvider\"]\n7:I[94049,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n8:I[20190,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/j"])</script><script>self.__next_f.push([1,"s/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n9:I[9766,[],\"\"]\na:I[98924,[],\"\"]\nb:I[74744,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"ToastContainer\"]\nd:I[24431,[],\"OutletBoundary\"]\n11:I[57150,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/e446a64f2ff89daf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"cvcjOqEnh44pDWmtY9X7b\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/e446a64f2ff89daf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",\"$Lf\"]}]]}],{},null,false]},null,false]},null,false]},null,false],\"$L10\",false]],\"m\":\"$undefined\",\"G\":[\"$11\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"12:I[15278,[],\"AsyncMetadataOutlet\"]\n14:I[24431,[],\"ViewportBoundary\"]\n16:I[24431,[],\"MetadataBoundary\"]\nf:[\"$\",\"$L12\",null,{\"promise\":\"$@13\"}]\n10:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L14\",null,{\"children\":\"$L15\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L16\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$5\",null,{\"fallback\":null,\"children\":\"$L17\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"18:I[41402,[\"9692\",\"static/js/9692.83f9877c.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"690\",\"static/js/690.e023e61b.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"5332\",\"static/js/5332.4ca3e6c6.js\",\"2410\",\"static/js/2410.ec36c5aa.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.2a4989ee.js\",\"8977\",\"static/js/8977.d520dad7.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0819d17d.js\"],\"\"]\n1a:I[78977,[\"9692\",\"static/js/9692.83f9877c.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"690\",\"static/js/690.e023e61b.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"5332\",\"static/js/5332.4ca3e6c6.js\",\"2410\",\"static/js/2410.ec36c5aa.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.2a4989ee.js\",\"8977\",\"static/js/8977.d520dad7.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0819d17d.js\"],\"default\"]\n19:T70f,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\",\"description\":\"Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg 'this cup', 'that spoon') to describe where objects are placed and when they were placed. Using the 'memory game' method (Coventry, Vald's, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:\",\"url\":\"https://harmonydata.ac.uk/search/items/language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-850814\"],\"keywords\":[],\"temporalCoverage\":\"2011-01-31/2012-09-15\"}"])</script><script>self.__next_f.push([1,"1b:T512,"])</script><script>self.__next_f.push([1,"Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg 'this cup', 'that spoon') to describe where objects are placed and when they were placed. Using the 'memory game' method (Coventry, Vald's, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L18\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$19\"}}],[\"$\",\"$L1a\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\",\"description\":\"$1b\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850814\",\"https://reshare.ukdataservice.ac.uk/850814\"],\"keywords\":[],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-850814\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850814\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"Economic and Social Research Council\"}],\"temporalCoverage\":\"2011-01-31/2012-09-15\"},\"extra_data\":{\"geographic_coverage\":\"\",\"start_year\":2011,\"harmony_id\":\"ukds/850814\",\"end_year\":2012,\"data_access\":\"The Data Collection is available for download to users registered with the UK Data Service.\",\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850814\",\"https://reshare.ukdataservice.ac.uk/850814\"],\"source\":[\"ukds\"],\"name\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\",\"slug\":\"language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\",\"num_variables\":null,\"language_codes\":[\"en\"],\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-850814\"],\"sex\":\"all\",\"instruments\":[],\"study_design\":[],\"ai_summary\":null,\"duration_years\":1,\"country_codes\":[\"GB\"],\"resource_type\":\"dataset\",\"genetic_data_collected\":false,\"uuid\":\"01acbc237d0dd72ffc1406e56d72a633\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]]}]\n"])</script><script>self.__next_f.push([1,"15:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"1c:T512,"])</script><script>self.__next_f.push([1,"Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg 'this cup', 'that spoon') to describe where objects are placed and when they were placed. Using the 'memory game' method (Coventry, Vald's, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"])</script><script>self.__next_f.push([1,"1d:T512,"])</script><script>self.__next_f.push([1,"Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg 'this cup', 'that spoon') to describe where objects are placed and when they were placed. Using the 'memory game' method (Coventry, Vald's, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"])</script><script>self.__next_f.push([1,"13:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$1c\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"$1d\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/language-within-your-reach-investigating-the-mapping-between-spatial-and-non-spatial-demonstratives-and-the-vision-and-action-systems\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\"],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"2b:I[80622,[],\"IconMark\"]\n1e:[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}]\n1f:[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n20:[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}]\n21:[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}]\n22:[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\"}]\n23:[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}]\n24:[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}]\n25:[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Language within your reach? Investigating the mapping between spatial and non-spatial demonstratives and the vision and action systems\"}]\n2a:T512,"])</script><script>self.__next_f.push([1,"Communication involves a combination of speech and gestures which afford joint attention between speaker and hearer. In this grant the mapping between language and the vision and action systems is targeted by examining how people use spatial and temporal demonstratives (eg 'this cup', 'that spoon') to describe where objects are placed and when they were placed. Using the 'memory game' method (Coventry, Vald's, Castillo and Guijarro-Fuentes, 2008), a series of experiments will investigate whether the basic perceptual distinction between near space (space within graspable distance) and far space (space out of graspable reach) underpins spatial demonstrative use in English, and if memory for object location is also affected by this basic perceptual contrast. Further experiments will establish whether variables that are important for demonstrative systems in other languages (such as whether an object is visible to the speaker, owned by the speaker, etc) also affect demonstrative choice in English, and if these in turn map onto basic perceptual distinctions. Finally virtual reality technology will be used to examine the nature of the mapping between spatial and temporal uses of demonstratives. Overall this project will help elucidate the mapping between three main cognitive systems:"])</script><script>self.__next_f.push([1,"26:[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"$2a\"}]\n27:[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n28:[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]\n29:[\"$\",\"$L2b\",\"17\",{}]\n17:\"$13:metadata\"\n"])</script></body></html>