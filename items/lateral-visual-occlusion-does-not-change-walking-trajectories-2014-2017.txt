1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"Yszxikv156HYdAQ3Lb4Aj","p":"/search","c":["","items","lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",null,["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","dzuFeL5vSS_7svrLfdWCM",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],""]
14:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],"default"]
13:T1104,{"@context":"https://schema.org/","@type":"Dataset","name":"Lateral visual occlusion does not change walking trajectories 2014-2017","description":"Here, we isolated and examined the effect of lateralised vision loss on walking behaviour in real and virtual environments. Healthy young participants walked to a target placed within a real room, a virtual corridor, or on a virtual ground plane. In the ground plane condition, the scene was either empty or contained three obstacles. We reduced vision on one side by occluding one eye (Experiment 1 and 2) or removal of one hemifield, defined relative to either the head or trunk (Experiment 2), through use of eye-patching (Experiment 1) and a Virtual Reality system (Experiment 2). Visual field restrictions did not induce significant deviations in walking paths in any of the occlusion conditions or any of the environments. The results provide further insight into the visual information that guides walking in humans and suggest that lateralised vision loss per se is not the primary cause of walking difficulties.\nDifficulties with walking are often reported following brain damage that causes a lateralised loss of awareness on one side. Whether lateralised loss of awareness has a direct causal impact on walking is unknown. A review of the literature on visually guided walking suggests several reasons why a lateralised loss of visual awareness might be expected to lead to difficulties walking.\nA long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain \"compensates\" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing.\nThe project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.","url":"https://harmonydata.ac.uk/search/items/lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017","identifier":["http://dx.doi.org/10.5255/UKDA-SN-853221"],"keywords":["WALKING","HEMIANOPIA","VISUAL NEGLECT","OPTIC FLOW","VIRTUAL REALITY"],"temporalCoverage":"2014-08-01/2017-10-31"}15:Tf39,Here, we isolated and examined the effect of lateralised vision loss on walking behaviour in real and virtual environments. Healthy young participants walked to a target placed within a real room, a virtual corridor, or on a virtual ground plane. In the ground plane condition, the scene was either empty or contained three obstacles. We reduced vision on one side by occluding one eye (Experiment 1 and 2) or removal of one hemifield, defined relative to either the head or trunk (Experiment 2), through use of eye-patching (Experiment 1) and a Virtual Reality system (Experiment 2). Visual field restrictions did not induce significant deviations in walking paths in any of the occlusion conditions or any of the environments. The results provide further insight into the visual information that guides walking in humans and suggest that lateralised vision loss per se is not the primary cause of walking difficulties.
Difficulties with walking are often reported following brain damage that causes a lateralised loss of awareness on one side. Whether lateralised loss of awareness has a direct causal impact on walking is unknown. A review of the literature on visually guided walking suggests several reasons why a lateralised loss of visual awareness might be expected to lead to difficulties walking.
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing.
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Lateral visual occlusion does not change walking trajectories 2014-2017","description":"$15","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853221","https://reshare.ukdataservice.ac.uk/853221"],"keywords":["WALKING","HEMIANOPIA","VISUAL NEGLECT","OPTIC FLOW","VIRTUAL REALITY"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-853221"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853221"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"}],"temporalCoverage":"2014-08-01/2017-10-31"},"extra_data":{"study_design":[],"urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=853221","https://reshare.ukdataservice.ac.uk/853221"],"dois":["http://dx.doi.org/10.5255/UKDA-SN-853221"],"ai_summary":null,"language_codes":["en"],"name":"Lateral visual occlusion does not change walking trajectories 2014-2017","num_variables":null,"country_codes":["GB"],"duration_years":3,"sex":"male","source":["ukds"],"geographic_coverage":"Cardiff","resource_type":"dataset","genetic_data_collected":false,"start_year":2014,"instruments":[],"slug":"lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017","end_year":2017,"data_access":"The Data Collection is available to any user without the requirement for registration for download/access.","harmony_id":"ukds/853221","uuid":"d8c0b30a049ffe27dd375b0f2e16481b"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:Tf39,Here, we isolated and examined the effect of lateralised vision loss on walking behaviour in real and virtual environments. Healthy young participants walked to a target placed within a real room, a virtual corridor, or on a virtual ground plane. In the ground plane condition, the scene was either empty or contained three obstacles. We reduced vision on one side by occluding one eye (Experiment 1 and 2) or removal of one hemifield, defined relative to either the head or trunk (Experiment 2), through use of eye-patching (Experiment 1) and a Virtual Reality system (Experiment 2). Visual field restrictions did not induce significant deviations in walking paths in any of the occlusion conditions or any of the environments. The results provide further insight into the visual information that guides walking in humans and suggest that lateralised vision loss per se is not the primary cause of walking difficulties.
Difficulties with walking are often reported following brain damage that causes a lateralised loss of awareness on one side. Whether lateralised loss of awareness has a direct causal impact on walking is unknown. A review of the literature on visually guided walking suggests several reasons why a lateralised loss of visual awareness might be expected to lead to difficulties walking.
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing.
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.17:Tf39,Here, we isolated and examined the effect of lateralised vision loss on walking behaviour in real and virtual environments. Healthy young participants walked to a target placed within a real room, a virtual corridor, or on a virtual ground plane. In the ground plane condition, the scene was either empty or contained three obstacles. We reduced vision on one side by occluding one eye (Experiment 1 and 2) or removal of one hemifield, defined relative to either the head or trunk (Experiment 2), through use of eye-patching (Experiment 1) and a Virtual Reality system (Experiment 2). Visual field restrictions did not induce significant deviations in walking paths in any of the occlusion conditions or any of the environments. The results provide further insight into the visual information that guides walking in humans and suggest that lateralised vision loss per se is not the primary cause of walking difficulties.
Difficulties with walking are often reported following brain damage that causes a lateralised loss of awareness on one side. Whether lateralised loss of awareness has a direct causal impact on walking is unknown. A review of the literature on visually guided walking suggests several reasons why a lateralised loss of visual awareness might be expected to lead to difficulties walking.
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing.
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.18:Tf39,Here, we isolated and examined the effect of lateralised vision loss on walking behaviour in real and virtual environments. Healthy young participants walked to a target placed within a real room, a virtual corridor, or on a virtual ground plane. In the ground plane condition, the scene was either empty or contained three obstacles. We reduced vision on one side by occluding one eye (Experiment 1 and 2) or removal of one hemifield, defined relative to either the head or trunk (Experiment 2), through use of eye-patching (Experiment 1) and a Virtual Reality system (Experiment 2). Visual field restrictions did not induce significant deviations in walking paths in any of the occlusion conditions or any of the environments. The results provide further insight into the visual information that guides walking in humans and suggest that lateralised vision loss per se is not the primary cause of walking difficulties.
Difficulties with walking are often reported following brain damage that causes a lateralised loss of awareness on one side. Whether lateralised loss of awareness has a direct causal impact on walking is unknown. A review of the literature on visually guided walking suggests several reasons why a lateralised loss of visual awareness might be expected to lead to difficulties walking.
A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing.
The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Lateral visual occlusion does not change walking trajectories 2014-2017"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Lateral visual occlusion does not change walking trajectories 2014-2017"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/lateral-visual-occlusion-does-not-change-walking-trajectories-2014-2017"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Lateral visual occlusion does not change walking trajectories 2014-2017"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Lateral visual occlusion does not change walking trajectories 2014-2017"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
