1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"oOvDuJZyQIOPELToyx8Mb","p":"/search","c":["","items","mapping-the-cultural-landscape-of-emotions-for-social-interaction"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","mapping-the-cultural-landscape-of-emotions-for-social-interaction","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","mapping-the-cultural-landscape-of-emotions-for-social-interaction","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",null,["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","Bwyq8VOHzQ69_XdRMPpei",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],""]
14:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],"default"]
13:T956,{"@context":"https://schema.org/","@type":"Dataset","name":"Mapping the cultural landscape of emotions for social interaction","description":"This project collected images, videos, .mat files and MS Excel spreadsheets. The images are in a variety of formats, including .tiff and .jpg. The videos also came in a variety of formats, including .avi and .mp4. Images were of faces of individuals. The videos are of dynamic facial expression models displayed on individual face identities. The data set includes approximately 30,000 images and videos. With rapid globalisation, cross-cultural communication is integral to modern society, with mutual understanding of emotions central to successful social interaction. This research examines the complexities of cross-cultural communication.\n\nCombining eye movements, computational modelling, and state-of-the-art 4D computer graphics, Dr Jack’s work (featuring in National Geographic, Discovery Channel Magazine) refutes universality, highlighting knowledge gaps. The aim is to bridge these gaps during the award. (1) Which emotions are primary across cultures? Using semantic network reconstruction tools, the conceptual landscape of emotions and identify the primary emotions across cultures will be mapped. (2) Which facial movements signal culture-specific emotions? Using a unique 4-D facial animation platform, dynamic mental models of a spectrum of culture-specific facial expressions will be constructed. (3) How accurate is cross-cultural emotion communication? Conducting previously impossible research with advanced stimuli, same- and other-culture facial expression recognition will be examined. Eye-tracking will identify facial signals supporting accurate recognition and creating confusion. Is there an in-group advantage?\n\nBy interchanging race of face with culture-specific emotions (eg, Eastern emotion on a white face), Dr Jack will precisely examine the in-group advantage theory.\nBenefits. With broad implications, this work will bridge scientific knowledge gaps and make timely contributions to the rapidly evolving communication needs of society.","url":"https://harmonydata.ac.uk/search/items/mapping-the-cultural-landscape-of-emotions-for-social-interaction","identifier":["http://dx.doi.org/10.5255/UKDA-SN-852278"],"keywords":["SOCIAL BEHAVIOUR","CULTURAL BEHAVIOUR"],"temporalCoverage":"2012-12-31/2015-12-30"}15:T7b6,This project collected images, videos, .mat files and MS Excel spreadsheets. The images are in a variety of formats, including .tiff and .jpg. The videos also came in a variety of formats, including .avi and .mp4. Images were of faces of individuals. The videos are of dynamic facial expression models displayed on individual face identities. The data set includes approximately 30,000 images and videos. With rapid globalisation, cross-cultural communication is integral to modern society, with mutual understanding of emotions central to successful social interaction. This research examines the complexities of cross-cultural communication.

Combining eye movements, computational modelling, and state-of-the-art 4D computer graphics, Dr Jack’s work (featuring in National Geographic, Discovery Channel Magazine) refutes universality, highlighting knowledge gaps. The aim is to bridge these gaps during the award. (1) Which emotions are primary across cultures? Using semantic network reconstruction tools, the conceptual landscape of emotions and identify the primary emotions across cultures will be mapped. (2) Which facial movements signal culture-specific emotions? Using a unique 4-D facial animation platform, dynamic mental models of a spectrum of culture-specific facial expressions will be constructed. (3) How accurate is cross-cultural emotion communication? Conducting previously impossible research with advanced stimuli, same- and other-culture facial expression recognition will be examined. Eye-tracking will identify facial signals supporting accurate recognition and creating confusion. Is there an in-group advantage?

By interchanging race of face with culture-specific emotions (eg, Eastern emotion on a white face), Dr Jack will precisely examine the in-group advantage theory.
Benefits. With broad implications, this work will bridge scientific knowledge gaps and make timely contributions to the rapidly evolving communication needs of society.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Mapping the cultural landscape of emotions for social interaction","description":"$15","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852278","https://reshare.ukdataservice.ac.uk/852278"],"keywords":["SOCIAL BEHAVIOUR","CULTURAL BEHAVIOUR"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-852278"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852278"}],"sponsor":[{"@type":"Organization","name":"ESRC"}],"temporalCoverage":"2012-12-31/2015-12-30"},"extra_data":{"study_design":[],"duration_years":3,"source":["ukds"],"slug":"mapping-the-cultural-landscape-of-emotions-for-social-interaction","language_codes":["en"],"instruments":[],"geographic_coverage":"UK","name":"Mapping the cultural landscape of emotions for social interaction","num_variables":null,"country_codes":["GB"],"data_access":"The Data Collection is available from an external repository. Access is available via Related Resources.","ai_summary":null,"sex":"male","resource_type":"dataset","dois":["http://dx.doi.org/10.5255/UKDA-SN-852278"],"end_year":2015,"genetic_data_collected":false,"harmony_id":"ukds/852278","urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852278","https://reshare.ukdataservice.ac.uk/852278"],"start_year":2012,"uuid":"8162ee379a89bd3d258659a98393732f"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T7b6,This project collected images, videos, .mat files and MS Excel spreadsheets. The images are in a variety of formats, including .tiff and .jpg. The videos also came in a variety of formats, including .avi and .mp4. Images were of faces of individuals. The videos are of dynamic facial expression models displayed on individual face identities. The data set includes approximately 30,000 images and videos. With rapid globalisation, cross-cultural communication is integral to modern society, with mutual understanding of emotions central to successful social interaction. This research examines the complexities of cross-cultural communication.

Combining eye movements, computational modelling, and state-of-the-art 4D computer graphics, Dr Jack’s work (featuring in National Geographic, Discovery Channel Magazine) refutes universality, highlighting knowledge gaps. The aim is to bridge these gaps during the award. (1) Which emotions are primary across cultures? Using semantic network reconstruction tools, the conceptual landscape of emotions and identify the primary emotions across cultures will be mapped. (2) Which facial movements signal culture-specific emotions? Using a unique 4-D facial animation platform, dynamic mental models of a spectrum of culture-specific facial expressions will be constructed. (3) How accurate is cross-cultural emotion communication? Conducting previously impossible research with advanced stimuli, same- and other-culture facial expression recognition will be examined. Eye-tracking will identify facial signals supporting accurate recognition and creating confusion. Is there an in-group advantage?

By interchanging race of face with culture-specific emotions (eg, Eastern emotion on a white face), Dr Jack will precisely examine the in-group advantage theory.
Benefits. With broad implications, this work will bridge scientific knowledge gaps and make timely contributions to the rapidly evolving communication needs of society.17:T7b6,This project collected images, videos, .mat files and MS Excel spreadsheets. The images are in a variety of formats, including .tiff and .jpg. The videos also came in a variety of formats, including .avi and .mp4. Images were of faces of individuals. The videos are of dynamic facial expression models displayed on individual face identities. The data set includes approximately 30,000 images and videos. With rapid globalisation, cross-cultural communication is integral to modern society, with mutual understanding of emotions central to successful social interaction. This research examines the complexities of cross-cultural communication.

Combining eye movements, computational modelling, and state-of-the-art 4D computer graphics, Dr Jack’s work (featuring in National Geographic, Discovery Channel Magazine) refutes universality, highlighting knowledge gaps. The aim is to bridge these gaps during the award. (1) Which emotions are primary across cultures? Using semantic network reconstruction tools, the conceptual landscape of emotions and identify the primary emotions across cultures will be mapped. (2) Which facial movements signal culture-specific emotions? Using a unique 4-D facial animation platform, dynamic mental models of a spectrum of culture-specific facial expressions will be constructed. (3) How accurate is cross-cultural emotion communication? Conducting previously impossible research with advanced stimuli, same- and other-culture facial expression recognition will be examined. Eye-tracking will identify facial signals supporting accurate recognition and creating confusion. Is there an in-group advantage?

By interchanging race of face with culture-specific emotions (eg, Eastern emotion on a white face), Dr Jack will precisely examine the in-group advantage theory.
Benefits. With broad implications, this work will bridge scientific knowledge gaps and make timely contributions to the rapidly evolving communication needs of society.18:T7b6,This project collected images, videos, .mat files and MS Excel spreadsheets. The images are in a variety of formats, including .tiff and .jpg. The videos also came in a variety of formats, including .avi and .mp4. Images were of faces of individuals. The videos are of dynamic facial expression models displayed on individual face identities. The data set includes approximately 30,000 images and videos. With rapid globalisation, cross-cultural communication is integral to modern society, with mutual understanding of emotions central to successful social interaction. This research examines the complexities of cross-cultural communication.

Combining eye movements, computational modelling, and state-of-the-art 4D computer graphics, Dr Jack’s work (featuring in National Geographic, Discovery Channel Magazine) refutes universality, highlighting knowledge gaps. The aim is to bridge these gaps during the award. (1) Which emotions are primary across cultures? Using semantic network reconstruction tools, the conceptual landscape of emotions and identify the primary emotions across cultures will be mapped. (2) Which facial movements signal culture-specific emotions? Using a unique 4-D facial animation platform, dynamic mental models of a spectrum of culture-specific facial expressions will be constructed. (3) How accurate is cross-cultural emotion communication? Conducting previously impossible research with advanced stimuli, same- and other-culture facial expression recognition will be examined. Eye-tracking will identify facial signals supporting accurate recognition and creating confusion. Is there an in-group advantage?

By interchanging race of face with culture-specific emotions (eg, Eastern emotion on a white face), Dr Jack will precisely examine the in-group advantage theory.
Benefits. With broad implications, this work will bridge scientific knowledge gaps and make timely contributions to the rapidly evolving communication needs of society.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Mapping the cultural landscape of emotions for social interaction"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Mapping the cultural landscape of emotions for social interaction"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/mapping-the-cultural-landscape-of-emotions-for-social-interaction"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Mapping the cultural landscape of emotions for social interaction"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Mapping the cultural landscape of emotions for social interaction"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
