1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"AuthProvider"]
4:I[83705,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"FirebaseProvider"]
5:"$Sreact.suspense"
6:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"SearchProvider"]
7:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"default"]
8:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"default"]
9:I[15244,[],""]
a:I[43866,[],""]
b:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.c89e68fe.js","4398","static/js/4398.8b943151.js","7177","static/js/app/layout.123737db.js"],"ToastContainer"]
d:I[86213,[],"OutletBoundary"]
f:I[86213,[],"MetadataBoundary"]
11:I[86213,[],"ViewportBoundary"]
13:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/80937bd8c5d07cbc.css","style"]
0:{"P":null,"b":"vfpsyyRoZZ75Xb1ZTDbtM","p":"/search","c":["","items","neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/80937bd8c5d07cbc.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":["$","$L6",null,{"children":[["$","$L7",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L8",null,{}],["$","$L7",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$Lb",null,{"position":"bottom-right"}]]}]}]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant","d"],["$","$1","c",{"children":[null,["$","$L9",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$La",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$Lc",null,["$","$Ld",null,{"children":"$Le"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","HLIfbjW6S7S6H-M3ziblD",{"children":[["$","$Lf",null,{"children":"$L10"}],["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$13","$undefined"],"s":false,"S":true}
14:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","9809","static/js/9809.f9049b43.js","6741","static/js/6741.ce01eadc.js","2649","static/js/2649.39caf1a1.js","4398","static/js/4398.8b943151.js","1857","static/js/1857.a01744c0.js","7626","static/js/7626.7cae5298.js","6387","static/js/app/items/%5Bslug%5D/page.ff89d9aa.js"],""]
16:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","9809","static/js/9809.f9049b43.js","6741","static/js/6741.ce01eadc.js","2649","static/js/2649.39caf1a1.js","4398","static/js/4398.8b943151.js","1857","static/js/1857.a01744c0.js","7626","static/js/7626.7cae5298.js","6387","static/js/app/items/%5Bslug%5D/page.ff89d9aa.js"],"default"]
15:T1587,{"@context":"https://schema.org/","@type":"Dataset","name":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024","description":"Infants’ motivation to engage with the social world depends on the interplay between individual brain’s characteristics and previous exposure to social cues such as the parent’s smile or eye contact. Different hypotheses about why specific combinations of emotional expressions and gaze direction engage children have been tested with group-level approaches rather than focusing on individual differences in the social brain development. Here, a novel Artificial Intelligence-enhanced brain-imaging approach, Neuroadaptive Bayesian Optimisation (NBO), was applied to infant electro-encephalography (EEG) to understand how selected neural signals encode social cues in individual infants.\nEEG data was acquired from 42 6- to 9-month-old infants looking at images of their parent’s face, analysed in real-time and selected by a Bayesian Optimisation algorithm to identify which combination of gaze and emotional expression of the parent’s face produces the strongest brain activation in the child. This individualised approach supported the theory that the infant’s brain is maximally engaged by communicative cues with a negative valence such as direct gaze and angry facial expressions. Moreover, we evaluated whether results also capture individual differences in behaviour. We found that infants attending preferentially to faces with direct gaze had increased positive affectivity and decreased negative affectivity compared to infants preferentially attending to faces with averted gaze.\nThis work supports the idea that infants’ attentional preferences for social cues are heterogeneous and lays the foundation for the development of neuroimaging-informed personalized experiments to study diversity in neurodevelopmental trajectories of social skills.Babies are born with a drive to interact with other people. Within a year, this drive takes them from a passive newborn to a smiling, talking toddler. Our goals shape how sociable we are and who we socialise with across the lifespan, and are thus fundamental to social psychology (Over, 2016). However, the reasons why babies choose to interact remains a mystery. Measuring motivation is difficult because it is generated by the child, whilst traditional experimental methods measure passive responses to stimuli produced by the experimenter. Our transformative approach to studying infant social motivation is inspired by innovations in advertising. In the last twenty years, advertising has been revolutionised by the use of artificial intelligence (AI). Rather than the traditional model of creating generic campaigns based on what creatives thought consumers wanted, on the internet advertisers can now identify what exactly motivates individual customers by trying out different adverts and measuring an individual customers reaction to them. For example, if you click on an advert for a holiday in Mauritius, you will then see adverts for holiday resorts on other websites that you later visit. We aim to use the principles of this approach to determine what motivates babies to interact with other people. Study 1: Identify brain signals and networks related to social motivation. As a first step, we need to identify readouts of core social reward networks in the brain; measuring the brain (rather than behaviour) allows us to measure social motivation using the same signals across development. We can measure these networks very precisely using functional magnetic resonance imaging (fMRI), but this is not suitable for babies who are awake. Functional Near-Infrared Spectroscopy (fNIRS) is an alternative imaging method that is very similar to fMRI but that can be used with babies who are awake. We will use a combination of fNIRS and fMRI to identify brain signals of the brain networks that are involved in the core social reward networks, which we can then measure with fNIRS alone in Studies 2 and 3. Study 2: Identify the social cues infants find maximally rewarding. We will use social tasks that use eye tracking methodology. This technology follows exactly where infants look at on a screen, with infants looking behaviour even triggering visual events on the screen (e.g., if infants look towards a face, this will trigger a social reward such as a smiling or talking face). As the infant watches the screen and completes the tasks, the algorithm will be able to learn which tasks produce a larger brain signal from the social reward networks. This then allows us to determine which type of social interaction is particularly rewarding for the infants and how this may change as babies grow up. For example, very young babies may be particularly interested in eye gaze and smiling, but as they grow into toddlers and begin to talk, language may be more interesting for them.","url":"https://harmonydata.ac.uk/search/items/neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant","identifier":["http://dx.doi.org/10.5255/UKDA-SN-856957"],"keywords":["DATA COLLECTION METHODOLOGY","METHODOLOGY","ARTIFICIAL INTELLIGENCE","SOCIAL BEHAVIOUR","INFANTS","CHILD DEVELOPMENT","NEURODEVELOPMENTAL DISORDERS","ELECTROENCEPHALOGRAPHY","BRAIN FUNCTION"],"temporalCoverage":"2023-06-28/2024-01-19"}17:T129f,Infants’ motivation to engage with the social world depends on the interplay between individual brain’s characteristics and previous exposure to social cues such as the parent’s smile or eye contact. Different hypotheses about why specific combinations of emotional expressions and gaze direction engage children have been tested with group-level approaches rather than focusing on individual differences in the social brain development. Here, a novel Artificial Intelligence-enhanced brain-imaging approach, Neuroadaptive Bayesian Optimisation (NBO), was applied to infant electro-encephalography (EEG) to understand how selected neural signals encode social cues in individual infants.
EEG data was acquired from 42 6- to 9-month-old infants looking at images of their parent’s face, analysed in real-time and selected by a Bayesian Optimisation algorithm to identify which combination of gaze and emotional expression of the parent’s face produces the strongest brain activation in the child. This individualised approach supported the theory that the infant’s brain is maximally engaged by communicative cues with a negative valence such as direct gaze and angry facial expressions. Moreover, we evaluated whether results also capture individual differences in behaviour. We found that infants attending preferentially to faces with direct gaze had increased positive affectivity and decreased negative affectivity compared to infants preferentially attending to faces with averted gaze.
This work supports the idea that infants’ attentional preferences for social cues are heterogeneous and lays the foundation for the development of neuroimaging-informed personalized experiments to study diversity in neurodevelopmental trajectories of social skills.Babies are born with a drive to interact with other people. Within a year, this drive takes them from a passive newborn to a smiling, talking toddler. Our goals shape how sociable we are and who we socialise with across the lifespan, and are thus fundamental to social psychology (Over, 2016). However, the reasons why babies choose to interact remains a mystery. Measuring motivation is difficult because it is generated by the child, whilst traditional experimental methods measure passive responses to stimuli produced by the experimenter. Our transformative approach to studying infant social motivation is inspired by innovations in advertising. In the last twenty years, advertising has been revolutionised by the use of artificial intelligence (AI). Rather than the traditional model of creating generic campaigns based on what creatives thought consumers wanted, on the internet advertisers can now identify what exactly motivates individual customers by trying out different adverts and measuring an individual customers reaction to them. For example, if you click on an advert for a holiday in Mauritius, you will then see adverts for holiday resorts on other websites that you later visit. We aim to use the principles of this approach to determine what motivates babies to interact with other people. Study 1: Identify brain signals and networks related to social motivation. As a first step, we need to identify readouts of core social reward networks in the brain; measuring the brain (rather than behaviour) allows us to measure social motivation using the same signals across development. We can measure these networks very precisely using functional magnetic resonance imaging (fMRI), but this is not suitable for babies who are awake. Functional Near-Infrared Spectroscopy (fNIRS) is an alternative imaging method that is very similar to fMRI but that can be used with babies who are awake. We will use a combination of fNIRS and fMRI to identify brain signals of the brain networks that are involved in the core social reward networks, which we can then measure with fNIRS alone in Studies 2 and 3. Study 2: Identify the social cues infants find maximally rewarding. We will use social tasks that use eye tracking methodology. This technology follows exactly where infants look at on a screen, with infants looking behaviour even triggering visual events on the screen (e.g., if infants look towards a face, this will trigger a social reward such as a smiling or talking face). As the infant watches the screen and completes the tasks, the algorithm will be able to learn which tasks produce a larger brain signal from the social reward networks. This then allows us to determine which type of social interaction is particularly rewarding for the infants and how this may change as babies grow up. For example, very young babies may be particularly interested in eye gaze and smiling, but as they grow into toddlers and begin to talk, language may be more interesting for them.c:["$","$5",null,{"fallback":["$","div",null,{"children":"Loading..."}],"children":[["$","$L14",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$15"}}],["$","$L16",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024","description":"$17","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=856957","https://reshare.ukdataservice.ac.uk/856957"],"keywords":["DATA COLLECTION METHODOLOGY","METHODOLOGY","ARTIFICIAL INTELLIGENCE","SOCIAL BEHAVIOUR","INFANTS","CHILD DEVELOPMENT","NEURODEVELOPMENTAL DISORDERS","ELECTROENCEPHALOGRAPHY","BRAIN FUNCTION"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-856957"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=856957"}],"sponsor":[{"@type":"Organization","name":"European Commission Horizon 2020 SAPIENS (grant no. 814302)"},{"@type":"Organization","name":"Economic and Social Research Council  (grant no. ES/R009368/1)"},{"@type":"Organization","name":"Biotechnology and Biological Sciences  Research Council (BBSRC) London Interdisciplinary Doctoral Program (LIDo)"},{"@type":"Organization","name":"Wellcome/Birkbeck ISSF2 Institutional Strategic Support Fund"},{"@type":"Organization","name":"iCASE studentship as part of the UCL Birkbeck MRC DTP2 (grant no. MR/W006774/1)"},{"@type":"Organization","name":"Innovative Medicines Initiative Joint Undertaking (grant no. 115300)"},{"@type":"Organization","name":"Innovative Medicines Initiative 2  Joint Undertaking (grant no. 777394)"}],"temporalCoverage":"2023-06-28/2024-01-19"},"extra_data":{"instruments":[],"study_design":[],"dois":["http://dx.doi.org/10.5255/UKDA-SN-856957"],"language_codes":["en"],"slug":"neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant","start_year":2023,"source":["ukds"],"data_access":"The Data Collection is available for download to users registered with the UK Data Service.","urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=856957","https://reshare.ukdataservice.ac.uk/856957"],"num_variables":null,"duration_years":1,"genetic_data_collected":false,"country_codes":["GB"],"harmony_id":"ukds/856957","ai_summary":null,"name":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024","geographic_coverage":"ToddlerLab, Birkbeck, University of London","sex":"all","resource_type":"dataset","end_year":2024,"uuid":"5f12441bb17d421229918dc6beb04eaa"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]}]
12:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
18:T129f,Infants’ motivation to engage with the social world depends on the interplay between individual brain’s characteristics and previous exposure to social cues such as the parent’s smile or eye contact. Different hypotheses about why specific combinations of emotional expressions and gaze direction engage children have been tested with group-level approaches rather than focusing on individual differences in the social brain development. Here, a novel Artificial Intelligence-enhanced brain-imaging approach, Neuroadaptive Bayesian Optimisation (NBO), was applied to infant electro-encephalography (EEG) to understand how selected neural signals encode social cues in individual infants.
EEG data was acquired from 42 6- to 9-month-old infants looking at images of their parent’s face, analysed in real-time and selected by a Bayesian Optimisation algorithm to identify which combination of gaze and emotional expression of the parent’s face produces the strongest brain activation in the child. This individualised approach supported the theory that the infant’s brain is maximally engaged by communicative cues with a negative valence such as direct gaze and angry facial expressions. Moreover, we evaluated whether results also capture individual differences in behaviour. We found that infants attending preferentially to faces with direct gaze had increased positive affectivity and decreased negative affectivity compared to infants preferentially attending to faces with averted gaze.
This work supports the idea that infants’ attentional preferences for social cues are heterogeneous and lays the foundation for the development of neuroimaging-informed personalized experiments to study diversity in neurodevelopmental trajectories of social skills.Babies are born with a drive to interact with other people. Within a year, this drive takes them from a passive newborn to a smiling, talking toddler. Our goals shape how sociable we are and who we socialise with across the lifespan, and are thus fundamental to social psychology (Over, 2016). However, the reasons why babies choose to interact remains a mystery. Measuring motivation is difficult because it is generated by the child, whilst traditional experimental methods measure passive responses to stimuli produced by the experimenter. Our transformative approach to studying infant social motivation is inspired by innovations in advertising. In the last twenty years, advertising has been revolutionised by the use of artificial intelligence (AI). Rather than the traditional model of creating generic campaigns based on what creatives thought consumers wanted, on the internet advertisers can now identify what exactly motivates individual customers by trying out different adverts and measuring an individual customers reaction to them. For example, if you click on an advert for a holiday in Mauritius, you will then see adverts for holiday resorts on other websites that you later visit. We aim to use the principles of this approach to determine what motivates babies to interact with other people. Study 1: Identify brain signals and networks related to social motivation. As a first step, we need to identify readouts of core social reward networks in the brain; measuring the brain (rather than behaviour) allows us to measure social motivation using the same signals across development. We can measure these networks very precisely using functional magnetic resonance imaging (fMRI), but this is not suitable for babies who are awake. Functional Near-Infrared Spectroscopy (fNIRS) is an alternative imaging method that is very similar to fMRI but that can be used with babies who are awake. We will use a combination of fNIRS and fMRI to identify brain signals of the brain networks that are involved in the core social reward networks, which we can then measure with fNIRS alone in Studies 2 and 3. Study 2: Identify the social cues infants find maximally rewarding. We will use social tasks that use eye tracking methodology. This technology follows exactly where infants look at on a screen, with infants looking behaviour even triggering visual events on the screen (e.g., if infants look towards a face, this will trigger a social reward such as a smiling or talking face). As the infant watches the screen and completes the tasks, the algorithm will be able to learn which tasks produce a larger brain signal from the social reward networks. This then allows us to determine which type of social interaction is particularly rewarding for the infants and how this may change as babies grow up. For example, very young babies may be particularly interested in eye gaze and smiling, but as they grow into toddlers and begin to talk, language may be more interesting for them.19:T129f,Infants’ motivation to engage with the social world depends on the interplay between individual brain’s characteristics and previous exposure to social cues such as the parent’s smile or eye contact. Different hypotheses about why specific combinations of emotional expressions and gaze direction engage children have been tested with group-level approaches rather than focusing on individual differences in the social brain development. Here, a novel Artificial Intelligence-enhanced brain-imaging approach, Neuroadaptive Bayesian Optimisation (NBO), was applied to infant electro-encephalography (EEG) to understand how selected neural signals encode social cues in individual infants.
EEG data was acquired from 42 6- to 9-month-old infants looking at images of their parent’s face, analysed in real-time and selected by a Bayesian Optimisation algorithm to identify which combination of gaze and emotional expression of the parent’s face produces the strongest brain activation in the child. This individualised approach supported the theory that the infant’s brain is maximally engaged by communicative cues with a negative valence such as direct gaze and angry facial expressions. Moreover, we evaluated whether results also capture individual differences in behaviour. We found that infants attending preferentially to faces with direct gaze had increased positive affectivity and decreased negative affectivity compared to infants preferentially attending to faces with averted gaze.
This work supports the idea that infants’ attentional preferences for social cues are heterogeneous and lays the foundation for the development of neuroimaging-informed personalized experiments to study diversity in neurodevelopmental trajectories of social skills.Babies are born with a drive to interact with other people. Within a year, this drive takes them from a passive newborn to a smiling, talking toddler. Our goals shape how sociable we are and who we socialise with across the lifespan, and are thus fundamental to social psychology (Over, 2016). However, the reasons why babies choose to interact remains a mystery. Measuring motivation is difficult because it is generated by the child, whilst traditional experimental methods measure passive responses to stimuli produced by the experimenter. Our transformative approach to studying infant social motivation is inspired by innovations in advertising. In the last twenty years, advertising has been revolutionised by the use of artificial intelligence (AI). Rather than the traditional model of creating generic campaigns based on what creatives thought consumers wanted, on the internet advertisers can now identify what exactly motivates individual customers by trying out different adverts and measuring an individual customers reaction to them. For example, if you click on an advert for a holiday in Mauritius, you will then see adverts for holiday resorts on other websites that you later visit. We aim to use the principles of this approach to determine what motivates babies to interact with other people. Study 1: Identify brain signals and networks related to social motivation. As a first step, we need to identify readouts of core social reward networks in the brain; measuring the brain (rather than behaviour) allows us to measure social motivation using the same signals across development. We can measure these networks very precisely using functional magnetic resonance imaging (fMRI), but this is not suitable for babies who are awake. Functional Near-Infrared Spectroscopy (fNIRS) is an alternative imaging method that is very similar to fMRI but that can be used with babies who are awake. We will use a combination of fNIRS and fMRI to identify brain signals of the brain networks that are involved in the core social reward networks, which we can then measure with fNIRS alone in Studies 2 and 3. Study 2: Identify the social cues infants find maximally rewarding. We will use social tasks that use eye tracking methodology. This technology follows exactly where infants look at on a screen, with infants looking behaviour even triggering visual events on the screen (e.g., if infants look towards a face, this will trigger a social reward such as a smiling or talking face). As the infant watches the screen and completes the tasks, the algorithm will be able to learn which tasks produce a larger brain signal from the social reward networks. This then allows us to determine which type of social interaction is particularly rewarding for the infants and how this may change as babies grow up. For example, very young babies may be particularly interested in eye gaze and smiling, but as they grow into toddlers and begin to talk, language may be more interesting for them.1a:T129f,Infants’ motivation to engage with the social world depends on the interplay between individual brain’s characteristics and previous exposure to social cues such as the parent’s smile or eye contact. Different hypotheses about why specific combinations of emotional expressions and gaze direction engage children have been tested with group-level approaches rather than focusing on individual differences in the social brain development. Here, a novel Artificial Intelligence-enhanced brain-imaging approach, Neuroadaptive Bayesian Optimisation (NBO), was applied to infant electro-encephalography (EEG) to understand how selected neural signals encode social cues in individual infants.
EEG data was acquired from 42 6- to 9-month-old infants looking at images of their parent’s face, analysed in real-time and selected by a Bayesian Optimisation algorithm to identify which combination of gaze and emotional expression of the parent’s face produces the strongest brain activation in the child. This individualised approach supported the theory that the infant’s brain is maximally engaged by communicative cues with a negative valence such as direct gaze and angry facial expressions. Moreover, we evaluated whether results also capture individual differences in behaviour. We found that infants attending preferentially to faces with direct gaze had increased positive affectivity and decreased negative affectivity compared to infants preferentially attending to faces with averted gaze.
This work supports the idea that infants’ attentional preferences for social cues are heterogeneous and lays the foundation for the development of neuroimaging-informed personalized experiments to study diversity in neurodevelopmental trajectories of social skills.Babies are born with a drive to interact with other people. Within a year, this drive takes them from a passive newborn to a smiling, talking toddler. Our goals shape how sociable we are and who we socialise with across the lifespan, and are thus fundamental to social psychology (Over, 2016). However, the reasons why babies choose to interact remains a mystery. Measuring motivation is difficult because it is generated by the child, whilst traditional experimental methods measure passive responses to stimuli produced by the experimenter. Our transformative approach to studying infant social motivation is inspired by innovations in advertising. In the last twenty years, advertising has been revolutionised by the use of artificial intelligence (AI). Rather than the traditional model of creating generic campaigns based on what creatives thought consumers wanted, on the internet advertisers can now identify what exactly motivates individual customers by trying out different adverts and measuring an individual customers reaction to them. For example, if you click on an advert for a holiday in Mauritius, you will then see adverts for holiday resorts on other websites that you later visit. We aim to use the principles of this approach to determine what motivates babies to interact with other people. Study 1: Identify brain signals and networks related to social motivation. As a first step, we need to identify readouts of core social reward networks in the brain; measuring the brain (rather than behaviour) allows us to measure social motivation using the same signals across development. We can measure these networks very precisely using functional magnetic resonance imaging (fMRI), but this is not suitable for babies who are awake. Functional Near-Infrared Spectroscopy (fNIRS) is an alternative imaging method that is very similar to fMRI but that can be used with babies who are awake. We will use a combination of fNIRS and fMRI to identify brain signals of the brain networks that are involved in the core social reward networks, which we can then measure with fNIRS alone in Studies 2 and 3. Study 2: Identify the social cues infants find maximally rewarding. We will use social tasks that use eye tracking methodology. This technology follows exactly where infants look at on a screen, with infants looking behaviour even triggering visual events on the screen (e.g., if infants look towards a face, this will trigger a social reward such as a smiling or talking face). As the infant watches the screen and completes the tasks, the algorithm will be able to learn which tasks produce a larger brain signal from the social reward networks. This then allows us to determine which type of social interaction is particularly rewarding for the infants and how this may change as babies grow up. For example, very young babies may be particularly interested in eye gaze and smiling, but as they grow into toddlers and begin to talk, language may be more interesting for them.10:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024"}],["$","meta","2",{"name":"description","content":"$18"}],["$","meta","3",{"property":"og:title","content":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024"}],["$","meta","4",{"property":"og:description","content":"$19"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/neuroadaptive-bayesian-optimisation-to-identify-which-combination-of-gaze-and-emotion-in-the-parent-face-maximises-attention-in-the-individual-infant"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Neuroadaptive Bayesian Optimisation to Identify which Combination of Gaze and Emotion in the Parent Face Maximises Attention in the Individual Infant, 2023-2024"}],["$","meta","15",{"name":"twitter:description","content":"$1a"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
e:null
