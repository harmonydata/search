1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"oOvDuJZyQIOPELToyx8Mb","p":"/search","c":["","items","one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",null,["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","mwkCYAynKfgp_XEQISjNQ",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],""]
14:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],"default"]
13:T1084,{"@context":"https://schema.org/","@type":"Dataset","name":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals","description":"The data collection contains the data for five independent publications, published as part of the ESRC grant “One step ahead: Prediction of other people's behavior in healthy and autistic individuals” (ES/J019178/1). For each publication, one zip is uploaded, containing all relevant raw data, the summary data used for the statistical analyses, as well as readme files, describing analysis procedures and coding methods.\n\n(I) Hudson, M., Nicholson, T., Simpson, W., Ellis, R., & Bach, P. (2016). One step ahead: the perceived kinematics of others' actions are biased towards expected goals. Journal of Experimental Psychology: General, 145(1), 1-7. \nThe zip file “2016_Hudson_at_al_JEPGeneral.zip” contains data (and readme files) for the three main experiments reported in the paper, as well as for the three supplementary experiments published in the online supplementary material.\n\n(II) Hudson, M., Nicholson, T., Ellis, R., & Bach, P. (2016). I see what you say: Prior knowledge of other's goals automatically biases the perception of their actions. Cognition, 146, 245-250.\nThe zip file “2016_Hudson_et_al_Cognition.zip” contains data (and readme files) for the two main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.\n\n(III) Bach, P. Fenton-Adams, W., Tipper, S.P. (2014). Can't touch this: the first-person perspective provides privileged access to predictions of sensory action outcomes. Journal of Experimental Psychology: Human Perception and Performance, 40(2), 457-64. \nThe zip file “2014_Bach_Fenton-Adams_Tipper.zip” contains data (and readme file) for the experiment reported in the paper.\n\n(IV) Joyce, K., Schenke, K., Bayliss, A. & Bach, P. (2015). Looking ahead: Anticipatory cuing of attention to objects others will look at. Cognitive Neuroscience, 1-8. \nThe zip file “2014_Joyce_Schenke_Bach.zip” contains data (and readme files) for the two groups of the main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.\n\n(V) Hudson, M. & Skarratt, P.A. (2016). Peripheral cues and gaze direction jointly focus attention and inhibition of return. Cognitive Neuroscience, 7, 67-73.\nThe zip file “2014_Hudson_Skarratt.zip” contains data (and readme files) for the main experiment reported in the paper.\nHumans are masters in predicting others’ behavior. By watching our child’s facial expression, we know exactly which toy she will go for. When seeing someone frown at an open window, we are not surprised when she gets up and closes it. Conversely, a breakdown of these predictions might be one reason why social interactions are so confusing to those with autism.\n\nThis project tests, using behavioral and psychophysical measures, whether there is a sophisticated mechanism in our brains that ‘knows’ which cues signal the intentions of others and uses this knowledge to predict these people’s actions (eg, looking at something signals interest, a smile signals the tendency to approach).\n\nThe first aim is to demonstrate that predictions of other’s behavior are indeed generated when watching others. We will test whether the perception of different social cues is automatically converted into predictions of their future actions.\n\nA second aim is to find out how these predictions come about, and specifically whether these predictions rely on our own action knowledge. A third and final aim is to establish whether such predictions are crucial for social interactions, and whether their breakdown is related to the social difficulties in individuals with autism spectrum disorder.","url":"https://harmonydata.ac.uk/search/items/one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals","identifier":["http://dx.doi.org/10.5255/UKDA-SN-852384"],"keywords":["PERCEPTUAL PROCESSES","COGNITION","COGNITIVE PROCESSES","PERCEPTION","PREDICTION","MOTOR PROCESSES"],"temporalCoverage":"2013-01-01/2016-03-25"}15:Te67,The data collection contains the data for five independent publications, published as part of the ESRC grant “One step ahead: Prediction of other people's behavior in healthy and autistic individuals” (ES/J019178/1). For each publication, one zip is uploaded, containing all relevant raw data, the summary data used for the statistical analyses, as well as readme files, describing analysis procedures and coding methods.

(I) Hudson, M., Nicholson, T., Simpson, W., Ellis, R., & Bach, P. (2016). One step ahead: the perceived kinematics of others' actions are biased towards expected goals. Journal of Experimental Psychology: General, 145(1), 1-7. 
The zip file “2016_Hudson_at_al_JEPGeneral.zip” contains data (and readme files) for the three main experiments reported in the paper, as well as for the three supplementary experiments published in the online supplementary material.

(II) Hudson, M., Nicholson, T., Ellis, R., & Bach, P. (2016). I see what you say: Prior knowledge of other's goals automatically biases the perception of their actions. Cognition, 146, 245-250.
The zip file “2016_Hudson_et_al_Cognition.zip” contains data (and readme files) for the two main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(III) Bach, P. Fenton-Adams, W., Tipper, S.P. (2014). Can't touch this: the first-person perspective provides privileged access to predictions of sensory action outcomes. Journal of Experimental Psychology: Human Perception and Performance, 40(2), 457-64. 
The zip file “2014_Bach_Fenton-Adams_Tipper.zip” contains data (and readme file) for the experiment reported in the paper.

(IV) Joyce, K., Schenke, K., Bayliss, A. & Bach, P. (2015). Looking ahead: Anticipatory cuing of attention to objects others will look at. Cognitive Neuroscience, 1-8. 
The zip file “2014_Joyce_Schenke_Bach.zip” contains data (and readme files) for the two groups of the main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(V) Hudson, M. & Skarratt, P.A. (2016). Peripheral cues and gaze direction jointly focus attention and inhibition of return. Cognitive Neuroscience, 7, 67-73.
The zip file “2014_Hudson_Skarratt.zip” contains data (and readme files) for the main experiment reported in the paper.
Humans are masters in predicting others’ behavior. By watching our child’s facial expression, we know exactly which toy she will go for. When seeing someone frown at an open window, we are not surprised when she gets up and closes it. Conversely, a breakdown of these predictions might be one reason why social interactions are so confusing to those with autism.

This project tests, using behavioral and psychophysical measures, whether there is a sophisticated mechanism in our brains that ‘knows’ which cues signal the intentions of others and uses this knowledge to predict these people’s actions (eg, looking at something signals interest, a smile signals the tendency to approach).

The first aim is to demonstrate that predictions of other’s behavior are indeed generated when watching others. We will test whether the perception of different social cues is automatically converted into predictions of their future actions.

A second aim is to find out how these predictions come about, and specifically whether these predictions rely on our own action knowledge. A third and final aim is to establish whether such predictions are crucial for social interactions, and whether their breakdown is related to the social difficulties in individuals with autism spectrum disorder.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals","description":"$15","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852384","https://reshare.ukdataservice.ac.uk/852384"],"keywords":["PERCEPTUAL PROCESSES","COGNITION","COGNITIVE PROCESSES","PERCEPTION","PREDICTION","MOTOR PROCESSES"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-852384"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852384"}],"sponsor":[{"@type":"Organization","name":"ESRC"}],"temporalCoverage":"2013-01-01/2016-03-25"},"extra_data":{"study_design":[],"name":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals","slug":"one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals","duration_years":3,"language_codes":["en"],"num_variables":null,"geographic_coverage":"","source":["ukds"],"country_codes":["GB"],"instruments":[],"data_access":null,"ai_summary":null,"sex":"male","resource_type":"dataset","dois":["http://dx.doi.org/10.5255/UKDA-SN-852384"],"end_year":2016,"genetic_data_collected":false,"urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852384","https://reshare.ukdataservice.ac.uk/852384"],"harmony_id":"ukds/852384","start_year":2013,"uuid":"2245ec9ebb492ea990e53e8119920bdd"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:Te67,The data collection contains the data for five independent publications, published as part of the ESRC grant “One step ahead: Prediction of other people's behavior in healthy and autistic individuals” (ES/J019178/1). For each publication, one zip is uploaded, containing all relevant raw data, the summary data used for the statistical analyses, as well as readme files, describing analysis procedures and coding methods.

(I) Hudson, M., Nicholson, T., Simpson, W., Ellis, R., & Bach, P. (2016). One step ahead: the perceived kinematics of others' actions are biased towards expected goals. Journal of Experimental Psychology: General, 145(1), 1-7. 
The zip file “2016_Hudson_at_al_JEPGeneral.zip” contains data (and readme files) for the three main experiments reported in the paper, as well as for the three supplementary experiments published in the online supplementary material.

(II) Hudson, M., Nicholson, T., Ellis, R., & Bach, P. (2016). I see what you say: Prior knowledge of other's goals automatically biases the perception of their actions. Cognition, 146, 245-250.
The zip file “2016_Hudson_et_al_Cognition.zip” contains data (and readme files) for the two main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(III) Bach, P. Fenton-Adams, W., Tipper, S.P. (2014). Can't touch this: the first-person perspective provides privileged access to predictions of sensory action outcomes. Journal of Experimental Psychology: Human Perception and Performance, 40(2), 457-64. 
The zip file “2014_Bach_Fenton-Adams_Tipper.zip” contains data (and readme file) for the experiment reported in the paper.

(IV) Joyce, K., Schenke, K., Bayliss, A. & Bach, P. (2015). Looking ahead: Anticipatory cuing of attention to objects others will look at. Cognitive Neuroscience, 1-8. 
The zip file “2014_Joyce_Schenke_Bach.zip” contains data (and readme files) for the two groups of the main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(V) Hudson, M. & Skarratt, P.A. (2016). Peripheral cues and gaze direction jointly focus attention and inhibition of return. Cognitive Neuroscience, 7, 67-73.
The zip file “2014_Hudson_Skarratt.zip” contains data (and readme files) for the main experiment reported in the paper.
Humans are masters in predicting others’ behavior. By watching our child’s facial expression, we know exactly which toy she will go for. When seeing someone frown at an open window, we are not surprised when she gets up and closes it. Conversely, a breakdown of these predictions might be one reason why social interactions are so confusing to those with autism.

This project tests, using behavioral and psychophysical measures, whether there is a sophisticated mechanism in our brains that ‘knows’ which cues signal the intentions of others and uses this knowledge to predict these people’s actions (eg, looking at something signals interest, a smile signals the tendency to approach).

The first aim is to demonstrate that predictions of other’s behavior are indeed generated when watching others. We will test whether the perception of different social cues is automatically converted into predictions of their future actions.

A second aim is to find out how these predictions come about, and specifically whether these predictions rely on our own action knowledge. A third and final aim is to establish whether such predictions are crucial for social interactions, and whether their breakdown is related to the social difficulties in individuals with autism spectrum disorder.17:Te67,The data collection contains the data for five independent publications, published as part of the ESRC grant “One step ahead: Prediction of other people's behavior in healthy and autistic individuals” (ES/J019178/1). For each publication, one zip is uploaded, containing all relevant raw data, the summary data used for the statistical analyses, as well as readme files, describing analysis procedures and coding methods.

(I) Hudson, M., Nicholson, T., Simpson, W., Ellis, R., & Bach, P. (2016). One step ahead: the perceived kinematics of others' actions are biased towards expected goals. Journal of Experimental Psychology: General, 145(1), 1-7. 
The zip file “2016_Hudson_at_al_JEPGeneral.zip” contains data (and readme files) for the three main experiments reported in the paper, as well as for the three supplementary experiments published in the online supplementary material.

(II) Hudson, M., Nicholson, T., Ellis, R., & Bach, P. (2016). I see what you say: Prior knowledge of other's goals automatically biases the perception of their actions. Cognition, 146, 245-250.
The zip file “2016_Hudson_et_al_Cognition.zip” contains data (and readme files) for the two main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(III) Bach, P. Fenton-Adams, W., Tipper, S.P. (2014). Can't touch this: the first-person perspective provides privileged access to predictions of sensory action outcomes. Journal of Experimental Psychology: Human Perception and Performance, 40(2), 457-64. 
The zip file “2014_Bach_Fenton-Adams_Tipper.zip” contains data (and readme file) for the experiment reported in the paper.

(IV) Joyce, K., Schenke, K., Bayliss, A. & Bach, P. (2015). Looking ahead: Anticipatory cuing of attention to objects others will look at. Cognitive Neuroscience, 1-8. 
The zip file “2014_Joyce_Schenke_Bach.zip” contains data (and readme files) for the two groups of the main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(V) Hudson, M. & Skarratt, P.A. (2016). Peripheral cues and gaze direction jointly focus attention and inhibition of return. Cognitive Neuroscience, 7, 67-73.
The zip file “2014_Hudson_Skarratt.zip” contains data (and readme files) for the main experiment reported in the paper.
Humans are masters in predicting others’ behavior. By watching our child’s facial expression, we know exactly which toy she will go for. When seeing someone frown at an open window, we are not surprised when she gets up and closes it. Conversely, a breakdown of these predictions might be one reason why social interactions are so confusing to those with autism.

This project tests, using behavioral and psychophysical measures, whether there is a sophisticated mechanism in our brains that ‘knows’ which cues signal the intentions of others and uses this knowledge to predict these people’s actions (eg, looking at something signals interest, a smile signals the tendency to approach).

The first aim is to demonstrate that predictions of other’s behavior are indeed generated when watching others. We will test whether the perception of different social cues is automatically converted into predictions of their future actions.

A second aim is to find out how these predictions come about, and specifically whether these predictions rely on our own action knowledge. A third and final aim is to establish whether such predictions are crucial for social interactions, and whether their breakdown is related to the social difficulties in individuals with autism spectrum disorder.18:Te67,The data collection contains the data for five independent publications, published as part of the ESRC grant “One step ahead: Prediction of other people's behavior in healthy and autistic individuals” (ES/J019178/1). For each publication, one zip is uploaded, containing all relevant raw data, the summary data used for the statistical analyses, as well as readme files, describing analysis procedures and coding methods.

(I) Hudson, M., Nicholson, T., Simpson, W., Ellis, R., & Bach, P. (2016). One step ahead: the perceived kinematics of others' actions are biased towards expected goals. Journal of Experimental Psychology: General, 145(1), 1-7. 
The zip file “2016_Hudson_at_al_JEPGeneral.zip” contains data (and readme files) for the three main experiments reported in the paper, as well as for the three supplementary experiments published in the online supplementary material.

(II) Hudson, M., Nicholson, T., Ellis, R., & Bach, P. (2016). I see what you say: Prior knowledge of other's goals automatically biases the perception of their actions. Cognition, 146, 245-250.
The zip file “2016_Hudson_et_al_Cognition.zip” contains data (and readme files) for the two main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(III) Bach, P. Fenton-Adams, W., Tipper, S.P. (2014). Can't touch this: the first-person perspective provides privileged access to predictions of sensory action outcomes. Journal of Experimental Psychology: Human Perception and Performance, 40(2), 457-64. 
The zip file “2014_Bach_Fenton-Adams_Tipper.zip” contains data (and readme file) for the experiment reported in the paper.

(IV) Joyce, K., Schenke, K., Bayliss, A. & Bach, P. (2015). Looking ahead: Anticipatory cuing of attention to objects others will look at. Cognitive Neuroscience, 1-8. 
The zip file “2014_Joyce_Schenke_Bach.zip” contains data (and readme files) for the two groups of the main experiments reported in the paper, as well as for the supplementary experiment published in the online supplementary material.

(V) Hudson, M. & Skarratt, P.A. (2016). Peripheral cues and gaze direction jointly focus attention and inhibition of return. Cognitive Neuroscience, 7, 67-73.
The zip file “2014_Hudson_Skarratt.zip” contains data (and readme files) for the main experiment reported in the paper.
Humans are masters in predicting others’ behavior. By watching our child’s facial expression, we know exactly which toy she will go for. When seeing someone frown at an open window, we are not surprised when she gets up and closes it. Conversely, a breakdown of these predictions might be one reason why social interactions are so confusing to those with autism.

This project tests, using behavioral and psychophysical measures, whether there is a sophisticated mechanism in our brains that ‘knows’ which cues signal the intentions of others and uses this knowledge to predict these people’s actions (eg, looking at something signals interest, a smile signals the tendency to approach).

The first aim is to demonstrate that predictions of other’s behavior are indeed generated when watching others. We will test whether the perception of different social cues is automatically converted into predictions of their future actions.

A second aim is to find out how these predictions come about, and specifically whether these predictions rely on our own action knowledge. A third and final aim is to establish whether such predictions are crucial for social interactions, and whether their breakdown is related to the social difficulties in individuals with autism spectrum disorder.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/one-step-ahead-prediction-of-other-people-s-behavior-in-healthy-and-autistic-individuals"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"One step ahead: Prediction of other people's behavior in healthy and autistic individuals"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
