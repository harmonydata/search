1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","9756","static/js/9756.65c7d9ea.js","5246","static/js/5246.d88343e0.js","7177","static/js/app/layout.2233f7cc.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/a38392bd344718e4.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"0Pw2B2A-ctu_hDkpgRDyX","p":"/search","c":["","items","peripheral-visual-cues-contribute-to-the-perception-of-object-movement-during-self-movement"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","peripheral-visual-cues-contribute-to-the-perception-of-object-movement-during-self-movement","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/a38392bd344718e4.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_55b4bf","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","peripheral-visual-cues-contribute-to-the-perception-of-object-movement-during-self-movement","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","-6enBnKLPGZqf1JJFB8Q_",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["3524","static/js/2170a4aa.3678665e.js","6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","1057","static/js/1057.fef3cc4c.js","2282","static/js/2282.e20001b9.js","9234","static/js/9234.7cf96505.js","2926","static/js/2926.76e4f620.js","7511","static/js/7511.a52b23cb.js","8173","static/js/8173.582c8c90.js","613","static/js/613.da2777c4.js","9756","static/js/9756.65c7d9ea.js","97","static/js/97.c5459b6e.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.07f8eb1b.js","9123","static/js/9123.0b9c8079.js","6387","static/js/app/items/%5Bslug%5D/page.e8e51342.js"],""]
14:I[5749,["3524","static/js/2170a4aa.3678665e.js","6586","static/js/6586.2e946dbf.js","4889","static/js/4889.4efc83ef.js","1057","static/js/1057.fef3cc4c.js","2282","static/js/2282.e20001b9.js","9234","static/js/9234.7cf96505.js","2926","static/js/2926.76e4f620.js","7511","static/js/7511.a52b23cb.js","8173","static/js/8173.582c8c90.js","613","static/js/613.da2777c4.js","9756","static/js/9756.65c7d9ea.js","97","static/js/97.c5459b6e.js","2649","static/js/2649.4d01838c.js","1857","static/js/1857.a01744c0.js","280","static/js/280.07f8eb1b.js","9123","static/js/9123.0b9c8079.js","6387","static/js/app/items/%5Bslug%5D/page.e8e51342.js"],"default"]
13:T10e7,{"@context":"https://schema.org/","@type":"Dataset","name":"Peripheral visual cues contribute to the perception of object movement during self-movement","description":"Safe movement through the environment requires us to monitor our surroundings for moving objects or people. However, identification of moving objects in the scene is complicated by self- movement, which adds motion across the retina. To identify world-relative object movement, the brain thus has to ‘compensate for’ or ‘parse out’ the components of retinal motion that are due to self-movement. We have previously demonstrated that retinal cues arising from central vision contribute to solving this problem. Here, we investigate the contribution of peripheral vision, commonly thought to provide strong cues to self-movement (for the publication, see Related Resources). Stationary participants viewed a large field of view display, with radial flow patterns presented in the periphery, and judged the trajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify the contribution of peripheral optic flow to flow parsing during forward and backward movement. \nThe archived data is described in Rogers, C., Rushton, S.K. & Warren, P.A. (2017). Peripheral visual cues contribute to the perception of object movement during self-movement\niPerception, volume 8, issue 6 (see Related Resources for weblink).A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain \"compensates\" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing\n\nThe project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.","url":"https://harmonydata.ac.uk/search/items/peripheral-visual-cues-contribute-to-the-perception-of-object-movement-during-self-movement","identifier":["http://dx.doi.org/10.5255/UKDA-SN-852880"],"keywords":["PSYCHOPHYSICS","FLOW PARSING","OPTIC FLOW","PERIPHERAL CUES"],"temporalCoverage":"2014-08-01/2017-10-31"}15:Tefc,Safe movement through the environment requires us to monitor our surroundings for moving objects or people. However, identification of moving objects in the scene is complicated by self- movement, which adds motion across the retina. To identify world-relative object movement, the brain thus has to ‘compensate for’ or ‘parse out’ the components of retinal motion that are due to self-movement. We have previously demonstrated that retinal cues arising from central vision contribute to solving this problem. Here, we investigate the contribution of peripheral vision, commonly thought to provide strong cues to self-movement (for the publication, see Related Resources). Stationary participants viewed a large field of view display, with radial flow patterns presented in the periphery, and judged the trajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify the contribution of peripheral optic flow to flow parsing during forward and backward movement. 
The archived data is described in Rogers, C., Rushton, S.K. & Warren, P.A. (2017). Peripheral visual cues contribute to the perception of object movement during self-movement
iPerception, volume 8, issue 6 (see Related Resources for weblink).A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing

The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"dataset":{"title":"Peripheral visual cues contribute to the perception of object movement during self-movement","description":"$15","image":"$undefined","publisher":"$undefined","funders":"$undefined","geographicCoverage":"GB","temporalCoverage":"2014-08-01/2017-10-31","ageCoverage":"$undefined","studyDesign":[],"resourceType":"dataset","topics":["PSYCHOPHYSICS","FLOW PARSING","OPTIC FLOW","PERIPHERAL CUES"],"instruments":[],"dataCatalogs":[{"name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852880","logo":"$undefined"}],"matchedVariables":[],"allVariables":[],"additionalLinks":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852880","https://reshare.ukdataservice.ac.uk/852880","http://dx.doi.org/10.5255/UKDA-SN-852880","http://dx.doi.org/10.5255/UKDA-SN-852880"],"child_datasets":[],"aiSummary":null}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:Tefc,Safe movement through the environment requires us to monitor our surroundings for moving objects or people. However, identification of moving objects in the scene is complicated by self- movement, which adds motion across the retina. To identify world-relative object movement, the brain thus has to ‘compensate for’ or ‘parse out’ the components of retinal motion that are due to self-movement. We have previously demonstrated that retinal cues arising from central vision contribute to solving this problem. Here, we investigate the contribution of peripheral vision, commonly thought to provide strong cues to self-movement (for the publication, see Related Resources). Stationary participants viewed a large field of view display, with radial flow patterns presented in the periphery, and judged the trajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify the contribution of peripheral optic flow to flow parsing during forward and backward movement. 
The archived data is described in Rogers, C., Rushton, S.K. & Warren, P.A. (2017). Peripheral visual cues contribute to the perception of object movement during self-movement
iPerception, volume 8, issue 6 (see Related Resources for weblink).A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing

The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.17:Tefc,Safe movement through the environment requires us to monitor our surroundings for moving objects or people. However, identification of moving objects in the scene is complicated by self- movement, which adds motion across the retina. To identify world-relative object movement, the brain thus has to ‘compensate for’ or ‘parse out’ the components of retinal motion that are due to self-movement. We have previously demonstrated that retinal cues arising from central vision contribute to solving this problem. Here, we investigate the contribution of peripheral vision, commonly thought to provide strong cues to self-movement (for the publication, see Related Resources). Stationary participants viewed a large field of view display, with radial flow patterns presented in the periphery, and judged the trajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify the contribution of peripheral optic flow to flow parsing during forward and backward movement. 
The archived data is described in Rogers, C., Rushton, S.K. & Warren, P.A. (2017). Peripheral visual cues contribute to the perception of object movement during self-movement
iPerception, volume 8, issue 6 (see Related Resources for weblink).A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing

The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.18:Tefc,Safe movement through the environment requires us to monitor our surroundings for moving objects or people. However, identification of moving objects in the scene is complicated by self- movement, which adds motion across the retina. To identify world-relative object movement, the brain thus has to ‘compensate for’ or ‘parse out’ the components of retinal motion that are due to self-movement. We have previously demonstrated that retinal cues arising from central vision contribute to solving this problem. Here, we investigate the contribution of peripheral vision, commonly thought to provide strong cues to self-movement (for the publication, see Related Resources). Stationary participants viewed a large field of view display, with radial flow patterns presented in the periphery, and judged the trajectory of a centrally presented probe. Across two experiments, we demonstrate and quantify the contribution of peripheral optic flow to flow parsing during forward and backward movement. 
The archived data is described in Rogers, C., Rushton, S.K. & Warren, P.A. (2017). Peripheral visual cues contribute to the perception of object movement during self-movement
iPerception, volume 8, issue 6 (see Related Resources for weblink).A long-standing question is how the brain transforms the light patterns impinging onto the retina into a meaningful world of objects and animates with which the observer can interact. While enormous progress has been made in the understanding of brain functions during the last few decades, the fundamental principles underlying the processing and extraction of visual information remain elusive. This project builds on the observation that perception has been traditionally studied in a passive manner, paying relatively little attention to the observer's motor activity during the acquisition of visual information. Yet, like other species, humans are not passively exposed to the incoming flow of sensory data. Instead, they actively seek useful information by coordinating sensory processing with motor activity. Our motivating hypothesis is that self-movement is a critical component of visual perception. Considered as a problem of simple visual geometry this hypothesis might appear counter-intuitive. Considered as an image-processing problem it might appear counter-intuitive. Considered against decades of work concerned with how the brain "compensates" for self-movement it might also appear counter-intuitive. However, this hypothesis is fully plausible from a biological perspective, because more information about the scene is available when the observer moves. This was pointed out many years ago by ecological psychologists and has more recently been recognised in computer vision - where it has caused a paradigm change. We argue that the visual, motor, and proprioceptive information generated by self-movement is fundamental to visual processing

The project brings together three laboratories from The Netherlands (Dr. Brenner at VU University in Amsterdam), the US (Dr. Rucci at Boston University), and the UK (Dr Rushton at Cardiff University), which have developed critical expertise on the analyses of different types of motor activities in humans. We will systematically investigate the mechanisms by which human observers use motor, proprioceptive and global optic flow signals to accomplish visual tasks. Elucidating the perceptual impact of motor activity is critical to advancing our knowledge of how the visual system functions. Such knowledge can also potentially guide the design of objects and environments, inform the building of machines capable of replicating human visual functions, and it may provide a scientific basis for the development of treatments of visual impairments commonly associated with abnormal motor activity in pathological conditions.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Peripheral visual cues contribute to the perception of object movement during self-movement"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Peripheral visual cues contribute to the perception of object movement during self-movement"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/peripheral-visual-cues-contribute-to-the-perception-of-object-movement-during-self-movement"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Peripheral visual cues contribute to the perception of object movement during self-movement"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Peripheral visual cues contribute to the perception of object movement during self-movement"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
