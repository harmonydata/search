1:"$Sreact.fragment"
2:I[82104,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
3:I[10683,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"AuthProvider"]
4:I[63612,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"SearchProvider"]
5:I[68998,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
6:I[98904,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","8173","static/chunks/8173-30737ce2fc776efb.js","9756","static/chunks/9756-90c6220c809c4148.js","3163","static/chunks/3163-d1a03f172499fcd8.js","7177","static/chunks/app/layout-802ca43371b3eb9d.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/138a3164b4c9e92c.css","style"]
:HL["/search/_next/static/css/4921cfd18b262f8c.css","style"]
0:{"P":null,"b":"j27aFvxleOaSSzL4BSwDK","p":"/search","c":["","items","preparatory-activation-of-guidance-templates-for-visual-search-and-of-target-templates-in-non-search-tasks"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","preparatory-activation-of-guidance-templates-for-visual-search-and-of-target-templates-in-non-search-tasks","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/138a3164b4c9e92c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":["$","meta",null,{"name":"emotion-insertion-point","content":""}]}],["$","body",null,{"className":"__className_62a302","children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","preparatory-activation-of-guidance-templates-for-visual-search-and-of-target-templates-in-non-search-tasks","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/4921cfd18b262f8c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","AtArB9nVGPYK1IYSw3xAY",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","2154","static/chunks/834cb1aa-fe75579b2a50baac.js","3524","static/chunks/2170a4aa-66be1631595ccab0.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","1057","static/chunks/1057-d97430463abd6821.js","2282","static/chunks/2282-26bc5318a4471ee9.js","9234","static/chunks/9234-fce85e807baa599f.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","5733","static/chunks/5733-d0ad15157d7394e5.js","8173","static/chunks/8173-30737ce2fc776efb.js","613","static/chunks/613-3467f3d6fe7e6e6a.js","9756","static/chunks/9756-90c6220c809c4148.js","8738","static/chunks/8738-58586275b0d791e8.js","2649","static/chunks/2649-8ae63f8e6332939b.js","511","static/chunks/511-036317be30af8955.js","1857","static/chunks/1857-99747bd4076c313b.js","2288","static/chunks/2288-c4f1c38c0cd98db5.js","6387","static/chunks/app/items/%5Bslug%5D/page-50b1faaba0d4435c.js"],""]
14:I[5749,["2992","static/chunks/bc9e92e6-ca3f8a01cbc7cc31.js","9895","static/chunks/f71d1b72-799ff7a6833dc50c.js","2154","static/chunks/834cb1aa-fe75579b2a50baac.js","3524","static/chunks/2170a4aa-66be1631595ccab0.js","6586","static/chunks/6586-1013c110456598c2.js","4889","static/chunks/4889-f0599128dd4090a0.js","1057","static/chunks/1057-d97430463abd6821.js","2282","static/chunks/2282-26bc5318a4471ee9.js","9234","static/chunks/9234-fce85e807baa599f.js","9141","static/chunks/9141-d17bf49085d8e296.js","2926","static/chunks/2926-f97573e569b0b5d8.js","5733","static/chunks/5733-d0ad15157d7394e5.js","8173","static/chunks/8173-30737ce2fc776efb.js","613","static/chunks/613-3467f3d6fe7e6e6a.js","9756","static/chunks/9756-90c6220c809c4148.js","8738","static/chunks/8738-58586275b0d791e8.js","2649","static/chunks/2649-8ae63f8e6332939b.js","511","static/chunks/511-036317be30af8955.js","1857","static/chunks/1857-99747bd4076c313b.js","2288","static/chunks/2288-c4f1c38c0cd98db5.js","6387","static/chunks/app/items/%5Bslug%5D/page-50b1faaba0d4435c.js"],"default"]
13:T1440,{"@context":"https://schema.org/","@type":"Dataset","name":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks","description":"Representations of task-relevant object attributes (attentional templates) control the adaptive selectivity of visual processing. Previous studies have demonstrated that templates involved in the guidance of attention during visual search are activated in a preparatory fashion prior to the arrival of visual search displays. The current study investigated whether such proactive mechanisms are also triggered in non-search tasks, where attentional templates do not mediate the guidance of attention towards targets amongst distractors but are still necessary for subsequent target recognition processes. Participants either searched for colour-defined targets among multiple distractors or performed two other non-search tasks where imperative stimuli appeared without competing distractors (a colour-based Go/NoGo task, and a shape discrimination task where target colour was constant and could thus be ignored). Preparatory activation of colour-selective templates was tracked by measuring N2pc components (markers of attention allocation) to task-irrelevant colour singleton probes flashed every 200 ms during the interval between target displays. As expected, N2pcs were triggered by target-coloured probes in the search task, indicating that a corresponding guidance template was triggered proactively. Critically, clear probe N2pcs were also observed in the Go/NoGo task, and even in the shape discrimination task in an attenuated fashion. These findings demonstrate that the preparatory activation of feature-selective attentional task settings is not uniquely associated with the guidance of visual search but is also present in other types of visual selection tasks where guidance is not required.Our perception of the outside world, and the way that we interact with external objects and events, is not just determined by incoming sensory information, but also by our expectations and intentions. We are not merely passive recipients of perceptual signals - very often, we are already prepared for what to expect and for what will be relevant in a given situation. Being prepared allows us to deal with our environment more effectively, by focussing our attention on what is important, and filtering out other information that can be safely ignored. It is obvious that preparation is one of the most important aspects of human cognition - it shapes our conscious experience and guides our interactions with the world. However, we still know very little about how we prepare for upcoming tasks. The reason for this is that the activation of preparatory states is an internal mental phenomenon that usually takes place in the absence of any directly observable behaviour. Such states are therefore difficult to assess with the conventional performance-based measures of experimental psychology.\n In this project, we will measure preparatory states directly, while they occur, by recording brain activity (EEG) from observers when they prepare for upcoming visual search tasks. In these tasks, they have to search for a specific known target object among multiple irrelevant objects (distractors). They can prepare for search by activating a mental representation of this target object, which will then help to guide their attention to the target when it appears. We have recently developed new methods to measure such preparatory \"images in the mind\" directly, at the moment when they are activated, and to track these activation states in real time. We can therefore now directly observe when preparation starts and how it changes across time. We can also determine the content of such preparatory states. For example, when we prepare to search for our mobile phone on our cluttered desk, do we activate a mental image of the whole object, or just a specific attribute of this object, such as its colour or shape? Can we control the content of what we prepare for, and deliberately employ different preparation strategies in different contexts? For example, do we prepare more effectively for task goals that are motivationally relevant, because they are associated with a higher reward? How quickly can we change preparatory states affected when task goals suddenly change? Importantly, we will also investigate links between preparation and failures of selective attention. We often fail to find what we are looking for, or attention can be distracted by irrelevant objects and events. By comparing preparatory states measured on an occasion where subsequent attentional selection operates efficiently and on an occasion where it does not, we can find out how fluctuations in preparedness produce different behavioural outcomes.","url":"https://harmonydata.ac.uk/search/items/preparatory-activation-of-guidance-templates-for-visual-search-and-of-target-templates-in-non-search-tasks","identifier":["http://dx.doi.org/10.5255/UKDA-SN-857750"],"keywords":["PSYCHOLOGICAL RESEARCH","COGNITIVE PROCESSES","PSYCHOLOGY","PSYCHOLOGICAL EFFECTS"],"temporalCoverage":"2022-09-12/2022-10-21"}15:T1220,Representations of task-relevant object attributes (attentional templates) control the adaptive selectivity of visual processing. Previous studies have demonstrated that templates involved in the guidance of attention during visual search are activated in a preparatory fashion prior to the arrival of visual search displays. The current study investigated whether such proactive mechanisms are also triggered in non-search tasks, where attentional templates do not mediate the guidance of attention towards targets amongst distractors but are still necessary for subsequent target recognition processes. Participants either searched for colour-defined targets among multiple distractors or performed two other non-search tasks where imperative stimuli appeared without competing distractors (a colour-based Go/NoGo task, and a shape discrimination task where target colour was constant and could thus be ignored). Preparatory activation of colour-selective templates was tracked by measuring N2pc components (markers of attention allocation) to task-irrelevant colour singleton probes flashed every 200 ms during the interval between target displays. As expected, N2pcs were triggered by target-coloured probes in the search task, indicating that a corresponding guidance template was triggered proactively. Critically, clear probe N2pcs were also observed in the Go/NoGo task, and even in the shape discrimination task in an attenuated fashion. These findings demonstrate that the preparatory activation of feature-selective attentional task settings is not uniquely associated with the guidance of visual search but is also present in other types of visual selection tasks where guidance is not required.Our perception of the outside world, and the way that we interact with external objects and events, is not just determined by incoming sensory information, but also by our expectations and intentions. We are not merely passive recipients of perceptual signals - very often, we are already prepared for what to expect and for what will be relevant in a given situation. Being prepared allows us to deal with our environment more effectively, by focussing our attention on what is important, and filtering out other information that can be safely ignored. It is obvious that preparation is one of the most important aspects of human cognition - it shapes our conscious experience and guides our interactions with the world. However, we still know very little about how we prepare for upcoming tasks. The reason for this is that the activation of preparatory states is an internal mental phenomenon that usually takes place in the absence of any directly observable behaviour. Such states are therefore difficult to assess with the conventional performance-based measures of experimental psychology.
 In this project, we will measure preparatory states directly, while they occur, by recording brain activity (EEG) from observers when they prepare for upcoming visual search tasks. In these tasks, they have to search for a specific known target object among multiple irrelevant objects (distractors). They can prepare for search by activating a mental representation of this target object, which will then help to guide their attention to the target when it appears. We have recently developed new methods to measure such preparatory "images in the mind" directly, at the moment when they are activated, and to track these activation states in real time. We can therefore now directly observe when preparation starts and how it changes across time. We can also determine the content of such preparatory states. For example, when we prepare to search for our mobile phone on our cluttered desk, do we activate a mental image of the whole object, or just a specific attribute of this object, such as its colour or shape? Can we control the content of what we prepare for, and deliberately employ different preparation strategies in different contexts? For example, do we prepare more effectively for task goals that are motivationally relevant, because they are associated with a higher reward? How quickly can we change preparatory states affected when task goals suddenly change? Importantly, we will also investigate links between preparation and failures of selective attention. We often fail to find what we are looking for, or attention can be distracted by irrelevant objects and events. By comparing preparatory states measured on an occasion where subsequent attentional selection operates efficiently and on an occasion where it does not, we can find out how fluctuations in preparedness produce different behavioural outcomes.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"dataset":{"title":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks","description":"$15","image":"$undefined","publisher":"$undefined","funders":"$undefined","geographicCoverage":"GB","temporalCoverage":"2022-09-12/2022-10-21","ageCoverage":"$undefined","studyDesign":[],"resourceType":"dataset","topics":["PSYCHOLOGICAL RESEARCH","COGNITIVE PROCESSES","PSYCHOLOGY","PSYCHOLOGICAL EFFECTS"],"instruments":[],"dataCatalogs":[{"name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857750","logo":"$undefined"}],"matchedVariables":[],"allVariables":[],"additionalLinks":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857750","https://reshare.ukdataservice.ac.uk/857750","http://dx.doi.org/10.5255/UKDA-SN-857750","http://dx.doi.org/10.5255/UKDA-SN-857750"],"child_datasets":[],"aiSummary":null}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T1220,Representations of task-relevant object attributes (attentional templates) control the adaptive selectivity of visual processing. Previous studies have demonstrated that templates involved in the guidance of attention during visual search are activated in a preparatory fashion prior to the arrival of visual search displays. The current study investigated whether such proactive mechanisms are also triggered in non-search tasks, where attentional templates do not mediate the guidance of attention towards targets amongst distractors but are still necessary for subsequent target recognition processes. Participants either searched for colour-defined targets among multiple distractors or performed two other non-search tasks where imperative stimuli appeared without competing distractors (a colour-based Go/NoGo task, and a shape discrimination task where target colour was constant and could thus be ignored). Preparatory activation of colour-selective templates was tracked by measuring N2pc components (markers of attention allocation) to task-irrelevant colour singleton probes flashed every 200 ms during the interval between target displays. As expected, N2pcs were triggered by target-coloured probes in the search task, indicating that a corresponding guidance template was triggered proactively. Critically, clear probe N2pcs were also observed in the Go/NoGo task, and even in the shape discrimination task in an attenuated fashion. These findings demonstrate that the preparatory activation of feature-selective attentional task settings is not uniquely associated with the guidance of visual search but is also present in other types of visual selection tasks where guidance is not required.Our perception of the outside world, and the way that we interact with external objects and events, is not just determined by incoming sensory information, but also by our expectations and intentions. We are not merely passive recipients of perceptual signals - very often, we are already prepared for what to expect and for what will be relevant in a given situation. Being prepared allows us to deal with our environment more effectively, by focussing our attention on what is important, and filtering out other information that can be safely ignored. It is obvious that preparation is one of the most important aspects of human cognition - it shapes our conscious experience and guides our interactions with the world. However, we still know very little about how we prepare for upcoming tasks. The reason for this is that the activation of preparatory states is an internal mental phenomenon that usually takes place in the absence of any directly observable behaviour. Such states are therefore difficult to assess with the conventional performance-based measures of experimental psychology.
 In this project, we will measure preparatory states directly, while they occur, by recording brain activity (EEG) from observers when they prepare for upcoming visual search tasks. In these tasks, they have to search for a specific known target object among multiple irrelevant objects (distractors). They can prepare for search by activating a mental representation of this target object, which will then help to guide their attention to the target when it appears. We have recently developed new methods to measure such preparatory "images in the mind" directly, at the moment when they are activated, and to track these activation states in real time. We can therefore now directly observe when preparation starts and how it changes across time. We can also determine the content of such preparatory states. For example, when we prepare to search for our mobile phone on our cluttered desk, do we activate a mental image of the whole object, or just a specific attribute of this object, such as its colour or shape? Can we control the content of what we prepare for, and deliberately employ different preparation strategies in different contexts? For example, do we prepare more effectively for task goals that are motivationally relevant, because they are associated with a higher reward? How quickly can we change preparatory states affected when task goals suddenly change? Importantly, we will also investigate links between preparation and failures of selective attention. We often fail to find what we are looking for, or attention can be distracted by irrelevant objects and events. By comparing preparatory states measured on an occasion where subsequent attentional selection operates efficiently and on an occasion where it does not, we can find out how fluctuations in preparedness produce different behavioural outcomes.17:T1220,Representations of task-relevant object attributes (attentional templates) control the adaptive selectivity of visual processing. Previous studies have demonstrated that templates involved in the guidance of attention during visual search are activated in a preparatory fashion prior to the arrival of visual search displays. The current study investigated whether such proactive mechanisms are also triggered in non-search tasks, where attentional templates do not mediate the guidance of attention towards targets amongst distractors but are still necessary for subsequent target recognition processes. Participants either searched for colour-defined targets among multiple distractors or performed two other non-search tasks where imperative stimuli appeared without competing distractors (a colour-based Go/NoGo task, and a shape discrimination task where target colour was constant and could thus be ignored). Preparatory activation of colour-selective templates was tracked by measuring N2pc components (markers of attention allocation) to task-irrelevant colour singleton probes flashed every 200 ms during the interval between target displays. As expected, N2pcs were triggered by target-coloured probes in the search task, indicating that a corresponding guidance template was triggered proactively. Critically, clear probe N2pcs were also observed in the Go/NoGo task, and even in the shape discrimination task in an attenuated fashion. These findings demonstrate that the preparatory activation of feature-selective attentional task settings is not uniquely associated with the guidance of visual search but is also present in other types of visual selection tasks where guidance is not required.Our perception of the outside world, and the way that we interact with external objects and events, is not just determined by incoming sensory information, but also by our expectations and intentions. We are not merely passive recipients of perceptual signals - very often, we are already prepared for what to expect and for what will be relevant in a given situation. Being prepared allows us to deal with our environment more effectively, by focussing our attention on what is important, and filtering out other information that can be safely ignored. It is obvious that preparation is one of the most important aspects of human cognition - it shapes our conscious experience and guides our interactions with the world. However, we still know very little about how we prepare for upcoming tasks. The reason for this is that the activation of preparatory states is an internal mental phenomenon that usually takes place in the absence of any directly observable behaviour. Such states are therefore difficult to assess with the conventional performance-based measures of experimental psychology.
 In this project, we will measure preparatory states directly, while they occur, by recording brain activity (EEG) from observers when they prepare for upcoming visual search tasks. In these tasks, they have to search for a specific known target object among multiple irrelevant objects (distractors). They can prepare for search by activating a mental representation of this target object, which will then help to guide their attention to the target when it appears. We have recently developed new methods to measure such preparatory "images in the mind" directly, at the moment when they are activated, and to track these activation states in real time. We can therefore now directly observe when preparation starts and how it changes across time. We can also determine the content of such preparatory states. For example, when we prepare to search for our mobile phone on our cluttered desk, do we activate a mental image of the whole object, or just a specific attribute of this object, such as its colour or shape? Can we control the content of what we prepare for, and deliberately employ different preparation strategies in different contexts? For example, do we prepare more effectively for task goals that are motivationally relevant, because they are associated with a higher reward? How quickly can we change preparatory states affected when task goals suddenly change? Importantly, we will also investigate links between preparation and failures of selective attention. We often fail to find what we are looking for, or attention can be distracted by irrelevant objects and events. By comparing preparatory states measured on an occasion where subsequent attentional selection operates efficiently and on an occasion where it does not, we can find out how fluctuations in preparedness produce different behavioural outcomes.18:T1220,Representations of task-relevant object attributes (attentional templates) control the adaptive selectivity of visual processing. Previous studies have demonstrated that templates involved in the guidance of attention during visual search are activated in a preparatory fashion prior to the arrival of visual search displays. The current study investigated whether such proactive mechanisms are also triggered in non-search tasks, where attentional templates do not mediate the guidance of attention towards targets amongst distractors but are still necessary for subsequent target recognition processes. Participants either searched for colour-defined targets among multiple distractors or performed two other non-search tasks where imperative stimuli appeared without competing distractors (a colour-based Go/NoGo task, and a shape discrimination task where target colour was constant and could thus be ignored). Preparatory activation of colour-selective templates was tracked by measuring N2pc components (markers of attention allocation) to task-irrelevant colour singleton probes flashed every 200 ms during the interval between target displays. As expected, N2pcs were triggered by target-coloured probes in the search task, indicating that a corresponding guidance template was triggered proactively. Critically, clear probe N2pcs were also observed in the Go/NoGo task, and even in the shape discrimination task in an attenuated fashion. These findings demonstrate that the preparatory activation of feature-selective attentional task settings is not uniquely associated with the guidance of visual search but is also present in other types of visual selection tasks where guidance is not required.Our perception of the outside world, and the way that we interact with external objects and events, is not just determined by incoming sensory information, but also by our expectations and intentions. We are not merely passive recipients of perceptual signals - very often, we are already prepared for what to expect and for what will be relevant in a given situation. Being prepared allows us to deal with our environment more effectively, by focussing our attention on what is important, and filtering out other information that can be safely ignored. It is obvious that preparation is one of the most important aspects of human cognition - it shapes our conscious experience and guides our interactions with the world. However, we still know very little about how we prepare for upcoming tasks. The reason for this is that the activation of preparatory states is an internal mental phenomenon that usually takes place in the absence of any directly observable behaviour. Such states are therefore difficult to assess with the conventional performance-based measures of experimental psychology.
 In this project, we will measure preparatory states directly, while they occur, by recording brain activity (EEG) from observers when they prepare for upcoming visual search tasks. In these tasks, they have to search for a specific known target object among multiple irrelevant objects (distractors). They can prepare for search by activating a mental representation of this target object, which will then help to guide their attention to the target when it appears. We have recently developed new methods to measure such preparatory "images in the mind" directly, at the moment when they are activated, and to track these activation states in real time. We can therefore now directly observe when preparation starts and how it changes across time. We can also determine the content of such preparatory states. For example, when we prepare to search for our mobile phone on our cluttered desk, do we activate a mental image of the whole object, or just a specific attribute of this object, such as its colour or shape? Can we control the content of what we prepare for, and deliberately employ different preparation strategies in different contexts? For example, do we prepare more effectively for task goals that are motivationally relevant, because they are associated with a higher reward? How quickly can we change preparatory states affected when task goals suddenly change? Importantly, we will also investigate links between preparation and failures of selective attention. We often fail to find what we are looking for, or attention can be distracted by irrelevant objects and events. By comparing preparatory states measured on an occasion where subsequent attentional selection operates efficiently and on an occasion where it does not, we can find out how fluctuations in preparedness produce different behavioural outcomes.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/preparatory-activation-of-guidance-templates-for-visual-search-and-of-target-templates-in-non-search-tasks"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"The Preparatory Activation of Guidance Templates for Visual Search and of Target Templates in Non-Search Tasks"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
