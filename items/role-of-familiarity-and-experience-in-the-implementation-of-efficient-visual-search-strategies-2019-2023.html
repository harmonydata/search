<!DOCTYPE html><!--WLCgvrrdknkKZDhW_WCbK--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/e446a64f2ff89daf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.ccaf2443.js"/><script src="/search/_next/static/js/4bd1b696.100b9d70.js" async=""></script><script src="/search/_next/static/js/1255.90e9842b.js" async=""></script><script src="/search/_next/static/js/main-app.0e7376d5.js" async=""></script><script src="/search/_next/static/js/9692.83f9877c.js" async=""></script><script src="/search/_next/static/js/421.98ca62d9.js" async=""></script><script src="/search/_next/static/js/1759.b13f3ee1.js" async=""></script><script src="/search/_next/static/js/3535.878ceef2.js" async=""></script><script src="/search/_next/static/js/2619.b8db57ac.js" async=""></script><script src="/search/_next/static/js/3820.af314958.js" async=""></script><script src="/search/_next/static/js/574.fd20103e.js" async=""></script><script src="/search/_next/static/js/5738.d28a9943.js" async=""></script><script src="/search/_next/static/js/app/layout.7ef30b9e.js" async=""></script><script src="/search/_next/static/js/690.e023e61b.js" async=""></script><script src="/search/_next/static/js/5332.4ca3e6c6.js" async=""></script><script src="/search/_next/static/js/2410.ec36c5aa.js" async=""></script><script src="/search/_next/static/js/5183.9f1a7545.js" async=""></script><script src="/search/_next/static/js/3055.8a1757af.js" async=""></script><script src="/search/_next/static/js/8977.d520dad7.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.0819d17d.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023</title><meta name="description" content="The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under &quot;related resources&quot;. The eight repositories are:
1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.
2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.
3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.
4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.
5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).
6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).
7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.
8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.
For more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking &quot;is search optimal or random?&quot; we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."/><meta property="og:title" content="Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023"/><meta property="og:description" content="The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under &quot;related resources&quot;. The eight repositories are:
1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.
2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.
3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.
4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.
5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).
6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).
7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.
8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.
For more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking &quot;is search optimal or random?&quot; we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023"/><meta name="twitter:description" content="The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under &quot;related resources&quot;. The eight repositories are:
1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.
2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.
3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.
4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.
5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).
6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).
7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.
8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.
For more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking &quot;is search optimal or random?&quot; we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><div hidden=""><!--$--><!--/$--></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.ccaf2443.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[52332,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n3:I[65380,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"AuthProvider\"]\n4:I[41627,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[92114,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"SearchProvider\"]\n7:I[94049,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n8:I[20190,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/j"])</script><script>self.__next_f.push([1,"s/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"default\"]\n9:I[9766,[],\"\"]\na:I[98924,[],\"\"]\nb:I[74744,[\"9692\",\"static/js/9692.83f9877c.js\",\"421\",\"static/js/421.98ca62d9.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"574\",\"static/js/574.fd20103e.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.7ef30b9e.js\"],\"ToastContainer\"]\nd:I[24431,[],\"OutletBoundary\"]\nf:I[15278,[],\"AsyncMetadataOutlet\"]\n11:I[24431,[],\"ViewportBoundary\"]\n14:I[57150,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/e446a64f2ff89daf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"WLCgvrrdknkKZDhW-WCbK\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/e446a64f2ff89daf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",[\"$\",\"$Lf\",null,{\"promise\":\"$@10\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],\"$L13\"]}],false]],\"m\":\"$undefined\",\"G\":[\"$14\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"15:I[24431,[],\"MetadataBoundary\"]\n13:[\"$\",\"$L15\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$5\",null,{\"fallback\":null,\"children\":\"$L16\"}]}]}]\n"])</script><script>self.__next_f.push([1,"17:I[41402,[\"9692\",\"static/js/9692.83f9877c.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"690\",\"static/js/690.e023e61b.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"5332\",\"static/js/5332.4ca3e6c6.js\",\"2410\",\"static/js/2410.ec36c5aa.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.8a1757af.js\",\"8977\",\"static/js/8977.d520dad7.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0819d17d.js\"],\"\"]\n18:T14bd,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\",\"description\":\"The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under \\\"related resources\\\". The eight repositories are:\\n1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.\\n2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.\\n3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.\\n4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.\\n5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).\\n6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).\\n7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.\\n8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.\\nFor more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking \\\"is search optimal or random?\\\" we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal.\",\"url\":\"https://harmonydata.ac.uk/search/items/role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-857409\"],\"keywords\":[\"STRATEGIES\",\"PSYCHOLOGY\",\"PERCEPTION\"],\"temporalCoverage\":\"2019-09-30/2023-09-29\"}"])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L17\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$18\"}}],\"$L19\"]}]\n"])</script><script>self.__next_f.push([1,"1a:I[78977,[\"9692\",\"static/js/9692.83f9877c.js\",\"1759\",\"static/js/1759.b13f3ee1.js\",\"690\",\"static/js/690.e023e61b.js\",\"3535\",\"static/js/3535.878ceef2.js\",\"5332\",\"static/js/5332.4ca3e6c6.js\",\"2410\",\"static/js/2410.ec36c5aa.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.8a1757af.js\",\"8977\",\"static/js/8977.d520dad7.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.0819d17d.js\"],\"default\"]\n1b:T12c7,"])</script><script>self.__next_f.push([1,"The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under \"related resources\". The eight repositories are:\n1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.\n2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.\n3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.\n4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.\n5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).\n6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).\n7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.\n8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.\nFor more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking \"is search optimal or random?\" we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."])</script><script>self.__next_f.push([1,"19:[\"$\",\"$L1a\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\",\"description\":\"$1b\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857409\",\"https://reshare.ukdataservice.ac.uk/857409\"],\"keywords\":[\"STRATEGIES\",\"PSYCHOLOGY\",\"PERCEPTION\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-857409\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857409\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"ESRC\"}],\"temporalCoverage\":\"2019-09-30/2023-09-29\"},\"extra_data\":{\"geographic_coverage\":\"\",\"start_year\":2019,\"harmony_id\":\"ukds/857409\",\"end_year\":2023,\"data_access\":\"The Data Collection is available from an external repository. Access is available via Related Resources.\",\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=857409\",\"https://reshare.ukdataservice.ac.uk/857409\"],\"source\":[\"ukds\"],\"name\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\",\"genetic_data_collected\":false,\"num_variables\":null,\"slug\":\"role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\",\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-857409\"],\"sex\":\"male\",\"instruments\":[],\"study_design\":[],\"ai_summary\":null,\"country_codes\":[\"GB\"],\"language_codes\":[\"en\"],\"resource_type\":\"dataset\",\"duration_years\":4,\"uuid\":\"35a8095fd95bcc6bac97ea2c1bf64da4\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"1c:T12c7,"])</script><script>self.__next_f.push([1,"The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under \"related resources\". The eight repositories are:\n1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.\n2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.\n3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.\n4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.\n5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).\n6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).\n7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.\n8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.\nFor more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking \"is search optimal or random?\" we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."])</script><script>self.__next_f.push([1,"10:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$1c\"}],\"$L1d\",\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\",\"$L2a\",\"$L2b\",\"$L2c\"],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"2f:I[80622,[],\"IconMark\"]\n1d:[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\"}]\n2d:T12c7,"])</script><script>self.__next_f.push([1,"The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under \"related resources\". The eight repositories are:\n1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.\n2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.\n3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.\n4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.\n5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).\n6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).\n7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.\n8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.\nFor more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking \"is search optimal or random?\" we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."])</script><script>self.__next_f.push([1,"1e:[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"$2d\"}]\n1f:[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/role-of-familiarity-and-experience-in-the-implementation-of-efficient-visual-search-strategies-2019-2023\"}]\n20:[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}]\n21:[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}]\n22:[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n23:[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}]\n24:[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}]\n25:[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\"}]\n26:[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}]\n27:[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}]\n28:[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Role of Familiarity and Experience in the Implementation of Efficient Visual Search Strategies, 2019-2023\"}]\n2e:T12c7,"])</script><script>self.__next_f.push([1,"The data collected as part of this grant represents the search strategies, biases and habits of a large number of participants searching under a range of different conditions. Eight of the journal articles published to date under this grant involved the collection of new data, which is publicly available in eight separate repositories associated with each respective publication (together with preprints, materials, pre-registrations, and supplementary materials). Unless stated otherwise, the primary task was a variation of the “split-half line segment” (SHLS) search task as described in the grant proposal. Rather than create potential confusion for meta-analysis by duplicating the data in more than one location, we link to the eight public repositories in which they are contained under \"related resources\". The eight repositories are:\n1. https://osf.io/efg8n/: two experiments, 60 participants total. RT, accuracy and fixation data, preregistrations, preprint, r scripts, supplementary materials. We manipulate time pressure and monetary rewards and observe no effect on strategy. We also model the timecourse of strategy improvements over time, within trial and across trials.\n2. https://osf.io/9edx6/: five main experiments, 104 participants total, RT, accuracy and fixation data. Across experiments we manipulate the search target and distractors and measure effects on strategy. Also contains supplementary material and links to preregistrations, six pilot experiments and one follow-up control experiment.\n3. https://osf.io/5aq4c/: one experiment with 306 participants and one pilot with 30 participants. Participants performed SHLS alongside a battery of other tasks and measures. This was a registered report and the repository contains the stage 1 submission as well as the post-data stage 2 version of the paper.\n4. https://osf.io/unx6v/: two experiments with 46 participants total. Tests the hypothesis that making the search target self-relevant will make search more efficient (it does not). Contains pre-registration, data, supplementary material and a preprint version of the paper.\n5. https://github.com/Riadsala/single_double_feature_search: Contains stage 1 (preregistered) version of the paper, pilot (N=4) and full experimental data (N=40). Participant search for a target with one or two features (not a SLHS experiment, see paper).\n6. https://osf.io/64r7m/ This repository contains supplementary materials and data underpinning a paper demonstrating the broad utility of asymptotic regression as a tool for modelling time course data. The “short-long” experiment data was collected as part of this grant (N=50) and examines the role of experience with short deadlines on the full timecourse of trials, expressed as three parameters (initial performance, rate of change, asymptote).\n7. https://osf.io/y6qbv/ Contains data from a group of participants (N=64) performing three different search tasks that have large individual performance differences (SHLS, a foraging task, and a colour-search task). Also contains experiment code, analysis scripts, and supplementary materials.\n8. https://osf.io/8qgju/ Contains data from two experiments (N=50 total) where the spatial layout of the SHLS experiment is manipulated. Also contains pre-registrations and supplementary materials.\nFor more details information on the data and methods, see the repositories and associated publications.Imagine searching your office for your keys. You will likely start by scanning surfaces in your office such as your desk, table, and shelves. You may then check pockets, bags, and underneath papers, until you either find the keys or give up. How efficient was this search? How much time did you waste looking in places you already inspected, searching an area for too long, or looking in places that contained no useful information? In this proposal, we define search efficiency as the proportion of eye movements that are directed to locations that can be easily ascertained to provide new information. In the office example, some surfaces will be empty, and some cluttered with books and papers. If your keys were in the middle of an empty surface, you would already know where they were; no new information would be gained by looking directly at these locations. An efficient searcher would instead direct their eyes to the cluttered regions, where central vision is needed. Our recent studies using this metric to define efficiency have found a surprisingly large range of individual strategies, with some people being highly efficient, some random, and some highly inefficient. These differences suggest that rather than asking \"is search optimal or random?\" we should be asking for whom, and in what circumstances, search is optimal or random. This is the aim of the current proposal."])</script><script>self.__next_f.push([1,"29:[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"$2e\"}]\n2a:[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n2b:[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]\n2c:[\"$\",\"$L2f\",\"17\",{}]\n16:\"$10:metadata\"\n"])</script></body></html>