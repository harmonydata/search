<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/0d5b820fee8240e5.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.b15e7306.js"/><script src="/search/_next/static/js/4bd1b696.f7584cea.js" async=""></script><script src="/search/_next/static/js/1517.db76c303.js" async=""></script><script src="/search/_next/static/js/main-app.bd11093a.js" async=""></script><script src="/search/_next/static/js/6586.2e946dbf.js" async=""></script><script src="/search/_next/static/js/9197.61b93e42.js" async=""></script><script src="/search/_next/static/js/8378.a1bea36e.js" async=""></script><script src="/search/_next/static/js/2926.76e4f620.js" async=""></script><script src="/search/_next/static/js/8173.582c8c90.js" async=""></script><script src="/search/_next/static/js/1702.de0c2d51.js" async=""></script><script src="/search/_next/static/js/1983.ec5be3f4.js" async=""></script><script src="/search/_next/static/js/7184.52d31c32.js" async=""></script><script src="/search/_next/static/js/4398.8644925b.js" async=""></script><script src="/search/_next/static/js/app/layout.0819bb7e.js" async=""></script><script src="/search/_next/static/js/2282.e20001b9.js" async=""></script><script src="/search/_next/static/js/9809.f9049b43.js" async=""></script><script src="/search/_next/static/js/6741.ce01eadc.js" async=""></script><script src="/search/_next/static/js/2649.95608f08.js" async=""></script><script src="/search/_next/static/js/1857.a01744c0.js" async=""></script><script src="/search/_next/static/js/7626.cc8608ac.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.ff89d9aa.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin</title><meta name="description" content="Many studies have described a condition called &#x27;prosopagnosia&#x27;, in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of &#x27;dynamic cues&#x27; (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. 
The present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics&#x27; coping with face recognition problems."/><meta property="og:title" content="Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin"/><meta property="og:description" content="Many studies have described a condition called &#x27;prosopagnosia&#x27;, in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of &#x27;dynamic cues&#x27; (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. 
The present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics&#x27; coping with face recognition problems."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin"/><meta name="twitter:description" content="Many studies have described a condition called &#x27;prosopagnosia&#x27;, in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of &#x27;dynamic cues&#x27; (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. 
The present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics&#x27; coping with face recognition problems."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.b15e7306.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n3:I[17146,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"AuthProvider\"]\n4:I[83705,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[63612,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"SearchProvider\"]\n7:I[68998,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n8:I[98904,[\"6586\",\"static/js/6586.2e946d"])</script><script>self.__next_f.push([1,"bf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"default\"]\n9:I[15244,[],\"\"]\na:I[43866,[],\"\"]\nb:I[14046,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.52d31c32.js\",\"4398\",\"static/js/4398.8644925b.js\",\"7177\",\"static/js/app/layout.0819bb7e.js\"],\"ToastContainer\"]\nd:I[86213,[],\"OutletBoundary\"]\nf:I[86213,[],\"MetadataBoundary\"]\n11:I[86213,[],\"ViewportBoundary\"]\n13:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/0d5b820fee8240e5.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"1RcbC2baE79jiGpG5vLIx\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/0d5b820fee8240e5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"bS2D1mRpLh9oRweIu8Xjs\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$13\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"14:I[53704,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"9809\",\"static/js/9809.f9049b43.js\",\"6741\",\"static/js/6741.ce01eadc.js\",\"2649\",\"static/js/2649.95608f08.js\",\"4398\",\"static/js/4398.8644925b.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.cc8608ac.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.ff89d9aa.js\"],\"\"]\n16:I[77626,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"9809\",\"static/js/9809.f9049b43.js\",\"6741\",\"static/js/6741.ce01eadc.js\",\"2649\",\"static/js/2649.95608f08.js\",\"4398\",\"static/js/4398.8644925b.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.cc8608ac.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.ff89d9aa.js\"],\"default\"]\n15:T709,{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\",\"description\":\"Many studies have described a condition called 'prosopagnosia', in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of 'dynamic cues' (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. \\nThe present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compar"])</script><script>self.__next_f.push([1,"ed to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics' coping with face recognition problems.\",\"url\":\"https://harmonydata.ac.uk/search/items/testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-850241\"],\"keywords\":[],\"temporalCoverage\":\"2007-09-01/2008-12-31\"}17:T526,Many studies have described a condition called 'prosopagnosia', in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of 'dynamic cues' (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. \nThe present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics' coping with face recognition problems.c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L14\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"t"])</script><script>self.__next_f.push([1,"ype\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}],[\"$\",\"$L16\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\",\"description\":\"$17\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850241\",\"https://reshare.ukdataservice.ac.uk/850241\"],\"keywords\":[],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-850241\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850241\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"Economic and Social Research Council\"}],\"temporalCoverage\":\"2007-09-01/2008-12-31\"},\"extra_data\":{\"language_codes\":[\"en\"],\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-850241\"],\"source\":[\"ukds\"],\"num_variables\":null,\"name\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\",\"instruments\":[],\"sex\":\"all\",\"geographic_coverage\":\"\",\"duration_years\":1,\"start_year\":2007,\"data_access\":\"The Data Collection is available for download to users registered with the UK Data Service.\",\"genetic_data_collected\":false,\"resource_type\":\"dataset\",\"country_codes\":[\"GB\"],\"ai_summary\":null,\"study_design\":[],\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=850241\",\"https://reshare.ukdataservice.ac.uk/850241\"],\"slug\":\"testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\",\"end_year\":2008,\"harmony_id\":\"ukds/850241\",\"uuid\":\"a5dd4184d8260b93ecd43427805d3bf1\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]]}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"18:T526,Many studies have described a condition called 'prosopagnosia', in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of 'dynamic cues' (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. \nThe present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics' coping with face recognition problems.19:T526,Many studies have described a condition called 'prosopagnosia', in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of 'dynamic cues' (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. \nThe present study examines whether p"])</script><script>self.__next_f.push([1,"rosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics' coping with face recognition problems.1a:T526,Many studies have described a condition called 'prosopagnosia', in which individuals have specific difficulties recognising the faces of familiar people. Despite poor performance in recognition tasks using static faces, anecdotal evidence suggests that prosopagnosics can ameliorate their face recognition problems through the strategic use of 'dynamic cues' (such as idiosyncratic facial movements). Further, research with normal participants demonstrates that characteristic facial gestures and expressions can prove useful for accessing identity. Taken together, these studies suggest that different mechanisms may underlie facial recognition by static versus dynamic cues. \nThe present study examines whether prosopagnosics can use facial motion information for recognition and matching tasks in a similar way to normal participants, despite their impairments in static face recognition and matching. If this is the case, we would expect prosopagnosics to perform better on matching and recognition tasks that use dynamic faces, compared to static faces. Support for this hypothesis would suggest value in therapies that help prosopagnosics to capitalise on facial motion cues. Such an approach might be usefully combined with static face therapy, to maximize prosopagnosics' coping with face recognition problems.10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Testing for dissociations between static and dy"])</script><script>self.__next_f.push([1,"namic face matching and recognition in normal and abnormal face processin\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$18\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$19\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/testing-for-dissociations-between-static-and-dynamic-face-matching-and-recognition-in-normal-and-abnormal-face-processin\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Testing for dissociations between static and dynamic face matching and recognition in normal and abnormal face processin\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$1a\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"e:null\n"])</script></body></html>