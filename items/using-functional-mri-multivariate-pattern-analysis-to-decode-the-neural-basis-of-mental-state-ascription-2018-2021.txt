1:"$Sreact.fragment"
2:I[82104,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
3:I[17146,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"AuthProvider"]
4:I[63612,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"SearchProvider"]
5:I[68998,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
6:I[98904,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"default"]
7:I[15244,[],""]
8:I[43866,[],""]
9:I[14046,["6586","static/js/6586.2e946dbf.js","9197","static/js/9197.61b93e42.js","8378","static/js/8378.a1bea36e.js","2926","static/js/2926.76e4f620.js","8173","static/js/8173.582c8c90.js","1702","static/js/1702.de0c2d51.js","1983","static/js/1983.ec5be3f4.js","7184","static/js/7184.52d31c32.js","7177","static/js/app/layout.e50c3fe1.js"],"ToastContainer"]
b:I[86213,[],"OutletBoundary"]
d:I[86213,[],"MetadataBoundary"]
f:I[86213,[],"ViewportBoundary"]
11:I[34835,[],""]
:HL["/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/search/_next/static/css/0d5b820fee8240e5.css","style"]
0:{"P":null,"b":"oOvDuJZyQIOPELToyx8Mb","p":"/search","c":["","items","using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021"],"i":false,"f":[[["",{"children":["items",{"children":[["slug","using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/search/_next/static/css/0d5b820fee8240e5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":[["$","head",null,{"children":[["$","meta",null,{"name":"emotion-insertion-point","content":""}],["$","link",null,{"rel":"preconnect","href":"https://fonts.googleapis.com"}],["$","link",null,{"rel":"preconnect","href":"https://fonts.gstatic.com","crossOrigin":"anonymous"}],["$","link",null,{"rel":"preconnect","href":"https://www.cataloguementalhealth.ac.uk"}],["$","link",null,{"rel":"dns-prefetch","href":"https://harmonydata.ac.uk"}],["$","style",null,{"dangerouslySetInnerHTML":{"__html":"\n            /* Ensure immediate rendering with Roboto and fallbacks */\n            * { \n              font-family: \"Roboto\", -apple-system, BlinkMacSystemFont, \"Segoe UI\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif !important;\n              font-display: swap;\n              -webkit-font-smoothing: antialiased;\n              -moz-osx-font-smoothing: grayscale;\n            }\n            body { \n              visibility: visible !important; \n              opacity: 1 !important; \n              margin: 0; \n              padding: 0; \n            }\n          "}}]]}],["$","body",null,{"children":["$","$L2",null,{"children":["$","$L3",null,{"children":["$","$L4",null,{"children":[["$","$L5",null,{"sx":{"display":"flex","flexDirection":{"xs":"column","md":"row"}},"children":[["$","$L6",null,{}],["$","$L5",null,{"component":"main","sx":{"flexGrow":1,"ml":{"xs":0,"md":"72px"},"mt":{"xs":"64px","md":0},"minHeight":{"xs":"calc(100vh - 64px)","md":"100vh"},"width":{"xs":"100%","md":"calc(100% - 72px)"}},"children":["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}],["$","$L9",null,{"position":"bottom-right"}]]}]}]}]}]]}]]}],{"children":["items",["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021","d"],["$","$1","c",{"children":[null,["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children","items","children","$0:f:0:1:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$La",null,["$","$Lb",null,{"children":"$Lc"}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","b6fgkWP62WTTCjM0D7s3u",{"children":[["$","$Ld",null,{"children":"$Le"}],["$","$Lf",null,{"children":"$L10"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$11","$undefined"],"s":false,"S":true}
12:I[53704,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],""]
14:I[77626,["6586","static/js/6586.2e946dbf.js","8378","static/js/8378.a1bea36e.js","2282","static/js/2282.e20001b9.js","5135","static/js/5135.b8bfc30e.js","9387","static/js/9387.65629b75.js","2649","static/js/2649.37ecdd75.js","1857","static/js/1857.a01744c0.js","280","static/js/280.5152a9e2.js","7626","static/js/7626.f9409ee1.js","6387","static/js/app/items/%5Bslug%5D/page.4934bfd6.js"],"default"]
13:T14c1,{"@context":"https://schema.org/","@type":"Dataset","name":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021","description":"Functional MRI data are available for 34 participants. All subjects were scanned during a theory of mind localiser task and a novel theory of mind task. Anonymised T1 scans are also available alongside the stimuli and Matlab script for running the experiment.\nPrevious work has shown bilateral temporal-parietal junction (TPJ) and the medial prefrontal cortex (mPFC) to be involved in both memory and theory of mind (mindreading) tasks. It remains unclear whether, during mindreading, these regions represent information relevant specifically to the content of what other people are thinking, above and beyond general memory demands.\nWe hypothesised that when a participant uses their “mindreading” abilities to represent someone else’s mental states – e.g., “The target thinks there’s an X in the box” – their brain will represent the content “X” in a way that is distinct from when they only use memory to recall “X”. Distinct representation for mindreading could be quantitative (“more of the same”) or qualitative (different in kind) from representation for memory. The aim of the study was to distinguish between these possibilities with specific emphasis on the right TPJ, mPFC using multi-voxel pattern classification.\nFull details of the paradigm and analysis can be found in the pre-registration linked below.Mindreading (also known as mentalising, or Theory of Mind) is the ability to think about what others see, know, think, want and intend, and is thought to be a fundamental basis of social interaction and communication. Mindreading has been widely studied in young children and infants, is known to be impaired in people with autism and schizophrenia, and more recently its cognitive and neural basis has begun to be studied in adults. Research using brain imaging, and examining the effects of brain injury and brain stimulation, converges on the view that some brain regions are distinctively involved in mindreading compared with similar tasks that do not involve understanding other minds, leading to suggestions that they comprise a \"social\" or \"mindreading brain network\". It is typically assumed that these brain regions represent mindreading information. However, a recent alternative suggestion is that mindreading information is represented elsewhere, perhaps in \"semantic\" brain regions, and that the mindreading brain network merely controls access to this information. Testing between these views is critical for our understanding of how the brain supports mindreading, and has implications for long-debated theoretical accounts about how we mindread.\n\nThe fundamental unit of mindreading is a representation that relates a particular AGENT (e.g., Mariam) to a particular CONTENT (e.g., ...thinks there's a rabbit in the box). We will ask participants to hold such information briefly in mind using tasks that present pictures of people and simple scenarios that depict what they are thinking. Thus, participants will be led to hold in mind something like \"Mariam thinks there's a rabbit in the box, but I know there's really a bell\", with the particular AGENT and the particular CONTENTS varying from trial to trial. If \"mindreading brain regions\" are centrally involved in representing such information, then it should be possible to decode the AGENT who is thinking (Mariam in this case), and the CONTENT they are thinking about (Rabbit) from patterns of brain activity in these areas. However, if \"mindreading brain regions\" actually only direct attention to information represented \"semantic\" brain regions then, it should be possible to decode AGENT and CONTENT information from activity in \"semantic\" brain areas, but not \"mindreading\" areas.\n\nThe work is made possible by recent developments in tasks for assessing mindreading and analytic techniques for decoding information from fine-grained patterns of human brain activity. Our tasks present mindreading problems for a large number of trials over which AGENT and CONTENT are systematically varied. Three experiments will focus on CONTENT (Experiment 1), AGENT+CONTENT (Experiment 2), and the co-ordination of CONTENT information over time (Experiment 3). Experiments 1 and 2 will employ fMRI, which gives excellent spatial resolution, while Experiment 3 will use EEG, which gives excellent temporal resolution. All three experiments will employ advanced techniques for multivariate analysis of brain activity data to examine whether we can indeed decode information about who is thinking what from \"mindreading\" or \"semantic\" brain regions.\n\nOur studies will show whether regions of the social brain actually encode information necessary for mindreading, and determine the order in which such information is activated.","url":"https://harmonydata.ac.uk/search/items/using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021","identifier":["http://dx.doi.org/10.5255/UKDA-SN-855118"],"keywords":["MRI SCAN","MEMORY","ABILITY EVALUATION","MENTAL DEVELOPMENT","PSYCHOLOGY"],"temporalCoverage":"2018-06-01/2021-11-30"}15:T1281,Functional MRI data are available for 34 participants. All subjects were scanned during a theory of mind localiser task and a novel theory of mind task. Anonymised T1 scans are also available alongside the stimuli and Matlab script for running the experiment.
Previous work has shown bilateral temporal-parietal junction (TPJ) and the medial prefrontal cortex (mPFC) to be involved in both memory and theory of mind (mindreading) tasks. It remains unclear whether, during mindreading, these regions represent information relevant specifically to the content of what other people are thinking, above and beyond general memory demands.
We hypothesised that when a participant uses their “mindreading” abilities to represent someone else’s mental states – e.g., “The target thinks there’s an X in the box” – their brain will represent the content “X” in a way that is distinct from when they only use memory to recall “X”. Distinct representation for mindreading could be quantitative (“more of the same”) or qualitative (different in kind) from representation for memory. The aim of the study was to distinguish between these possibilities with specific emphasis on the right TPJ, mPFC using multi-voxel pattern classification.
Full details of the paradigm and analysis can be found in the pre-registration linked below.Mindreading (also known as mentalising, or Theory of Mind) is the ability to think about what others see, know, think, want and intend, and is thought to be a fundamental basis of social interaction and communication. Mindreading has been widely studied in young children and infants, is known to be impaired in people with autism and schizophrenia, and more recently its cognitive and neural basis has begun to be studied in adults. Research using brain imaging, and examining the effects of brain injury and brain stimulation, converges on the view that some brain regions are distinctively involved in mindreading compared with similar tasks that do not involve understanding other minds, leading to suggestions that they comprise a "social" or "mindreading brain network". It is typically assumed that these brain regions represent mindreading information. However, a recent alternative suggestion is that mindreading information is represented elsewhere, perhaps in "semantic" brain regions, and that the mindreading brain network merely controls access to this information. Testing between these views is critical for our understanding of how the brain supports mindreading, and has implications for long-debated theoretical accounts about how we mindread.

The fundamental unit of mindreading is a representation that relates a particular AGENT (e.g., Mariam) to a particular CONTENT (e.g., ...thinks there's a rabbit in the box). We will ask participants to hold such information briefly in mind using tasks that present pictures of people and simple scenarios that depict what they are thinking. Thus, participants will be led to hold in mind something like "Mariam thinks there's a rabbit in the box, but I know there's really a bell", with the particular AGENT and the particular CONTENTS varying from trial to trial. If "mindreading brain regions" are centrally involved in representing such information, then it should be possible to decode the AGENT who is thinking (Mariam in this case), and the CONTENT they are thinking about (Rabbit) from patterns of brain activity in these areas. However, if "mindreading brain regions" actually only direct attention to information represented "semantic" brain regions then, it should be possible to decode AGENT and CONTENT information from activity in "semantic" brain areas, but not "mindreading" areas.

The work is made possible by recent developments in tasks for assessing mindreading and analytic techniques for decoding information from fine-grained patterns of human brain activity. Our tasks present mindreading problems for a large number of trials over which AGENT and CONTENT are systematically varied. Three experiments will focus on CONTENT (Experiment 1), AGENT+CONTENT (Experiment 2), and the co-ordination of CONTENT information over time (Experiment 3). Experiments 1 and 2 will employ fMRI, which gives excellent spatial resolution, while Experiment 3 will use EEG, which gives excellent temporal resolution. All three experiments will employ advanced techniques for multivariate analysis of brain activity data to examine whether we can indeed decode information about who is thinking what from "mindreading" or "semantic" brain regions.

Our studies will show whether regions of the social brain actually encode information necessary for mindreading, and determine the order in which such information is activated.a:[["$","$L12",null,{"strategy":"beforeInteractive","id":"structured-data","type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"$13"}}],["$","$L14",null,{"study":{"dataset_schema":{"@context":"https://schema.org/","@type":"Dataset","name":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021","description":"$15","url":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855118","https://reshare.ukdataservice.ac.uk/855118"],"keywords":["MRI SCAN","MEMORY","ABILITY EVALUATION","MENTAL DEVELOPMENT","PSYCHOLOGY"],"identifier":["http://dx.doi.org/10.5255/UKDA-SN-855118"],"includedInDataCatalog":[{"@type":"DataCatalog","name":"UK Data Service","url":"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855118"}],"sponsor":[{"@type":"Organization","name":"Economic and Social Research Council"}],"temporalCoverage":"2018-06-01/2021-11-30"},"extra_data":{"study_design":[],"duration_years":3,"slug":"using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021","source":["ukds"],"language_codes":["en"],"num_variables":null,"geographic_coverage":"Birmingham","instruments":[],"country_codes":["GB"],"name":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021","sex":"all","ai_summary":null,"urls":["https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=855118","https://reshare.ukdataservice.ac.uk/855118"],"resource_type":"dataset","dois":["http://dx.doi.org/10.5255/UKDA-SN-855118"],"end_year":2021,"genetic_data_collected":false,"data_access":"The Data Collection is available for download to users registered with the UK Data Service.","harmony_id":"ukds/855118","start_year":2018,"uuid":"27f6aae8b7a393e485f960416b6de589"},"distance":0,"score":0,"parent":{},"ancestors":[]}}]]
10:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
16:T1281,Functional MRI data are available for 34 participants. All subjects were scanned during a theory of mind localiser task and a novel theory of mind task. Anonymised T1 scans are also available alongside the stimuli and Matlab script for running the experiment.
Previous work has shown bilateral temporal-parietal junction (TPJ) and the medial prefrontal cortex (mPFC) to be involved in both memory and theory of mind (mindreading) tasks. It remains unclear whether, during mindreading, these regions represent information relevant specifically to the content of what other people are thinking, above and beyond general memory demands.
We hypothesised that when a participant uses their “mindreading” abilities to represent someone else’s mental states – e.g., “The target thinks there’s an X in the box” – their brain will represent the content “X” in a way that is distinct from when they only use memory to recall “X”. Distinct representation for mindreading could be quantitative (“more of the same”) or qualitative (different in kind) from representation for memory. The aim of the study was to distinguish between these possibilities with specific emphasis on the right TPJ, mPFC using multi-voxel pattern classification.
Full details of the paradigm and analysis can be found in the pre-registration linked below.Mindreading (also known as mentalising, or Theory of Mind) is the ability to think about what others see, know, think, want and intend, and is thought to be a fundamental basis of social interaction and communication. Mindreading has been widely studied in young children and infants, is known to be impaired in people with autism and schizophrenia, and more recently its cognitive and neural basis has begun to be studied in adults. Research using brain imaging, and examining the effects of brain injury and brain stimulation, converges on the view that some brain regions are distinctively involved in mindreading compared with similar tasks that do not involve understanding other minds, leading to suggestions that they comprise a "social" or "mindreading brain network". It is typically assumed that these brain regions represent mindreading information. However, a recent alternative suggestion is that mindreading information is represented elsewhere, perhaps in "semantic" brain regions, and that the mindreading brain network merely controls access to this information. Testing between these views is critical for our understanding of how the brain supports mindreading, and has implications for long-debated theoretical accounts about how we mindread.

The fundamental unit of mindreading is a representation that relates a particular AGENT (e.g., Mariam) to a particular CONTENT (e.g., ...thinks there's a rabbit in the box). We will ask participants to hold such information briefly in mind using tasks that present pictures of people and simple scenarios that depict what they are thinking. Thus, participants will be led to hold in mind something like "Mariam thinks there's a rabbit in the box, but I know there's really a bell", with the particular AGENT and the particular CONTENTS varying from trial to trial. If "mindreading brain regions" are centrally involved in representing such information, then it should be possible to decode the AGENT who is thinking (Mariam in this case), and the CONTENT they are thinking about (Rabbit) from patterns of brain activity in these areas. However, if "mindreading brain regions" actually only direct attention to information represented "semantic" brain regions then, it should be possible to decode AGENT and CONTENT information from activity in "semantic" brain areas, but not "mindreading" areas.

The work is made possible by recent developments in tasks for assessing mindreading and analytic techniques for decoding information from fine-grained patterns of human brain activity. Our tasks present mindreading problems for a large number of trials over which AGENT and CONTENT are systematically varied. Three experiments will focus on CONTENT (Experiment 1), AGENT+CONTENT (Experiment 2), and the co-ordination of CONTENT information over time (Experiment 3). Experiments 1 and 2 will employ fMRI, which gives excellent spatial resolution, while Experiment 3 will use EEG, which gives excellent temporal resolution. All three experiments will employ advanced techniques for multivariate analysis of brain activity data to examine whether we can indeed decode information about who is thinking what from "mindreading" or "semantic" brain regions.

Our studies will show whether regions of the social brain actually encode information necessary for mindreading, and determine the order in which such information is activated.17:T1281,Functional MRI data are available for 34 participants. All subjects were scanned during a theory of mind localiser task and a novel theory of mind task. Anonymised T1 scans are also available alongside the stimuli and Matlab script for running the experiment.
Previous work has shown bilateral temporal-parietal junction (TPJ) and the medial prefrontal cortex (mPFC) to be involved in both memory and theory of mind (mindreading) tasks. It remains unclear whether, during mindreading, these regions represent information relevant specifically to the content of what other people are thinking, above and beyond general memory demands.
We hypothesised that when a participant uses their “mindreading” abilities to represent someone else’s mental states – e.g., “The target thinks there’s an X in the box” – their brain will represent the content “X” in a way that is distinct from when they only use memory to recall “X”. Distinct representation for mindreading could be quantitative (“more of the same”) or qualitative (different in kind) from representation for memory. The aim of the study was to distinguish between these possibilities with specific emphasis on the right TPJ, mPFC using multi-voxel pattern classification.
Full details of the paradigm and analysis can be found in the pre-registration linked below.Mindreading (also known as mentalising, or Theory of Mind) is the ability to think about what others see, know, think, want and intend, and is thought to be a fundamental basis of social interaction and communication. Mindreading has been widely studied in young children and infants, is known to be impaired in people with autism and schizophrenia, and more recently its cognitive and neural basis has begun to be studied in adults. Research using brain imaging, and examining the effects of brain injury and brain stimulation, converges on the view that some brain regions are distinctively involved in mindreading compared with similar tasks that do not involve understanding other minds, leading to suggestions that they comprise a "social" or "mindreading brain network". It is typically assumed that these brain regions represent mindreading information. However, a recent alternative suggestion is that mindreading information is represented elsewhere, perhaps in "semantic" brain regions, and that the mindreading brain network merely controls access to this information. Testing between these views is critical for our understanding of how the brain supports mindreading, and has implications for long-debated theoretical accounts about how we mindread.

The fundamental unit of mindreading is a representation that relates a particular AGENT (e.g., Mariam) to a particular CONTENT (e.g., ...thinks there's a rabbit in the box). We will ask participants to hold such information briefly in mind using tasks that present pictures of people and simple scenarios that depict what they are thinking. Thus, participants will be led to hold in mind something like "Mariam thinks there's a rabbit in the box, but I know there's really a bell", with the particular AGENT and the particular CONTENTS varying from trial to trial. If "mindreading brain regions" are centrally involved in representing such information, then it should be possible to decode the AGENT who is thinking (Mariam in this case), and the CONTENT they are thinking about (Rabbit) from patterns of brain activity in these areas. However, if "mindreading brain regions" actually only direct attention to information represented "semantic" brain regions then, it should be possible to decode AGENT and CONTENT information from activity in "semantic" brain areas, but not "mindreading" areas.

The work is made possible by recent developments in tasks for assessing mindreading and analytic techniques for decoding information from fine-grained patterns of human brain activity. Our tasks present mindreading problems for a large number of trials over which AGENT and CONTENT are systematically varied. Three experiments will focus on CONTENT (Experiment 1), AGENT+CONTENT (Experiment 2), and the co-ordination of CONTENT information over time (Experiment 3). Experiments 1 and 2 will employ fMRI, which gives excellent spatial resolution, while Experiment 3 will use EEG, which gives excellent temporal resolution. All three experiments will employ advanced techniques for multivariate analysis of brain activity data to examine whether we can indeed decode information about who is thinking what from "mindreading" or "semantic" brain regions.

Our studies will show whether regions of the social brain actually encode information necessary for mindreading, and determine the order in which such information is activated.18:T1281,Functional MRI data are available for 34 participants. All subjects were scanned during a theory of mind localiser task and a novel theory of mind task. Anonymised T1 scans are also available alongside the stimuli and Matlab script for running the experiment.
Previous work has shown bilateral temporal-parietal junction (TPJ) and the medial prefrontal cortex (mPFC) to be involved in both memory and theory of mind (mindreading) tasks. It remains unclear whether, during mindreading, these regions represent information relevant specifically to the content of what other people are thinking, above and beyond general memory demands.
We hypothesised that when a participant uses their “mindreading” abilities to represent someone else’s mental states – e.g., “The target thinks there’s an X in the box” – their brain will represent the content “X” in a way that is distinct from when they only use memory to recall “X”. Distinct representation for mindreading could be quantitative (“more of the same”) or qualitative (different in kind) from representation for memory. The aim of the study was to distinguish between these possibilities with specific emphasis on the right TPJ, mPFC using multi-voxel pattern classification.
Full details of the paradigm and analysis can be found in the pre-registration linked below.Mindreading (also known as mentalising, or Theory of Mind) is the ability to think about what others see, know, think, want and intend, and is thought to be a fundamental basis of social interaction and communication. Mindreading has been widely studied in young children and infants, is known to be impaired in people with autism and schizophrenia, and more recently its cognitive and neural basis has begun to be studied in adults. Research using brain imaging, and examining the effects of brain injury and brain stimulation, converges on the view that some brain regions are distinctively involved in mindreading compared with similar tasks that do not involve understanding other minds, leading to suggestions that they comprise a "social" or "mindreading brain network". It is typically assumed that these brain regions represent mindreading information. However, a recent alternative suggestion is that mindreading information is represented elsewhere, perhaps in "semantic" brain regions, and that the mindreading brain network merely controls access to this information. Testing between these views is critical for our understanding of how the brain supports mindreading, and has implications for long-debated theoretical accounts about how we mindread.

The fundamental unit of mindreading is a representation that relates a particular AGENT (e.g., Mariam) to a particular CONTENT (e.g., ...thinks there's a rabbit in the box). We will ask participants to hold such information briefly in mind using tasks that present pictures of people and simple scenarios that depict what they are thinking. Thus, participants will be led to hold in mind something like "Mariam thinks there's a rabbit in the box, but I know there's really a bell", with the particular AGENT and the particular CONTENTS varying from trial to trial. If "mindreading brain regions" are centrally involved in representing such information, then it should be possible to decode the AGENT who is thinking (Mariam in this case), and the CONTENT they are thinking about (Rabbit) from patterns of brain activity in these areas. However, if "mindreading brain regions" actually only direct attention to information represented "semantic" brain regions then, it should be possible to decode AGENT and CONTENT information from activity in "semantic" brain areas, but not "mindreading" areas.

The work is made possible by recent developments in tasks for assessing mindreading and analytic techniques for decoding information from fine-grained patterns of human brain activity. Our tasks present mindreading problems for a large number of trials over which AGENT and CONTENT are systematically varied. Three experiments will focus on CONTENT (Experiment 1), AGENT+CONTENT (Experiment 2), and the co-ordination of CONTENT information over time (Experiment 3). Experiments 1 and 2 will employ fMRI, which gives excellent spatial resolution, while Experiment 3 will use EEG, which gives excellent temporal resolution. All three experiments will employ advanced techniques for multivariate analysis of brain activity data to examine whether we can indeed decode information about who is thinking what from "mindreading" or "semantic" brain regions.

Our studies will show whether regions of the social brain actually encode information necessary for mindreading, and determine the order in which such information is activated.e:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021"}],["$","meta","2",{"name":"description","content":"$16"}],["$","meta","3",{"property":"og:title","content":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021"}],["$","meta","4",{"property":"og:description","content":"$17"}],["$","meta","5",{"property":"og:url","content":"https://harmonydata.ac.uk/search/items/using-functional-mri-multivariate-pattern-analysis-to-decode-the-neural-basis-of-mental-state-ascription-2018-2021"}],["$","meta","6",{"property":"og:site_name","content":"Academic Resource Discovery"}],["$","meta","7",{"property":"og:locale","content":"en_US"}],["$","meta","8",{"property":"og:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","meta","9",{"property":"og:image:width","content":"1200"}],["$","meta","10",{"property":"og:image:height","content":"630"}],["$","meta","11",{"property":"og:image:alt","content":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021"}],["$","meta","12",{"property":"og:type","content":"website"}],["$","meta","13",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","14",{"name":"twitter:title","content":"Using Functional MRI Multivariate Pattern Analysis to Decode the Neural Basis of Mental State Ascription, 2018-2021"}],["$","meta","15",{"name":"twitter:description","content":"$18"}],["$","meta","16",{"name":"twitter:image","content":"https://harmonydata.ac.uk/search/harmony.png"}],["$","link","17",{"rel":"icon","href":"/search/favicon.ico","type":"image/x-icon","sizes":"16x16"}]]
c:null
