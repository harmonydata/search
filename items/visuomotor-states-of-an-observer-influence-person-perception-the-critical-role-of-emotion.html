<!DOCTYPE html><!--669YHYfowfluJ5cB834U0--><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/e446a64f2ff89daf.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.1a25c7f6.js"/><script src="/search/_next/static/js/4bd1b696.100b9d70.js" async=""></script><script src="/search/_next/static/js/1255.90e9842b.js" async=""></script><script src="/search/_next/static/js/main-app.0e7376d5.js" async=""></script><script src="/search/_next/static/js/9692.83f9877c.js" async=""></script><script src="/search/_next/static/js/1828.31087444.js" async=""></script><script src="/search/_next/static/js/7213.f8248d79.js" async=""></script><script src="/search/_next/static/js/690.e023e61b.js" async=""></script><script src="/search/_next/static/js/7133.521b2ecd.js" async=""></script><script src="/search/_next/static/js/9829.124a89b0.js" async=""></script><script src="/search/_next/static/js/2619.b8db57ac.js" async=""></script><script src="/search/_next/static/js/3820.af314958.js" async=""></script><script src="/search/_next/static/js/5906.206ff298.js" async=""></script><script src="/search/_next/static/js/5738.d28a9943.js" async=""></script><script src="/search/_next/static/js/app/layout.079f6f03.js" async=""></script><script src="/search/_next/static/js/867.7f6bef5e.js" async=""></script><script src="/search/_next/static/js/2939.aa50df5c.js" async=""></script><script src="/search/_next/static/js/5183.9f1a7545.js" async=""></script><script src="/search/_next/static/js/3055.87b66c06.js" async=""></script><script src="/search/_next/static/js/8977.89625695.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.cedc9485.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>Visuomotor states of an observer influence person perception: the critical role of emotion</title><meta name="description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta property="og:title" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta property="og:description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Visuomotor states of an observer influence person perception: the critical role of emotion"/><meta name="twitter:description" content="This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. 
For each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.
Previous research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:

1. 
to establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.


2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.

3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.


4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><div hidden=""><!--$--><!--/$--></div><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.1a25c7f6.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[52332,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n3:I[65380,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"AuthProvider\"]\n4:I[41627,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[92114,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"SearchProvider\"]\n7:I[94049,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958."])</script><script>self.__next_f.push([1,"js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n8:I[20190,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"default\"]\n9:I[9766,[],\"\"]\na:I[98924,[],\"\"]\nb:I[74744,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"7213\",\"static/js/7213.f8248d79.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"2619\",\"static/js/2619.b8db57ac.js\",\"3820\",\"static/js/3820.af314958.js\",\"5906\",\"static/js/5906.206ff298.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"7177\",\"static/js/app/layout.079f6f03.js\"],\"ToastContainer\"]\nd:I[24431,[],\"OutletBoundary\"]\nf:I[15278,[],\"AsyncMetadataOutlet\"]\n11:I[24431,[],\"ViewportBoundary\"]\n13:I[24431,[],\"MetadataBoundary\"]\n15:I[57150,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/e446a64f2ff89daf.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"669YHYfowfluJ5cB834U0\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/e446a64f2ff89daf.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":[\"$Le\",[\"$\",\"$Lf\",null,{\"promise\":\"$@10\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]],[\"$\",\"$L13\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$5\",null,{\"fallback\":null,\"children\":\"$L14\"}]}]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$15\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"16:I[41402,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"\"]\n18:I[78977,[\"9692\",\"static/js/9692.83f9877c.js\",\"1828\",\"static/js/1828.31087444.js\",\"690\",\"static/js/690.e023e61b.js\",\"7133\",\"static/js/7133.521b2ecd.js\",\"9829\",\"static/js/9829.124a89b0.js\",\"867\",\"static/js/867.7f6bef5e.js\",\"2939\",\"static/js/2939.aa50df5c.js\",\"5183\",\"static/js/5183.9f1a7545.js\",\"5738\",\"static/js/5738.d28a9943.js\",\"3055\",\"static/js/3055.87b66c06.js\",\"8977\",\"static/js/8977.89625695.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.cedc9485.js\"],\"default\"]\n17:T965,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\",\"description\":\"This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \\nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\\n\\n1. \\nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\\n\\n\\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\\n\\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\\n\\n\\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval.\",\"url\":\"https://harmonydata.ac.uk/search/items/visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-852488\"],\"keywords\":[\"FACIAL MIMICRY\",\"EMOTION\",\"SPATIAL COMPATIBILITY\",\"SOCIAL CUES\",\"TRUSTWORTHINESS\",\"INCIDENTAL LEARNING\",\"VISUOMOTOR FLUENCY\",\"GAZE CUEING\"],\"temporalCoverage\":\"2013-04-01/2016-09-30\"}"])</script><script>self.__next_f.push([1,"19:T728,"])</script><script>self.__next_f.push([1,"This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L16\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$17\"}}],[\"$\",\"$L18\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\",\"description\":\"$19\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852488\",\"https://reshare.ukdataservice.ac.uk/852488\"],\"keywords\":[\"FACIAL MIMICRY\",\"EMOTION\",\"SPATIAL COMPATIBILITY\",\"SOCIAL CUES\",\"TRUSTWORTHINESS\",\"INCIDENTAL LEARNING\",\"VISUOMOTOR FLUENCY\",\"GAZE CUEING\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-852488\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852488\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"ESRC\"}],\"temporalCoverage\":\"2013-04-01/2016-09-30\"},\"extra_data\":{\"language_codes\":[\"en\"],\"harmony_id\":\"ukds/852488\",\"start_year\":2013,\"end_year\":2016,\"data_access\":\"The Data Collection is available to any user without the requirement for registration for download/access. \",\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852488\",\"https://reshare.ukdataservice.ac.uk/852488\"],\"source\":[\"ukds\"],\"name\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\",\"num_variables\":null,\"genetic_data_collected\":false,\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-852488\"],\"sex\":\"male\",\"instruments\":[],\"slug\":\"visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\",\"ai_summary\":null,\"duration_years\":3,\"country_codes\":[\"GB\"],\"resource_type\":\"dataset\",\"geographic_coverage\":\"\",\"study_design\":[],\"uuid\":\"ec61c9de1d8ab67f870e4fffbb9f83ec\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]]}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:null\n"])</script><script>self.__next_f.push([1,"1a:T728,"])</script><script>self.__next_f.push([1,"This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."])</script><script>self.__next_f.push([1,"1b:T728,"])</script><script>self.__next_f.push([1,"This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."])</script><script>self.__next_f.push([1,"10:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"$1a\"}],[\"$\",\"meta\",\"2\",{\"property\":\"og:title\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:description\",\"content\":\"$1b\"}],\"$L1c\",\"$L1d\",\"$L1e\",\"$L1f\",\"$L20\",\"$L21\",\"$L22\",\"$L23\",\"$L24\",\"$L25\",\"$L26\",\"$L27\",\"$L28\",\"$L29\"],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"2b:I[80622,[],\"IconMark\"]\n1c:[\"$\",\"meta\",\"4\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/visuomotor-states-of-an-observer-influence-person-perception-the-critical-role-of-emotion\"}]\n1d:[\"$\",\"meta\",\"5\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}]\n1e:[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}]\n1f:[\"$\",\"meta\",\"7\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n20:[\"$\",\"meta\",\"8\",{\"property\":\"og:image:width\",\"content\":\"1200\"}]\n21:[\"$\",\"meta\",\"9\",{\"property\":\"og:image:height\",\"content\":\"630\"}]\n22:[\"$\",\"meta\",\"10\",{\"property\":\"og:image:alt\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}]\n23:[\"$\",\"meta\",\"11\",{\"property\":\"og:type\",\"content\":\"website\"}]\n24:[\"$\",\"meta\",\"12\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}]\n25:[\"$\",\"meta\",\"13\",{\"name\":\"twitter:title\",\"content\":\"Visuomotor states of an observer influence person perception: the critical role of emotion\"}]\n2a:T728,"])</script><script>self.__next_f.push([1,"This data collection contains experimental data that support nine publications on the core processes involved in social learning, in particular the role of emotion as a critical variable during implicit learning of subtle social cues. \nFor each publication, a zip file contains experimental data files and a readme file that describes the content of the data files and how these are interpreted within the manuscript. Data were collected from participants’ responses to stimuli on a computer screen.\nPrevious research has investigated visuomotor processes, demonstrating that visual information is automatically converted in to action, and that these action states activated by vision can feedback and influence subsequent visual processes. Thus there is a bi-directional relationship from vision-to-action and from action-to-vision. The research will test the novel hypothesis that emotional reactions are central to these processes: more specifically, the feedback from body motor states to visual processes only influences the latter if they are accompanied by positive or negative emotional reactions. To examine this we intend to employ the technique of recording facial muscle activity via EMG as a measure of implicit/non-conscious emotional reactions. The main goals are:\n\n1. \nto establish EMG as a direct and implicit measure of emotional reactions during visuomotor processes.\n\n\n2. to demonstrate that body states activated via prior visuomotor processes determine the perception of other people in terms of assigning personal traits and levels of trust, when emotional reactions are evoked.\n\n3. to use converging techniques which explicitly evoke body states associated with positive or negative emotions.\n\n\n4. to examine whether recording of EMG can be used as a new measure of implicit non-conscious memory retrieval."])</script><script>self.__next_f.push([1,"26:[\"$\",\"meta\",\"14\",{\"name\":\"twitter:description\",\"content\":\"$2a\"}]\n27:[\"$\",\"meta\",\"15\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}]\n28:[\"$\",\"link\",\"16\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]\n29:[\"$\",\"$L2b\",\"17\",{}]\n14:\"$10:metadata\"\n"])</script></body></html>