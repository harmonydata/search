<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/search/_next/static/css/80937bd8c5d07cbc.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/search/_next/static/js/webpack.b15e7306.js"/><script src="/search/_next/static/js/4bd1b696.f7584cea.js" async=""></script><script src="/search/_next/static/js/1517.db76c303.js" async=""></script><script src="/search/_next/static/js/main-app.bd11093a.js" async=""></script><script src="/search/_next/static/js/6586.2e946dbf.js" async=""></script><script src="/search/_next/static/js/9197.61b93e42.js" async=""></script><script src="/search/_next/static/js/8378.a1bea36e.js" async=""></script><script src="/search/_next/static/js/2926.76e4f620.js" async=""></script><script src="/search/_next/static/js/8173.582c8c90.js" async=""></script><script src="/search/_next/static/js/1702.de0c2d51.js" async=""></script><script src="/search/_next/static/js/1983.ec5be3f4.js" async=""></script><script src="/search/_next/static/js/7184.c89e68fe.js" async=""></script><script src="/search/_next/static/js/4398.8b943151.js" async=""></script><script src="/search/_next/static/js/app/layout.123737db.js" async=""></script><script src="/search/_next/static/js/2282.e20001b9.js" async=""></script><script src="/search/_next/static/js/9809.f9049b43.js" async=""></script><script src="/search/_next/static/js/6741.ce01eadc.js" async=""></script><script src="/search/_next/static/js/2649.39caf1a1.js" async=""></script><script src="/search/_next/static/js/1857.a01744c0.js" async=""></script><script src="/search/_next/static/js/7626.7cae5298.js" async=""></script><script src="/search/_next/static/js/app/items/%5Bslug%5D/page.ff89d9aa.js" async=""></script><meta name="next-size-adjust" content=""/><meta name="emotion-insertion-point" content=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://www.cataloguementalhealth.ac.uk"/><link rel="dns-prefetch" href="https://harmonydata.ac.uk"/><title>Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan</title><meta name="description" content="We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson &amp; Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."/><meta property="og:title" content="Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"/><meta property="og:description" content="We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson &amp; Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."/><meta property="og:url" content="https://harmonydata.ac.uk/search/items/watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan"/><meta property="og:site_name" content="Academic Resource Discovery"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://harmonydata.ac.uk/search/harmony.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan"/><meta name="twitter:description" content="We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). 
Only dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. 

Behavioural training analysis
Dance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.
 
Physical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.
 
VA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.
 
Post-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.
 
Neuroimaging Procedure
Each participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson &amp; Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."/><meta name="twitter:image" content="https://harmonydata.ac.uk/search/harmony.png"/><link rel="icon" href="/search/favicon.ico" type="image/x-icon" sizes="16x16"/><style>
            /* Ensure immediate rendering with Roboto and fallbacks */
            * { 
              font-family: "Roboto", -apple-system, BlinkMacSystemFont, "Segoe UI", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif !important;
              font-display: swap;
              -webkit-font-smoothing: antialiased;
              -moz-osx-font-smoothing: grayscale;
            }
            body { 
              visibility: visible !important; 
              opacity: 1 !important; 
              margin: 0; 
              padding: 0; 
            }
          </style><script src="/search/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script><style data-emotion="mui-global v658lt">html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;box-sizing:border-box;-webkit-text-size-adjust:100%;}*,*::before,*::after{box-sizing:inherit;}strong,b{font-weight:700;}body{margin:0;color:#1A1A1A;font-size:0.875rem;line-height:1.5;font-family:'Roboto','Roboto Fallback',-apple-system,BlinkMacSystemFont,Segoe UI,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;font-weight:400;background-color:#FFFFFF;}@media (min-width:600px){body{font-size:1rem;}}@media print{body{background-color:#fff;}}body::backdrop{background-color:#FFFFFF;}</style></head><body><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><div>Loading...</div><!--/$--><script src="/search/_next/static/js/webpack.b15e7306.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[82104,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"default\"]\n3:I[17146,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"AuthProvider\"]\n4:I[83705,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"FirebaseProvider\"]\n5:\"$Sreact.suspense\"\n6:I[63612,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"SearchProvider\"]\n7:I[68998,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"default\"]\n8:I[98904,[\"6586\",\"static/js/6586.2e946d"])</script><script>self.__next_f.push([1,"bf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"default\"]\n9:I[15244,[],\"\"]\na:I[43866,[],\"\"]\nb:I[14046,[\"6586\",\"static/js/6586.2e946dbf.js\",\"9197\",\"static/js/9197.61b93e42.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2926\",\"static/js/2926.76e4f620.js\",\"8173\",\"static/js/8173.582c8c90.js\",\"1702\",\"static/js/1702.de0c2d51.js\",\"1983\",\"static/js/1983.ec5be3f4.js\",\"7184\",\"static/js/7184.c89e68fe.js\",\"4398\",\"static/js/4398.8b943151.js\",\"7177\",\"static/js/app/layout.123737db.js\"],\"ToastContainer\"]\nd:I[86213,[],\"OutletBoundary\"]\nf:I[86213,[],\"MetadataBoundary\"]\n11:I[86213,[],\"ViewportBoundary\"]\n13:I[34835,[],\"\"]\n:HL[\"/search/_next/static/media/47cbc4e2adbc5db9-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/search/_next/static/css/80937bd8c5d07cbc.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"1E0t4sM2VGxrOb4kqv6Ho\",\"p\":\"/search\",\"c\":[\"\",\"items\",\"watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"items\",{\"children\":[[\"slug\",\"watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/search/_next/static/css/80937bd8c5d07cbc.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[[\"$\",\"meta\",null,{\"name\":\"emotion-insertion-point\",\"content\":\"\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.googleapis.com\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://fonts.gstatic.com\",\"crossOrigin\":\"anonymous\"}],[\"$\",\"link\",null,{\"rel\":\"preconnect\",\"href\":\"https://www.cataloguementalhealth.ac.uk\"}],[\"$\",\"link\",null,{\"rel\":\"dns-prefetch\",\"href\":\"https://harmonydata.ac.uk\"}],[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"\\n            /* Ensure immediate rendering with Roboto and fallbacks */\\n            * { \\n              font-family: \\\"Roboto\\\", -apple-system, BlinkMacSystemFont, \\\"Segoe UI\\\", \\\"Oxygen\\\", \\\"Ubuntu\\\", \\\"Cantarell\\\", \\\"Fira Sans\\\", \\\"Droid Sans\\\", \\\"Helvetica Neue\\\", sans-serif !important;\\n              font-display: swap;\\n              -webkit-font-smoothing: antialiased;\\n              -moz-osx-font-smoothing: grayscale;\\n            }\\n            body { \\n              visibility: visible !important; \\n              opacity: 1 !important; \\n              margin: 0; \\n              padding: 0; \\n            }\\n          \"}}]]}],[\"$\",\"body\",null,{\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"children\":[\"$\",\"$L4\",null,{\"children\":[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[\"$\",\"$L6\",null,{\"children\":[[\"$\",\"$L7\",null,{\"sx\":{\"display\":\"flex\",\"flexDirection\":{\"xs\":\"column\",\"md\":\"row\"}},\"children\":[[\"$\",\"$L8\",null,{}],[\"$\",\"$L7\",null,{\"component\":\"main\",\"sx\":{\"flexGrow\":1,\"ml\":{\"xs\":0,\"md\":\"72px\"},\"mt\":{\"xs\":\"64px\",\"md\":0},\"minHeight\":{\"xs\":\"calc(100vh - 64px)\",\"md\":\"100vh\"},\"width\":{\"xs\":\"100%\",\"md\":\"calc(100% - 72px)\"}},\"children\":[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],[\"$\",\"$Lb\",null,{\"position\":\"bottom-right\"}]]}]}]}]}]}]}]]}]]}],{\"children\":[\"items\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L9\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"items\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$La\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$Lc\",null,[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"aynaFPB9QdO5DWL7-99qo\",{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],[\"$\",\"$L11\",null,{\"children\":\"$L12\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$13\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"14:I[53704,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"9809\",\"static/js/9809.f9049b43.js\",\"6741\",\"static/js/6741.ce01eadc.js\",\"2649\",\"static/js/2649.39caf1a1.js\",\"4398\",\"static/js/4398.8b943151.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.7cae5298.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.ff89d9aa.js\"],\"\"]\n16:I[77626,[\"6586\",\"static/js/6586.2e946dbf.js\",\"8378\",\"static/js/8378.a1bea36e.js\",\"2282\",\"static/js/2282.e20001b9.js\",\"9809\",\"static/js/9809.f9049b43.js\",\"6741\",\"static/js/6741.ce01eadc.js\",\"2649\",\"static/js/2649.39caf1a1.js\",\"4398\",\"static/js/4398.8b943151.js\",\"1857\",\"static/js/1857.a01744c0.js\",\"7626\",\"static/js/7626.7cae5298.js\",\"6387\",\"static/js/app/items/%5Bslug%5D/page.ff89d9aa.js\"],\"default\"]\n15:T14e3,"])</script><script>self.__next_f.push([1,"{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\",\"description\":\"We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). \\nOnly dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. \\n\\nBehavioural training analysis\\nDance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.\\n \\nPhysical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.\\n \\nVA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.\\n \\nPost-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.\\n \\nNeuroimaging Procedure\\nEach participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson \u0026 Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response.\",\"url\":\"https://harmonydata.ac.uk/search/items/watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\",\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-852472\"],\"keywords\":[\"ACTION OBSERVATION NETWORK\",\"DANCE\",\"MOTOR LEARNING\",\"PARIETAL\",\"PREMOTOR\",\"TRAINING\"],\"temporalCoverage\":\"2013-04-22/2016-03-18\"}"])</script><script>self.__next_f.push([1,"17:T12b5,"])</script><script>self.__next_f.push([1,"We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). \nOnly dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. \n\nBehavioural training analysis\nDance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.\n \nPhysical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.\n \nVA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.\n \nPost-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.\n \nNeuroimaging Procedure\nEach participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson \u0026 Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."])</script><script>self.__next_f.push([1,"c:[\"$\",\"$5\",null,{\"fallback\":[\"$\",\"div\",null,{\"children\":\"Loading...\"}],\"children\":[[\"$\",\"$L14\",null,{\"strategy\":\"beforeInteractive\",\"id\":\"structured-data\",\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}],[\"$\",\"$L16\",null,{\"study\":{\"dataset_schema\":{\"@context\":\"https://schema.org/\",\"@type\":\"Dataset\",\"name\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\",\"description\":\"$17\",\"url\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852472\",\"https://reshare.ukdataservice.ac.uk/852472\"],\"keywords\":[\"ACTION OBSERVATION NETWORK\",\"DANCE\",\"MOTOR LEARNING\",\"PARIETAL\",\"PREMOTOR\",\"TRAINING\"],\"identifier\":[\"http://dx.doi.org/10.5255/UKDA-SN-852472\"],\"includedInDataCatalog\":[{\"@type\":\"DataCatalog\",\"name\":\"UK Data Service\",\"url\":\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852472\"}],\"sponsor\":[{\"@type\":\"Organization\",\"name\":\"Economic and Social Research Council\"}],\"temporalCoverage\":\"2013-04-22/2016-03-18\"},\"extra_data\":{\"name\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\",\"duration_years\":3,\"data_access\":\"The Data Collection only consists of metadata and documentation as the data could not be archived due to legal, ethical or commercial constraints. For further information, please contact the contact person for this data collection.\\n\",\"country_codes\":[\"GB\"],\"harmony_id\":\"ukds/852472\",\"num_variables\":null,\"geographic_coverage\":\"Bangor\",\"dois\":[\"http://dx.doi.org/10.5255/UKDA-SN-852472\"],\"urls\":[\"https://beta.ukdataservice.ac.uk/datacatalogue/studies/study?id=852472\",\"https://reshare.ukdataservice.ac.uk/852472\"],\"instruments\":[],\"slug\":\"watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\",\"end_year\":2016,\"ai_summary\":null,\"genetic_data_collected\":false,\"study_design\":[],\"source\":[\"ukds\"],\"sex\":\"all\",\"language_codes\":[\"en\"],\"start_year\":2013,\"resource_type\":\"dataset\",\"uuid\":\"5070958a6d89906de65f3860444e973d\"},\"distance\":0,\"score\":0,\"parent\":{},\"ancestors\":[]}}]]}]\n"])</script><script>self.__next_f.push([1,"12:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n"])</script><script>self.__next_f.push([1,"18:T12b5,"])</script><script>self.__next_f.push([1,"We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). \nOnly dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. \n\nBehavioural training analysis\nDance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.\n \nPhysical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.\n \nVA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.\n \nPost-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.\n \nNeuroimaging Procedure\nEach participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson \u0026 Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."])</script><script>self.__next_f.push([1,"19:T12b5,"])</script><script>self.__next_f.push([1,"We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). \nOnly dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. \n\nBehavioural training analysis\nDance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.\n \nPhysical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.\n \nVA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.\n \nPost-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.\n \nNeuroimaging Procedure\nEach participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson \u0026 Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."])</script><script>self.__next_f.push([1,"1a:T12b5,"])</script><script>self.__next_f.push([1,"We recruited three groups of neurologically healthy participants: 20 Adolescents (Mean age = 12.7; SD = 0.8; 7 female); 23 Younger adults (Mean age = 19.44; SD = 1.62; 11 female) and 19 Older adults (Mean age = 63.6; SD = 4.40, 11 females). \nOnly dance-naive participants were selected. This meant all participants had limited or no experience performing or observing dance, and none had prior experience playing dance video games. \n\nBehavioural training analysis\nDance performance scores recorded by the Kinect™ system each day of PVA training for each participant were used to quantify participants’ performance across the training days and test day. Raw numeric scores, as quantified by the Kinect™ system, were used.\n \nPhysical performance. The four raw scores participants received each day for the dance sequences in the PVA condition were averaged so that each participant had a single score representing their dance performance for each training day. A repeated measures ANOVA with training day as a within-subjects factor with four levels (days 1, 2, 3 and 4) was conducted on these scores to confirm the training manipulation worked and that physical performance increased across the daily training sessions. Additionally, we performed pairwise comparisons to determine how performance on consecutive days of training compared.\n \nVA recognition task accuracy. To ensure participants paid close attention to the sequences they watched and listened to in the VA training condition, they were asked to perform a simple recognition task on video segments.  An accuracy score for each participant on each of the four days of training was calculated based on their performance on this task, and a repeated measures ANOVA on these accuracy scores was conducted to investigate the effect of VA training on the recognition task accuracy over the days of training.\n \nPost-training behavioural test. On the final day of the experiment, participants physically performed all eight training sequences: the two from the PVA condition, two from the VA condition, two from the A condition, and two additional untrained sequences that they had seen short segments of during fMRI. Raw scores from both exemplars from each training category were averaged within training conditions to produce an average score per participant for each of the four test conditions. We performed a repeated measures ANOVA on these scores to investigate the impact of different kinds of experience on physical performance. Pairwise comparisons (Bonferonni corrected) were subsequently evaluated to further investigate any differences between conditions in more detail. Degrees of freedom reflect the Greenhouse-Geisser correction where sphericity has been violated.\n \nNeuroimaging Procedure\nEach participant completed one functional magnetic resonance imaging (fMRI) session prior to the training procedures and an identical session immediately following the four days of training. Participants completed 2 runs within each scanning session, lasting an average of 15 min and containing 80 trials each. In each run, participants watched and listened to 64 music video stimuli featuring short dance segments taken from the four training conditions (PVA, VA, A and untrained) that were each between 3.5 and 4.5 seconds in length. Each stimulus was preceded by a fixation cross presented for 3-8 seconds (the amount of time the fixation cross was on the screen was pseudo-randomized). Each trial was followed by one of two questions in which participants were required to aesthetically rate the observed dance movement (‘How much did you like the movement you just watched?’), or assess their physical ability to reproduce the movement (‘How well could you reproduce the movement you just watched?’). These questions were shortened to ‘LIKE?’ and ‘REPRODUCE?’, respectively, and participants responded via a button response. The next trial started once participants answered or after a maximum of 4s. Participants provided their response via a four-button fibre optic response box placed on their lap on which they rested the index finger and middle fingers of both hands over the buttons. The Likert-scale ranged from 1 (not at all) to 4 (extremely), and was counterbalanced across participants such that the scale was reversed for half of the participants. Participants were instructed to watch the dance movements carefully and respond to the question following each video. Analyses that take into account participants’ ratings are the focus of a separate study (Kirsch, Dawson \u0026 Cross, manuscript in preparation). Ten additional video stimuli featuring the main dancer standing still were presented throughout the functional runs for 5 seconds each and required no response."])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"$18\"}],[\"$\",\"meta\",\"3\",{\"property\":\"og:title\",\"content\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:description\",\"content\":\"$19\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:url\",\"content\":\"https://harmonydata.ac.uk/search/items/watch-and-learn-mapping-the-behavioural-and-neural-profile-of-observational-learning-throughout-the-lifespan\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:site_name\",\"content\":\"Academic Resource Discovery\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image:alt\",\"content\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"14\",{\"name\":\"twitter:title\",\"content\":\"Watch and learn: Mapping the behavioural and neural profile of observational learning throughout the lifespan\"}],[\"$\",\"meta\",\"15\",{\"name\":\"twitter:description\",\"content\":\"$1a\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:image\",\"content\":\"https://harmonydata.ac.uk/search/harmony.png\"}],[\"$\",\"link\",\"17\",{\"rel\":\"icon\",\"href\":\"/search/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"e:null\n"])</script></body></html>